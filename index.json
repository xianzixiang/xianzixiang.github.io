[{"authors":["admin"],"categories":null,"content":"Zixiang Xian is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1582962603,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://faithio.cn/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Zixiang Xian is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.","tags":null,"title":"Zixiang Xian","type":"authors"},{"authors":["zi_xian"],"categories":null,"content":"Xian Zixiang is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\nBefore his graduate study, he is a senior backend engineer at Kingsoft Company, skilling at Golang, Java, JavaScript, and Python.\nHe is so motivative and passion for exploring the new world of computer science.\nFeel free to contact me.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1582962603,"objectID":"b531f07f2ad34c1997a37315504c48d8","permalink":"https://faithio.cn/authors/zi_xian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/zi_xian/","section":"authors","summary":"Xian Zixiang is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\nBefore his graduate study, he is a senior backend engineer at Kingsoft Company, skilling at Golang, Java, JavaScript, and Python.\nHe is so motivative and passion for exploring the new world of computer science.\nFeel free to contact me.","tags":null,"title":"XIAN ZIXIANG","type":"authors"},{"authors":[],"categories":[],"content":" Confusion Matrix Sensitivity vs Specificity AUC vs ROC ","date":1588885534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"af80896f9c59632f8f07a607c95e9a2c","permalink":"https://faithio.cn/post/auc-vs-roc/","publishdate":"2020-05-07T17:05:34-04:00","relpermalink":"/post/auc-vs-roc/","section":"post","summary":" Confusion Matrix Sensitivity vs Specificity AUC vs ROC ","tags":[],"title":"AUC vs ROC","type":"post"},{"authors":[],"categories":[],"content":" 需要基于假设，考虑你的假设合不合理\nGenerative Model 初始化一系列参数，可以random也可以从已经训练的数据得来。\n每次增加loglikelihood 结束在local minimum\nLow-density Separation Assumption 通过一定策略将pseudo-label data 增加到train set，也可以给一定weight，confident有高weight\noutput一个数字其实不会影响结果\n对于神经网络哪个有用 Entropy-based Regularization entropy越小越好， labelled data cross entropy越小越好，也可以加上weight\n看倾向于哪边\nOutlook: Semi-supervised SVM 穷举所有unlabeled data。改一些label 如果objective function大，那就改\nSmoothness Assumption  近朱者赤，近墨者黑 “You are known by the company you keep”\n x1 和 x2 之间有high density\n文本分类\nCluster and then Label 在image 上可能不会work，因为pixel可能差不多，但是并不像\n人的左右侧面/手写\n Deep Autoencoder call feature, call clustering.\n Graph-based Approach 网页的hyperlink/论文的引用可以做分类\n因为有取exp，所以下降很快，singularity才会大。需要有这样的机制才不会连到跨海沟的link\n data 需要够多，不然会断掉\n 两两拿出来，乘以weights\n让神经网络的labeled data 和真正的label 越接近越好，还要符合smoothness assumption的假设。做gradient descent\nBetter Representation ","date":1587850047,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"fe29690851b31ba92744a5bedd4cce3b","permalink":"https://faithio.cn/post/semi-supervised-learning/","publishdate":"2020-04-25T17:27:27-04:00","relpermalink":"/post/semi-supervised-learning/","section":"post","summary":"需要基于假设，考虑你的假设合不合理 Generative Model 初始化一系列参数，可以random也可以从已经训练的数据得来。 每次增加loglikelihood 结束在","tags":[],"title":"Semi Supervised Learning","type":"post"},{"authors":[],"categories":[],"content":" 讲讲Ensemble Methods的Boosting/Bagging/Stacking\n在Kaggle比赛最后都会用到Ensemble Methods来提高performance。\n简单来说就是：Ensemble of various models into one more effective model\n一般来说model \u0026rsquo;s learning error 来自于 variance, noise, and bias.\nensemble的出现就是为了解决这三个问题，让model 更加robust。\nBagging to decrease the model’s variance;  主要解决overfiting问题，让error surface更加平缓。\n 可以并行进行。\n 采取voting 或者average方法选取model，所以weight是相同的\n 一般采用subsample方法，分为bootstraping and aggregating。但是在sample的过程中样本是有放回的\n  # Get some classifiers to evaluate from sklearn.model_selection import cross_val_score from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import RidgeClassifier from sklearn.svm import SVC seed = 1075 np.random.seed(seed) # Create classifiers rf = RandomForestClassifier() et = ExtraTreesClassifier() knn = KNeighborsClassifier() svc = SVC() rg = RidgeClassifier() clf_array = [rf, et, knn, svc, rg] for clf in clf_array: vanilla_scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1) bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=seed) bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1) print \u0026quot;Mean of: {1:.3f}, std: (+/-) {2:.3f [{0}]\u0026quot; .format(clf.__class__.__name__, vanilla_scores.mean(), vanilla_scores.std()) print \u0026quot;Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\u0026quot; .format(clf.__class__.__name__, bagging_scores.mean(), bagging_scores.std())  Mean of: 0.632, std: (+/-) 0.081 [RandomForestClassifier] Mean of: 0.639, std: (+/-) 0.069 [Bagging RandomForestClassifier] Mean of: 0.636, std: (+/-) 0.080 [ExtraTreesClassifier] Mean of: 0.654, std: (+/-) 0.073 [Bagging ExtraTreesClassifier] Mean of: 0.500, std: (+/-) 0.086 [KNeighborsClassifier] Mean of: 0.535, std: (+/-) 0.111 [Bagging KNeighborsClassifier] Mean of: 0.465, std: (+/-) 0.085 [SVC] Mean of: 0.535, std: (+/-) 0.083 [Bagging SVC] Mean of: 0.639, std: (+/-) 0.050 [RidgeClassifier] Mean of: 0.597, std: (+/-) 0.045 [Bagging RidgeClassifier]  在做cross validation 验证的时候，只有ridge classifier的准确率下降了，其他的方法都能提高accuracy。\n那现在bagged classifier都比原来好了，我们选择哪个呢？\nVoting，可以做hard voting或者soft voting（vote by weight）、\n以下是hard voting\n实际情况，weight是比较难调整的。\nBoosting to decreasing the model’s bias 集合weak classifier，降低error rate。相当于sequential，只能一个个进行。\n代表model：Adaboost\n find a weak classifer with less then 50% accuracy. 惩罚分类结果，错误的增加weight，正确的降低weight 继续train  又可以演化为Gradient Boosting\nStacking to increasing the predictive force of the classifier. stacking 主要就是将多个训练好的比较负责模型的output 作为Logistics Regression1的input。\n 其实仔细思考下有点像神经网络的fine tuned。\n 在Kaggle中最广泛被使用就是stacking\n因为可以并行训练，多个不同model之间weight设置好可以消除variance\n下面是一个比赛第三名采用方法\n My final submission is ensemble of resnet34 x 5, inception-v3 and se-resnext50\n   Model GPUs Image size Training Epochs Training Time     resnet34 1x TitanX 512 40 16 hours   inception-v3 3x TitanX 1024 27 1day 15 hours   se-resnext50 2x TitanX 1024 22 2days 15 hours     什么是TTA Test Time Augmentation\ncited：https://towardsdatascience.com/augmentation-for-image-classification-24ffcbc38833\n因为对比度，截取等原因可能misclassified，可以使用TTA\nTo mitigate errors such as these we use TTA wherein we predict class for the original test image along with 4 random tranforms of the same image. We then take an average of the predictions to determine which class the image belongs to.\n The intuition behind this is that even if the test image is not too easy to make a prediction, the transformations change it such that the model has higher chances of capturing the dog/cat shape and predicting accordingly.\n 简单来说就是同一种image，采用不同transform，然后取average prediction。当同一个图片有不同的变换，model更容易learn到feature。\n当然现在GAN 能生成更多更复杂的图片了参考：https://arxiv.org/pdf/1712.04621.pdf\n","date":1587842825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"a667464f4bde667d37be950a8981a824","permalink":"https://faithio.cn/post/ensemble-methods/","publishdate":"2020-04-25T15:27:05-04:00","relpermalink":"/post/ensemble-methods/","section":"post","summary":"讲讲Ensemble Methods的Boosting/Bagging/Stacking 在Kaggle比赛最后都会用到Ensemble Meth","tags":[],"title":"Ensemble Methods","type":"post"},{"authors":[],"categories":[],"content":"Both of Cross-entropy and KL divergence are tools to measure the distance between two probability distribution. What is the difference?\n𝐻(𝑃,𝑄)=−∑𝑥𝑃(𝑥)log𝑄(𝑥)H(P,Q)=−∑xP(x)log⁡Q(x)\n𝐾𝐿(𝑃|𝑄)=∑𝑥𝑃(𝑥)log𝑃(𝑥)𝑄(𝑥)KL(P|Q)=∑xP(x)log⁡P(x)Q(x)\nMoreover, minimization of KL is equivalent to minimization of Cross-Entropy.\nI want to know them instinctively.\nYou will need some conditions to claim the equivalence between minimizing cross entropy and minimizing KL divergence. I will put your question under the context of classification problems using cross entropy as loss functions.\nLet us first recall that entropy is used to measure the uncertainty of a system, which is defined as\n𝑆(𝑣)=−∑𝑖𝑝(𝑣𝑖)log𝑝(𝑣𝑖),S(v)=−∑ip(vi)log⁡p(vi),\nfor\nFor instance, the event A I will die eventually is almost certain (maybe we can solve the aging problem for word almost), therefore it has low entropy which requires only the information of the aging problem cannot be solved to make it certain. However, the event B The president will die in 50 years is much more uncertain than A, thus it needs more information to remove the uncertainties.\nNow look at the definition of KL divergence between events A and B\n𝐷𝐾𝐿(𝐴∥𝐵)=∑𝑖𝑝𝐴(𝑣𝑖)log𝑝𝐴(𝑣𝑖)−𝑝𝐴(𝑣𝑖)log𝑝𝐵(𝑣𝑖),DKL(A∥B)=∑ipA(vi)log⁡pA(vi)−pA(vi)log⁡pB(vi),\nwhere the first term of the right hand side is the entropy of event A, the second term can be interpreted as the expectation of event B in terms of event A. And the\nTo relate cross entropy to entropy and KL divergence, we formalize the cross entropy in terms of events A and B as\n𝐻(𝐴,𝐵)=−∑𝑖𝑝𝐴(𝑣𝑖)log𝑝𝐵(𝑣𝑖).H(A,B)=−∑ipA(vi)log⁡pB(vi).\nFrom the definitions, we can easily see𝐻(𝐴,𝐵)=𝐷𝐾𝐿(𝐴∥𝐵)+𝑆𝐴.H(A,B)=DKL(A∥B)+SA. .\nA further question follows naturally as how the entropy can be a constant. In a machine learning task, we start with a dataset (denoted as 𝑃()P(D)) which represent the problem to be solved, and the learning purpose is to make the model estimated distribution (denoted as 𝑃(𝑚𝑜𝑑𝑒𝑙)P(model)) as close as possible to true distribution of the problem (denoted as 𝑃(𝑡𝑟𝑢𝑡ℎ)P(truth)). 𝑃(𝑡𝑟𝑢𝑡ℎ)P(truth) is unknown and represented by 𝑃()P(D). Therefore in an ideal world, we expect\n𝑃(𝑚𝑜𝑑𝑒𝑙)≈𝑃()≈𝑃(𝑡𝑟𝑢𝑡ℎ)P(model)≈P(D)≈P(truth)\nand minimize . And luckily, in practiceDis given, which means its entropy𝑆(𝐷)S(D)is fixed as a constant.\n","date":1587836497,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"8372b9139b33d3334de203cf7f9bc11b","permalink":"https://faithio.cn/post/crossentropy-vs-kl-divergence/","publishdate":"2020-04-25T13:41:37-04:00","relpermalink":"/post/crossentropy-vs-kl-divergence/","section":"post","summary":"Both of Cross-entropy and KL divergence are tools to measure the distance between two probability distribution. What is the difference?\n𝐻(𝑃,𝑄)=−∑𝑥𝑃(𝑥)log𝑄(𝑥)H(P,Q)=−∑xP(x)log⁡Q(x)\n𝐾𝐿(𝑃|𝑄)=∑𝑥𝑃(𝑥)log𝑃(𝑥)𝑄(𝑥)KL(P|Q)=∑xP(x)log⁡P(x)Q(x)\nMoreover, minimization of KL is equivalent to minimization of Cross-Entropy.\nI want to know them instinctively.\nYou will need some conditions to claim the equivalence between minimizing cross entropy and minimizing KL divergence. I will put your question under the context of classification problems using cross entropy as loss functions.","tags":[],"title":"CrossEntropy vs KL Divergence","type":"post"},{"authors":[],"categories":[],"content":" Why use GNN?\nClassification问题，丢一个没有见过的图片进去\n怎么知道node 和 edge的 feature\nNN4G Aggregation Readout DCNN DGC MoNet GAT GIN dgl.ai\nGraph Signal Processing and Spectral-based GNN ","date":1587308472,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"0eec5fe9e6c0716cf0513348d26681c0","permalink":"https://faithio.cn/post/gnn/","publishdate":"2020-04-19T11:01:12-04:00","relpermalink":"/post/gnn/","section":"post","summary":"Why use GNN? Classification问题，丢一个没有见过的图片进去 怎么知道node 和 edge的 feature NN4G Aggregation Readout DCNN DGC MoNet GAT GIN dgl.ai Graph Signal Processing and Spectral-based GNN","tags":[],"title":"GNN","type":"post"},{"authors":[],"categories":[],"content":" Adaptive Learning Rates  不增加运算量的情况下，算二次微分，其实是采样\n Stochastic Gradient Descent Feature scaling  x1对梯度影响很小，update慢， error surface 不一样，正圆速度更快\n Gradient Descent Theory Limitation of Gradient Descent New Optimizers for deep learning Exponential moving average (EMA)\n找到一组参数使得Loss function的和最小\nOptimizer: Real Application Bert: QA/文章生成/阅读理解\ntransformer： 翻译\nTacotron：语音生成\nBig-Gan\nMEMO：在不同分类学习共同的分类\n都是Adam\nYOLO：影像侦测\nMask R-CNN\nResNet\n都是（SGDM）\nhttps://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/\nSGDM 比较稳定，不会有很大落差，coverge很好。\nTtraining和testing的function有差异。\nSWATS 什么切换点不太合适，没有证明。Adam是adaptive，会被分母影响\n切换的方法不科学\nAdam的问题\nAMSGrad adaptive learning rate 可以动态调整，需要大步走大步，平缓的地方可以大步走过去。\nLR range test Cyclical LR learning rate 大的时候就是exploring，小的时候fine-tuning, step size如何设计？\nDoes Adam need warm-up? 总结 ","date":1587135393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"c43035c82a56d3f87b7c42d9cf68bf8a","permalink":"https://faithio.cn/post/gradient-descent/","publishdate":"2020-04-17T10:56:33-04:00","relpermalink":"/post/gradient-descent/","section":"post","summary":"Adaptive Learning Rates 不增加运算量的情况下，算二次微分，其实是采样 Stochastic Gradient Descent Feature scaling x1对梯度影响很小，update慢， error surface 不一样，正圆速度更快 Gradient Descent Theory Limitation of Gradient Descent New Optimizers for","tags":[],"title":"Gradient Descent","type":"post"},{"authors":[],"categories":[],"content":" bert - semi-supervisored learning\nRNN - Hard to parallel\nCNN can parallel, 但是需要叠很长时间的咨询\n可以完全替代RNN，也是sequence2sequence的模型\n除以dimensions是为了减少variance，相乘会产生更多error\nSummary 变形 位置并不重要（天涯若比邻）\nseq2seq mask: 只会attend 产生出来的sequence。\n","date":1587008752,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"77d740a99bda7443b0674a7a636abf6b","permalink":"https://faithio.cn/post/transformer/","publishdate":"2020-04-15T23:45:52-04:00","relpermalink":"/post/transformer/","section":"post","summary":"bert - semi-supervisored learning RNN - Hard to parallel CNN can parallel, 但是需要叠很长时间的咨询 可以完全替代RNN，也是sequence2sequence的模型 除以dimensions是为","tags":[],"title":"Transformer","type":"post"},{"authors":[],"categories":[],"content":" Generating Word Vector is unsupervised.\nHow about auto-encoder?\nCount based Prediction-based 就也是one of encoding，output 接近\n变形  不是deep ，只是一个linear hidden layer。\n 有很多tip，很多人其实也做过，并且用deep。不用deep可以做很多运算量   Unsupervised Learning: Neighbor Embedding TSNE\nx\u0026ndash;\u0026gt;z没有很好的依据\nELMO/BERT/GPT\n如果同一个词汇有多种senses\n不同意思的token同样的type也有不同的embedding\n过去是查字典，用不同的embedding\n然后每个word token has its own embedding\nELMO Embeddings from Language Model\n不同语义下的hidden layer的input 作为Contextualized embedding\n不同的人物取的hidderlayer不一样\nSRL:\nCoref: 代名词找到人物找出\nSNLI:\nSQuAD: QA问题\nSST-5: Semantic classification\nBidirectional Encoder Representations from Transformers (BERT) 训练bert的时候，中文最好用字更好，input word，会产出一堆embedding\n中文的字，常用的只有4k one of encoding 小很多，但是词都是无穷\ntraining 第一种\n随机挖空15%mask 然后预测。两个词填在这里没有违和感就表示有类似的embedding\n第二种方法：\nSEP: 分界。\nCLS：classification。在这开头表示要做分类。为什么放开头？\n如果是RNN结构，放在尾部比较合理，因为尾部才会输出。但是bert内部是transformer，两个相邻或者很远的没有差别。对于放在哪里区别不大\n这两个方法需要同时使用，效果最好\n在CLS前面放一个类型，24层或者48层，文本分类，情感分类\nSlot filling，挖词填空\nNatural Language Inference，回答对错\n其实是分类，只有三类\nExtraction-based Question Answering 阅读理解\n怎么train呢？\n橙色的s，蓝色的是e，每次都做类似attention的动作。这些词汇来自于文章。取最高的概率\nS=3，e=2 就是此题无解\nEnhanced Representation through Knowledge Integration (ERNIE) 为中文设计的\nbert trained by其他语言文本分类，但是可以快速学会中文的分类\nGenerative Pre-Training (GPT) ","date":1586990905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"dda22775532b33c5619df28e8a31ac26","permalink":"https://faithio.cn/post/wordembeddingelmobert/","publishdate":"2020-04-15T18:48:25-04:00","relpermalink":"/post/wordembeddingelmobert/","section":"post","summary":"Generating Word Vector is unsupervised. How about auto-encoder? Count based Prediction-based 就也是one of encoding，output 接近 变形 不是deep ，只是一个linear hidden layer。 有很多tip，很多","tags":[],"title":"Embedding","type":"post"},{"authors":[],"categories":[],"content":"","date":1586983342,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"6a6faa41c8fe066312ffcd4736cb727d","permalink":"https://faithio.cn/post/ml-2020/","publishdate":"2020-04-15T16:42:22-04:00","relpermalink":"/post/ml-2020/","section":"post","summary":"","tags":[],"title":"ML 2020","type":"post"},{"authors":[],"categories":[],"content":" Pre-training  unlabled data有大量，可以先训练好，最后再用labled data train 一下就好\n CNN ","date":1586485145,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"947f4a41a0400747495afbd92f3bb7e7","permalink":"https://faithio.cn/post/auto-encoder/","publishdate":"2020-04-09T22:19:05-04:00","relpermalink":"/post/auto-encoder/","section":"post","summary":"Pre-training unlabled data有大量，可以先训练好，最后再用labled data train 一下就好 CNN","tags":[],"title":"Auto Encoder","type":"post"},{"authors":[],"categories":[],"content":" HMM Step1 Step2 ","date":1586466969,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"dfad30ea5c8945132281581b39194905","permalink":"https://faithio.cn/post/structured-learning/","publishdate":"2020-04-09T17:16:09-04:00","relpermalink":"/post/structured-learning/","section":"post","summary":" HMM Step1 Step2 ","tags":[],"title":"Structured Learning","type":"post"},{"authors":[],"categories":[],"content":" http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/\nGate function uses sigmoid, but not ReLu\nRNN 的big problems  RNN不好训练不是因为activation function，而是来自time sequence，同样的weight，在不同的时间点反复使用\n LSTM 可以让RNN的error surface 不那么崎岖，可以把平坦的地方拿掉，gradient vanishing but not gradient explode。\nlearning rate 小的时候训练，没有平台训练。\n为什么handling gradient vanishing？\nRNN：memory的值每次都会被洗掉\nLSTM：memory 乘以forget gate再加起input的值， memory和input相加的。只要forget gate open就不会清除memory，所以不会有gradient vanishing。\n 建议不要给forget gate很大的bias，确保它多数情况开启。\n  参数比较少，LSTM如果overfiting，可以尝试GRU。\nGRU： input gate/ forget gate联动，input 打开的时候，forget关闭，洗掉memory。要清掉memory才能放新值。\n  如果用identity matrix 初始化，就是ReLu 作为activation function，效果很好。吊打LSTM！\n如果是random，就用sigmoid 作为activation function。\n Attention-based model(Memory) RNN output \u0026ndash;\u0026gt; HMM/CRF(input)\n","date":1586403161,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586466803,"objectID":"726ed725854b5f265031c5e90bcb7807","permalink":"https://faithio.cn/post/rnn/","publishdate":"2020-04-08T23:32:41-04:00","relpermalink":"/post/rnn/","section":"post","summary":"http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/ Gate function uses sigmoid, but not ReLu RNN 的big problems RNN不好训练不是因为activation function，而是来自time sequence，同样的weight","tags":[],"title":"RNN","type":"post"},{"authors":[],"categories":[],"content":" dropout linear 好 \u0026ndash;\u0026gt;ReLU/maxout 好\n ##ResNet\n","date":1586399414,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"ef8aeccdbe56db07f0af0a93a9e02c54","permalink":"https://faithio.cn/post/cnn/","publishdate":"2020-04-08T22:30:14-04:00","relpermalink":"/post/cnn/","section":"post","summary":"dropout linear 好 \u0026ndash;\u0026gt;ReLU/maxout 好 ##ResNet","tags":[],"title":"CNN","type":"post"},{"authors":[],"categories":[],"content":" $$ \\begin{array}{l}P(Y | X)=\\frac{P(X | Y) P(Y)}{P(X)} \\propto(P(X | Y) \\cdot P(Y) \\ M A P \\ P(Y=0 | X) \\Rightarrow P(Y=1 | X)\\end{array} $$\nClassification 改进  不同的class可以share参数，如果参数越多，variance会越大，就会导致overfiting。Feature和covariance的平方成正比\n  当Gaussian 共用covariance的时候，boundary就是linear的，所以也可以成为linear model。但是如果不共用covariance就不是linear的\n 简单的模型，参数少，bias大，variance小\n复杂的模型，参数多，bias小，variance大\n covariance除了对角线都是零，属性与属性之间是independent\n Logistic Regression  Cross entropy\n  为什么逻辑回归不用square error来定义loss function呢？\n  可以通过解least square error的方式，找最佳解，然后初始化\n Why Logistic Regression cannot use square error Discriminative vs Generative Gaussian 属于Generative，但是covarianceshare的话，model是一样的\n找出的parameter w b是不一样的\n如果当前label有问题，data是有noise的，generative model做了一些强的假设就可以排除干扰。\nprior 和 class-dependent probability来自不同的分布，语音辨识，prior是从网络上收集的文本（某一句话说出的几率），class-dependent才是声音和文本的结合。\n所以整个系统是generative的系统\nMultilass 因为有exponential 大的值和小的值会被拉的更开，一定是正的。total sum 是，因为做了normalization。（softmax是强化）\nSoftmax output用来统计posterior probability。有三个class， gaussian，共用covariance matrix，就会得到softmax。（Maximum entropy和Logistic regression一样的）\nXOR问题 ","date":1586273008,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"852281a8c886216194a5c29b9c39b138","permalink":"https://faithio.cn/post/classification/","publishdate":"2020-04-07T11:23:28-04:00","relpermalink":"/post/classification/","section":"post","summary":"$$ \\begin{array}{l}P(Y | X)=\\frac{P(X | Y) P(Y)}{P(X)} \\propto(P(X | Y) \\cdot P(Y) \\ M A P \\ P(Y=0 | X) \\Rightarrow P(Y=1 | X)\\end{array} $$ Classification 改进 不同的class可以share参数，如果参数越多，variance会越大，就会导致o","tags":[],"title":"Classification","type":"post"},{"authors":[],"categories":[],"content":" kernel method 证明 linear SVM vs Logistics Regression 区别在于loss function.\n如果是hinge loss 就是linear SVM\nCross Entropy 就是logistics regression\nSVM也有deep 版本，function也不一定是linear。Deeplearning用HingeLoss 作为loss function就是Deep SVM\nKernel method Kernel trick Radial basic function kernel - RBF 很容易出现overfiting\nSigmoid kernel 可以直接设计kernel function\nx是structured data like sequence，每个sequence的长度不一样。\nkernel 类似于定义similarity。\nMercer‘s theory 可以检查。\n总结  Support vector regression（SVR）  进入到某一个距离的时候loss就是0\n Ranking SVM 考虑output是需要有order list的。像recommend系统\n One-class SVM：positive的自成一类，其他的散开\n  ","date":1586272919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"039a5aded1ea3595932b885cc9d1a1b6","permalink":"https://faithio.cn/post/svm/","publishdate":"2020-04-07T11:21:59-04:00","relpermalink":"/post/svm/","section":"post","summary":"kernel method 证明 linear SVM vs Logistics Regression 区别在于loss function. 如果是hinge loss 就是linear SVM Cross Entropy 就是logistics regression SVM也有deep 版本，function","tags":[],"title":"SVM","type":"post"},{"authors":[],"categories":[],"content":" click here for link\nGAN $$ \\mathcal{KL}(p|q) = E_p[\\log \\frac{p}{q}] \\ \u0026mdash;-\nP_g \\rightarrow \\theta_g \\text{ MLE: } \\thetag = \\arg \\max{\\thetag} \\sum{i=1}^N \\log P_g(xi) = \\arg \\min \\mathcal{KL}(P{data}|P_g) $$\n","date":1586184049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"1d122806ed4491e33c03463a7e4f4592","permalink":"https://faithio.cn/post/generative-adversarial-network/","publishdate":"2020-04-06T10:40:49-04:00","relpermalink":"/post/generative-adversarial-network/","section":"post","summary":"click here for link\nGAN $$ \\mathcal{KL}(p|q) = E_p[\\log \\frac{p}{q}] \\ \u0026mdash;-\nP_g \\rightarrow \\theta_g \\text{ MLE: } \\thetag = \\arg \\max{\\thetag} \\sum{i=1}^N \\log P_g(xi) = \\arg \\min \\mathcal{KL}(P{data}|P_g) $$","tags":[],"title":"Generative Adversarial Network","type":"post"},{"authors":[],"categories":[],"content":" Neural Networks Basics Logistic Regression as a Neural Network $$ \\hat{y}=\\sigma\\left(w^{T} x+b\\right), \\text { where } \\sigma(z)=\\frac{1}{1+e^{-z}} \\\n\\text { Given }\\left{\\left(x^{(1)}, y^{(1)}\\right), \\ldots,\\left(x^{(m)}, y^{(m)}\\right)\\right}, \\text { want } \\hat{y}^{(i)} \\approx y^{(i)} $$\nLoss(error) function:\nDon\u0026rsquo;t use this, non-convex $$ \\ell(\\hat{y}, y)=\\frac{1}{2}(\\hat{y}-y)^{2} $$ The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. $$ J(w, b)=\\frac{1}{m} \\sum{i=1}^{m} \\mathcal{L}\\left(\\hat{y}^{(i)}, y^{(i)}\\right)=-\\frac{1}{m} \\sum{i=1}^{m} y^{(i)} \\log \\widehat{y}^{(i)}+\\left(1-y^{(i)}\\right) \\log \\left(1-\\hat{y}^{(i)}\\right) $$\n$$ \\text { Want to find } w, b \\text { that minimize } J(w, b) $$\nGradient Desent $$ \\begin{array}{l}\\text { Step } 1: \\frac{d L}{d a} \\ L=-(y \\times \\log (a)+(1-y) \\times \\log (1-a)) \\ \\frac{d L}{d a}=-y \\times \\frac{1}{a}-(1-y) \\times \\frac{1}{1-a} \\times-1\\end{array} $$\n$$ \\begin{align} \\dfrac{d}{dx} \\sigma(x) \u0026amp;= \\dfrac{d}{dx} \\left[ \\dfrac{1}{1 + e^{-x}} \\right] \u0026amp;= \\dfrac{d}{dx} \\left( 1 + \\mathrm{e}^{-x} \\right)^{-1} \u0026amp;= -(1 + e^{-x})^{-2}(-e^{-x}) \u0026amp;= \\dfrac{e^{-x}}{\\left(1 + e^{-x}\\right)^2} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{e^{-x}}{1 + e^{-x}} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{(1 + e^{-x}) - 1}{1 + e^{-x}} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( \\dfrac{1 + e^{-x}}{1 + e^{-x}} - \\dfrac{1}{1 + e^{-x}} \\right) \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( 1 - \\dfrac{1}{1 + e^{-x}} \\right) \u0026amp;= \\sigma(x) \\cdot (1 - \\sigma(x)) \\end{align} $$\n$$ \\begin{array}{l}\\text { In the previous video, Andrew refers to } d z=a(1-a) \\ \\text { Note that Andrew is using \u0026ldquo;dz\u0026rdquo; as a shorthand to refer to } \\frac{d a}{d z}=a(1-a) \\text { . } \\ \\text { To clarify, earlier in this week\u0026rsquo;s videos, Andrew used the name \u0026ldquo;dz\u0026rdquo; to refer to a different derivative: } \\frac{d L}{d z}=a-y . \\ \\text { Recall that the relationship between } \\frac{d L}{d z} \\text { and } \\frac{d a}{d z} \\text { is: } \\ \\frac{d L}{d z}=\\frac{d L}{d a} \\times \\frac{d a}{d z} \\ \\frac{d L}{d z}=\\frac{a-y}{a(1-a)} \\times a(1-a)=a-y\\end{array} $$\nVectorization Code For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $$ num_px $$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.\nExercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $$ num_px $$ 3, 1).\nA trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$$c$$d, a) is to use:\nX_flatten = X.reshape(X.shape[0], -1).T # X.T is the transpose of X  To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\nOne common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).\nLet\u0026rsquo;s standardize our dataset.\nNeural Network Shallow neural networks Representation X：竖方向 features\n横方向：training example\nActivation function：\n Sigmoid: 如果output是binary classification，可以考虑sigmoid function，一般nerver used tanh function： ReLU Rectified Linear Unit $a = \\max(0, z)$ : by default, 很多人用，faster，slope 1，or 0 Leaky ReLU  Why need non-linear activation functions Derivatives of activation functions Gradient descent for Neural Networks np.sum(keepdims=True): prevent rank one arrays\nBackpropagation intuition https://medium.com/@pdquant/all-the-backpropagation-derivatives-d5275f727f60\nhttps://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/3/threads/a38VuhyMEei5zw6yFhWyOg\nRandom Initialization LR can be initialized as 0, but not neural network\nSupplement 基础 graph LR; MachineLearning--\u0026gt;频率/统计机器学习; 频率/统计机器学习--\u0026gt;正则化/L1/L2 频率/统计机器学习--\u0026gt;核化 频率/统计机器学习--\u0026gt;集成化 频率/统计机器学习--\u0026gt;层次化 层次化--\u0026gt;MultiayerPercepton/MLP 层次化--\u0026gt;Autoencoder 层次化--\u0026gt;CNN 层次化--\u0026gt;RNN MachineLearning--\u0026gt;贝叶斯派/PGM 贝叶斯派/PGM--\u0026gt;BayesianNetwork/有向图 贝叶斯派/PGM--\u0026gt;MarkovNetwork/无向图 贝叶斯派/PGM--\u0026gt;MixedNetwork/有向图无向图 BayesianNetwork/有向图--\u0026gt;DeepDirectedNetwork DeepDirectedNetwork--\u0026gt;SigmoidBeliefNetwork DeepDirectedNetwork--\u0026gt;VAE DeepDirectedNetwork--\u0026gt;GAN MarkovNetwork/无向图--\u0026gt;DeepBoltzmannNetwork MixedNetwork/有向图无向图--\u0026gt;DeepBeliefNetwork  统计机器学习  正则化：Loss Function + regularizer(L1/L2)\n 核化: Kernel SVM\n 集成化: AdaBoost, RandomForest\n 层次化: Neural Network/Deep Neural Network\n MLP(Mutilayer Perceptron)\n Autoencoder\n CNN\n RNN\n   贝叶斯派  BayesianNetwork $\\Rightarrow$ Deep Directed Network  Sigmoid Belief Network Variational Autoencoder(VAE) GAN  Markov Network $\\Rightarrow$ Deep Boltzmann Network Mixed Netowork $\\Rightarrow$ Deep Belief Network   上述都是：Deep Generative Model\n 狭义的DeepLearning：Deep Neural Network\n其实应该包括：\n Deep Neural Network Deep Generative Model（当层次非常多，推断非常困难）  时间线  深度学习的理论在2006年已经成型，直到现在，理论并没有根本性突破。 为什么take off  data 分布式 硬件 GPU 效果   Non-Linear Problem Neural Network 符合运算-》复合表达式-〉复合函数\n人工智能 两大阵营 三大主义 Deep learning HMM-GMM 每个model就是一个state，但是DNN就是一个大的model。所有的state共用一个DNN。\n更加多层的DNN，其实会更少neurons，最终是更少的参数，不容易overfiting\n多层其实就是将空间对折了。\n","date":1585099595,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"80470b31effc764701791a977ec585e6","permalink":"https://faithio.cn/post/deep-learning/","publishdate":"2020-03-24T21:26:35-04:00","relpermalink":"/post/deep-learning/","section":"post","summary":"Neural Networks Basics Logistic Regression as a Neural Network $$ \\hat{y}=\\sigma\\left(w^{T} x+b\\right), \\text { where } \\sigma(z)=\\frac{1}{1+e^{-z}} \\ \\text { Given }\\left{\\left(x^{(1)}, y^{(1)}\\right), \\ldots,\\left(x^{(m)}, y^{(m)}\\right)\\right}, \\text { want } \\hat{y}^{(i)} \\approx y^{(i)} $$ Loss(error) function: Don\u0026rsquo;t use this, non-convex $$ \\ell(\\hat{y}, y)=\\frac{1}{2}(\\hat{y}-y)^{2} $$ The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. $$","tags":[],"title":"Deep Learning","type":"post"},{"authors":[],"categories":[],"content":" [pdf]\nclick here for link\n概率图模型  inference-\u0026gt; $P(Z|X)$-\u0026gt;积分问题（MCMC）\n GMM：样本之间是独立同分布\nHMM: Dynamic Model y: System state 隐变量\n state 离散：HMM state 线性: Kalman Filter state 非线性: Particle Filter  $$ \\begin{aligned} \\lambda \u0026amp;= (\\underbrace{\\pi}{初始prob dist}, \\underbrace{A}{状态转移矩阵}, \\underbrace{B}{发射矩阵emission}) \\pi\u0026amp;=\\left(\\pi, \\pi{2}, \\cdots, \\pi{N}\\right), \\sum{i=1}^{K} \\pi_{i}= 1 \\pi_i\u0026amp;= P\\left(i_1=q_i\\right) 状态变量i:\u0026amp; i_1, i_2, \\cdots i_t \\cdots \\rightarrow Q={q_1, q_2, \\cdots, q_m} 观测变量o:\u0026amp; o_1, o_2, \\cdots o_t \\cdots \\rightarrow V={v_1, v_2, \\cdots, vm} A\u0026amp;=\\left[a{i j}\\right], a{i j}=P\\left(i{t+1}=q_{i} | it=q{i}\\right) B\u0026amp;=\\left[b{j k} \\right], b{j k}=P\\left(Q{t}=v{k} | it=q{j}\\right) \\\n\\end{aligned} $$\n transition 和 emission probability 是independent\n 两个假设：\n 齐次Markov 假设\n $$ \\begin{aligned} \u0026amp;P(i_{t+1}|it, t{t-1}, \\cdots, t_1, ot, o{t-1}, \\dots, o1) = p(i{t+1}|i_t) \\end{aligned} $$\n 观察独立假设 $$ \\begin{aligned} \u0026amp;P(o_{t}|it, t{t-1}, \\cdots, t_1, ot, o{t-1}, \\dots, o1) = p(o{t}|i_t) \\end{aligned} $$\n  三个问题：\n Evaluation: $P(O| \\lambda) \\Rightarrow$ 前向后向 Forward-backward learning $\\lambda=\\arg \\max P(O|\\lambda)$ EM algorithm\\baum welch Decoding $\\lambda=\\arg \\max_{i} P(I|O)$  预测：$P(i_{t+1}|o_1, o_2, \\cdots, o_t)$ 滤波：$P(i_{t}|o_1, o_2, \\cdots, o_t)$   HMM-Evaluation $$ \\begin{aligned} Give \u0026amp;\\lambda, 求 P(O|\\lambda) P(O | \\lambda) \u0026amp;=\\sum{1} P(I, O | \\lambda)=\\sum{1} P(O | I, \\lambda) \\cdot P(I | \\lambda) \\\nP(I | \\lambda)\u0026amp;=P\\left(i{1}, i{2}, \\cdots, i{T} | \\lambda\\right)=\\underbrace{P\\left(i{T} | i, i{2},\\cdots,i{T-1}, \\lambda\\right)}_{P(iT|i{T-1})=a{i{T-1}, i_T}} P(i_1, i2, \\cdots, i{T-1}|\\lambda) = a{i{T-1}, iT} \\cdot a{i{T-2}, i{T-1}} \\cdots a{i{1}, i_{2}} \\cdot \\pi(i_1) \\\n\u0026amp;\\pi\\text{ 是初始分布} \u0026amp;= \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{t-1}, it} \u0026mdash;-\np(O | I, \\lambda) \u0026amp; =\\prod{t=1}^{T} b_{it}\\left(O{t}\\right) \\end{aligned} $$\nPPT $$ \\begin{array}{l}P(O | \\lambda)=\\sum{I} P(I, O | \\lambda)=\\sum{I} P(O | I, \\lambda) \\cdot P(I | \\lambda) \\ \\because P(I | \\lambda)=P\\left(i{1}, i{2} \\cdots i{T} | \\lambda\\right)=P\\left(i{i} | i{i}, i{i}, \\ldots{i-1}, \\lambda\\right) \\cdot P\\left(i{i}, i{2}, \\cdots i{t-1}, \\lambda\\right)=\\pi\\left(a{i1}\\right) \\cdot \\prod{t=2}^{T} a_{i-1, i}\n\\ P(0 | I, \\lambda)=\\prod{t=1}^{T} b{t}\\left(O_{t}\\right)\n\\ \\therefore P(O | \\lambda)=\\sum{1} \\pi\\left(a{i{1}}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i{i}}\\left(0{t}\\right)= \\underbrace{ \\sum{i{1}} \\sum{i{2}} \\cdots \\sum{i{T}} }{O(N^T)} \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i}\\left(O{t}\\right)\\end{array} $$\n前向算法 $$ \\begin{array}{l} \\\n\\alpha{t+1}(j) =P\\left(o{0}, \\cdots, o{t}, o{t+1}, i{t+1}=q{j} | \\lambda\\right) \\ =\\sum{i=1}^{N} P\\left(o{1}, \\cdots, o{t}, o{t+1}, i{t+1}=q{j}, i{t}=q{i} | \\lambda\\right) \\ =\\sum{i=1}^{N} P\\left(o{t+1} | o{1}, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{j}, \\lambda\\right) \\cdot P\\left(o1, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{j} | \\lambda\\right)\n\\ =\\sum{i=1}^{N} P\\left(o{t+1} | i{t+1}=q{j} \\right) \\cdot P\\left(o{1}, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{i} | x\\right)\n\\ =\\sum{i=1}^{N} P\\left(o{t+1} | i{t+1}=q{j}\\right) \\cdot P\\left(i{t+1}=q{j} | o{1}, \\cdots, o{t}, i{i}=q{i}, \\lambda\\right) \\cdot P\\left( o{1}, \\cdots, o{t}, i{i}=q{i} | \\lambda\\right)\n\\ =\\sum{i=1}^{N} \\underbrace{ P\\left(o{t+1} | i{t+1}=q{j}\\right)}_{bj(o{t+1})} \\cdot \\underbrace{P\\left(i{t+1}=q{j} | i{i}=q{i}, \\lambda\\right)}{a{ij}} \\alpha_t(i)\n\\end{array} $$\n后向算法 $$ \\begin{array}{l} \\\n\\text{状态：} \\ \\pi=\\left(\\pi, \\pi{2}, \\cdots, \\pi{N}\\right), \\sum{i=1}^{K} \\pi{i}= 1 \\\n\\begin{aligned}\n\u0026amp; P(o | x)=P(o, \\cdots , o_r| \\lambda)\n\\=\u0026amp; \\sum_{i=1}^{N} p\\left(o1, \\cdots, o{r}, i{1}=q{i} | \\lambda\\right)\n\\=\u0026amp; \\sum{i=1}^{N} p\\left(o{1}, \\cdots, o{r} | i{1}=q_{i}, \\lambda \\right) \\cdot \\underbrace{P(i_1=qi | \\lambda)}{\\pi_i}\n\\=\u0026amp; \\sum_{i=1}^{N} P\\left(o_1| o_2, \\cdots, o_r, i1=q{i}\\right) \\cdot P\\left( o_2, \\cdots, o_r | i1=q{i} \\right)\\cdot \\pi_i\n\\=\u0026amp; \\sum_{i=1}^{N} P\\left(o_1| i1=q{i}\\right) \\beta{1}(i) \\cdot \\pi{i}\n\\=\u0026amp; \\sum{i=1}^{N} b{i}(o1) \\pi{i} \\beta_{1}(i) \u0026mdash; \\\n\u0026amp; \\beta{t}(i)=P\\left(o{t+1}, \\cdots, o{T} | i{t}=q_{i}\\right)\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\cdots, o{T}, i{t+1}=q_{j} | it=q{i}\\right)\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\cdots, o{T} | i{t+1}=q{j}, t{t}=q{i}\\right) \\cdot \\underbrace{ P\\left(i{t-1}=q{j} | i{t}=q{i}\\right) }{a_{ij}}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\ldots, o{T} | i{t+1}=q{j}\\right) \\cdot a{ij}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1} | o{t+2}, \\cdots, o{T}, i{t+1}=q{j}\\right) \\cdot P\\left(o{t+1}, \\ldots, o{T} | i{t+1}=q{j}\\right) \\cdot a_{i j}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1} | t{t+1}=q{j}\\right) \\quad \\cdot \\quad \\beta{t+1}(j) \\quad \\cdot \\quad a{ij}\n\\ =\u0026amp; \\sum{j=1}^{N} b{j}\\left(o{t+1}\\right) \\cdot a{i j} \\cdot \\beta_{t+1}(j) \\end{aligned}\n\\end{array} $$\nEvaluation总结 $$ \\begin{array}{l}\n\\text{条件概率复杂度很高：} P(O | \\lambda)=\\sum{I} P(I, O | \\lambda) =\\underbrace{ \\sum{i{1}} \\sum{i{2}} \\cdots \\sum{i{T}} }{O(N^T)} \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i}\\left(O{t}\\right) \\\n\\alpha_{t}(i)=P(o_1, \\cdots, o_t, i_t=q_i | \\lambda) \\\n\\alpha{T}(i)=P\\left(O, i{T}=q_{i} | \\lambda\\right) \\\nP(O | \\lambda)=\\sum{i=1}^{N} \\alpha{T}(i) \u0026mdash;\n\\beta{t}(i)=P(o{t+1}, \\cdots, o_T |i_t=qi, \\lambda) \\beta{1}(i)=P(o_{2}, \\cdots, o_T |i_1=qi, \\lambda) P(O | \\lambda)=\\sum{i=1}^{N} \\pi{i} b{i}(o1) \\beta{1}(i)\n\\end{array} $$\n引入EM的思想 $$ \\begin{aligned}\n\\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \\\n\u0026amp; \\text{x: 观测值O z：隐变量I(discrete) } \\theta \\text{:参数 }\\lambda \\\n\\ \\lambda^{(t)}\u0026amp;=\\left(\\pi^{t}, A^{t}, B^{t}\\right) \\lambda^{(t+1)}\u0026amp; =\\arg \\max {\\lambda} \\sum{1} \\log P(O,I |\\lambda) \\cdot\n\\underbrace{P\\left(I|O, \\lambda^{(t)}\\right)}_{ P\\left(I|O, \\lambda^{(t)}\\right) = \\frac{P\\left(I,O| \\lambda^{(t)}\\right)}{P\\left(O, \\lambda ^{(t)}\\right)} }\n= \\arg \\max {\\lambda} \\sum{1} \\log P(O,I |\\lambda) \\cdot P\\left(O,I| \\lambda^{(t)}\\right) \\\nQ\\left(\\lambda, \\lambda^{(t))}\\right) \u0026amp;=\\sum_{T} \\log P(O,I | \\lambda) \\cdot P\\left(O, I | \\lambda^{(t)}\\right) \u0026amp;= \\sumI \\left[ \\left(\\log \\pi{i1} + \\sum{t=2}^{T} \\log a{i{t-1}, it} + \\sum{t=2}^{T} \\log b_{i_t} \\left(o_t \\right) \\right) P\\left(O,I|\\lambda^{(t) }\\right) \\right] \u0026amp; \\text{Now we only consider }\\pi \\\n\\pi^{(t+1)} \u0026amp;=\\arg \\max _{\\pi} Q\\left(\\lambda, \\lambda^{(t)}\\right)\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{I}\\left[\\log \\pi_{i_1}, P\\left(O,I | \\lambda^{(t)}\\right)\\right]\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{i1} \\cdots \\sum{i{T}}\\left[\\log \\pi{i1} \\cdot P\\left(O, i{1} \\cdots i_T | \\lambda^{(t)}\\right)\\right]\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{i{1}}\\left[\\log \\pi{i{1}} P\\left(O, i{1} | \\lambda^{(t)}\\right)\\right] \\\n\u0026amp;=\\arg \\max {\\pi} \\sum{i=1}^{N}\\left[\\log \\pi_{i} \\cdot P\\left(O, i_1=q_i |\\lambda^{(t)}\\right) \\right] \\\u0026amp; \\pi \\text{带约束，和为1} \\end{aligned} $$\n用lagrange multiplier $$ \\begin{array}{l}\n\\mathcal{L}(\\pi, \\eta)=\\sum{i=1}^{N} \\log \\pi{i} P\\left(O, i{1}=q{i} | \\lambda^{(t)}\\right)+\\eta\\left(\\sum{i=1}^{i} \\pi{i}-1\\right)\n\\ \\frac{\\partial f}{\\partial \\pii}=\\frac{1}{\\pi{i}} P\\left(O, i{1}=q{i} | \\lambda^{(t)}\\right)+\\eta=0 \\\n\\sum_{i=1}^{N} \\left[P\\left(O, i1=q{i} | \\lambda^{(t)}\\right)+\\pi_{i} \\eta \\right] =0 \\\nP\\left(O | \\lambda^{(t)}\\right)+\\eta=0 \\\n\\therefore \\eta = - P\\left(O, \\lambda^{(t)}\\right) \\\n\\pii = - \\frac{P\\left(O, i{1}=q_{i} | \\lambda^{(t)}\\right)}{\\eta} \\pii^{(t+1)} = \\frac{P\\left(O, i{1}=q_{i} | \\lambda^{(t)}\\right)}{P\\left(O, \\lambda^{(t)}\\right)} \\\n\\pi_i^{(t+1)} = \\left(\\pi_1^{(t+1)}, \\pi_2^{(t+1)}, \\cdots, \\pi_N^{(t+1)} \\right) \\end{array} $$\nDecoding $$ \\begin{aligned} \\delta_{t}(i) \u0026amp;=\\max _{i_1, i2, \\cdots, i{t+1} } P\\left(o_1,O_2, \\cdots, O_t, i_1, i2, \\cdots, i{t-1}, it=q{i}\\right) \\ \\delta{t+1}(j) \u0026amp;=\\max{i_1, i2, \\cdots, i{t+1} } P\\left(o_1,O_2, \\cdots, O_t, i_1, i2, \\cdots, i{t}, i{t+1}=q{i}\\right) \u0026amp;=\\max {1 \\leqslant i \\leq N} \\delta{t}(i) a{i j} b{j}\\left(O_{t+1}\\right) \\\n\u0026amp;\\text{上述式子只求出最大概率值，需要记录状态路径：} \\\n\\psi{t+1}(j) \u0026amp;=\\underset{1 \\leqslant i \\leqslant N}{\\arg \\max } \\delta{t}(i) \\cdot a_{ij}\n\\end{aligned} $$\nfiltering(Forward Algorithm) $$ P\\left(i{t} | o{1: t}\\right)=\\frac{P\\left(i{t}, o{1:t}\\right)}{P\\left(o{1:t}\\right)}=\\frac{P\\left(o{1:t}, it\\right)}{\\sum{it} P\\left(o{1:t}, it\\right)} \\propto P\\left(o{1:t}, i_t\\right) = \\alpha_i(t) $$\nsmoothing(Forward-backward Algorithm) $$ \\begin{aligned} P\\left(i{t} | o{1: T}\\right) \u0026amp;=\\frac{P\\left(i{t}, o{1:T}\\right)}{P\\left(o{1:T}\\right)}=\\frac{P\\left(o{1:T}, it\\right)}{\\sum{it} P\\left(o{1:T}, i_t\\right)} \\\nP\\left(o_{1:T}, it\\right) \u0026amp; = P\\left(o{1:t}, o_{t+1:T}, i_t\\right) \\\n\u0026amp; = \\underbrace{ P\\left(o{t+1:T}| o{1:t}, it\\right) }{ P\\left( o_{t+1:T}| i_t \\right)}\n\\underbrace{ P\\left( o_{1:t}, it\\right)}{\\alpha_t} \\\n\u0026amp;= \\beta_t \\cdot \\alpha_t \\\n\u0026amp; \\therefore P\\left(o_{1:T}, it\\right) \\propto P\\left( o{t+1:T}| i_t \\right) = \\alpha_t \\cdot \\beta_t \\end{aligned} $$\nprediction $$ \\begin{aligned} P\\left( i{t+1}|o{1:t} \\right) \u0026amp;= \\sum{i{t}} P\\left( i_{t+1}, it|o{1:t} \\right)\n\\\u0026amp;= \\sum{i{t}} \\underbrace{ P\\left( i_{t+1}| it,o{1:t} \\right)}{ P\\left( i{t+1}| i_t\\right) } \\underbrace{ P\\left( it|o{1:t} \\right) }_{filtering}\n\\end{aligned} $$\n$$ \\begin{aligned} P\\left( o{t+1}|o{1:t} \\right) \u0026amp;= \\sum{i{t+1}} P\\left( o{t+1}, i{t+ 1}|o_{1:t} \\right)\n\\\u0026amp;= \\sum{i{t+1}} \\underbrace{ P\\left( o{t+1}| i{t+1},o{1:t} \\right)}{ P\\left( o{t+1}| i{t+1}\\right) } \\underbrace{ P\\left( i{t+1}|o{1:t} \\right) }_{上一个prediction}\n\\end{aligned} $$\n","date":1585082750,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589829036,"objectID":"a26198dec54033211ebab263a5e00927","permalink":"https://faithio.cn/post/hmm/","publishdate":"2020-03-24T16:45:50-04:00","relpermalink":"/post/hmm/","section":"post","summary":"[pdf] click here for link 概率图模型 inference-\u0026gt; $P(Z|X)$-\u0026gt;积分问题（MCMC） GMM：样本之间是独立同分布 HMM: Dynamic Model y: System state 隐变量 state 离散：HMM state 线性: Kalman Filter","tags":[],"title":"HMM","type":"post"},{"authors":[],"categories":[],"content":" 语音识别 HMM Method 1:Tandem Method 2: DNN-HMM Hybrid ","date":1585068369,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585155865,"objectID":"4f4a6c327fba1cf1c0a126544a3a4547","permalink":"https://faithio.cn/post/nlp/","publishdate":"2020-03-24T12:46:09-04:00","relpermalink":"/post/nlp/","section":"post","summary":"语音识别 HMM Method 1:Tandem Method 2: DNN-HMM Hybrid","tags":[],"title":"NLP","type":"post"},{"authors":[],"categories":[],"content":" $$ \\begin{aligned} E{z|x}\\left[f(z)\\right] \u0026amp;= \\int P(z|x) f(z) dz \\ \u0026amp; \\approx \\frac{1}{N} \\sum{i=1}^N f(z_i) \\\u0026amp; z^{(1)}, z^{(2)}, \\cdots, z^{(N)} \\sim P(z|x) \\end{aligned} $$\n$$ \\frac{1}{N} \\sum_{i=1}^{N} f\\left(x^{(i)}\\right) \\stackrel{a . s}{\\rightarrow} \\int f(x) p(x) d x $$\n概率分布采样 Standard distributions PDF如果很复杂，CDF求不出来。\nRejection Sampling adaptive rejection sampling log P(x)是concave 才能使用。\nImportance Sampling 因为大部分采样得到的样本重要性很低，反之仅有少量的样本重要性非常大。\nSampling Importance Resampling\n$$ \\begin{array}{l}\\text { Our goal is to compute: } I(f)=\\int f(x) p(x) d x \\\n\\text { If we have a density } q(x) \\text { which is easy to sample from, we can sample } x^{(i)} \\stackrel{\\text { id }}{\\sim} q(x) \\text { Define the importance weight as: } w\\left(x^{(i)}\\right)=\\frac{p\\left(x^{(i)}\\right)}{q\\left(x^{(i)}\\right)} \\\n\\text { Consider the weighted Monte Carlo sum: } \\\n\\begin{array}{ll}\n\\frac{1}{N} \\sum{i=1}^{N} f\\left(x^{(i)}\\right) w\\left(x^{(i)}\\right) \u0026amp;= \\frac{1}{N} \\sum{i=1}^{N} f\\left(x^{(i)}\\right) \\frac{p\\left(x^{(i)}\\right)}{q\\left(x^{(i)}\\right)} \\\n\u0026amp; \\stackrel{a . s .}{\\rightarrow} \\int\\left(f(x) \\frac{p(x)}{q(x)}\\right) q(x) d x \\quad \\text{(Law of Large Numbers)} \\\n\u0026amp;= \\int f(x) p(x) d x\\end{array}\\end{array} $$\nMCMC 基于随机采样的近似方法\nMarkov Chain: 时间状态都是离散的。特殊的随机过程\n齐次（一阶）Markov Chain：未来只依赖于当前，和过去没有关系 ${xt}$ P为转移矩阵$[P{ij}]$ $$ P(X_{t+1} = x| x_1, x_2, \\cdots, xt) = P(X{t+1}|x_t) $$\n$$ P{i j} \\quad P{i j}=P\\left(X{i+1}=j | X{t=i}\\right) $$\ngraph LR; x1--\u0026gt;x2; x2--\u0026gt;x3; x3--\u0026gt;xt; xt--\u0026gt;xt+1;  平稳分布\n","date":1585028300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589841215,"objectID":"2e809b9eacbd8c09c0c32ead5e993a3d","permalink":"https://faithio.cn/post/markov-chain-monte-carlo/","publishdate":"2020-03-24T01:38:20-04:00","relpermalink":"/post/markov-chain-monte-carlo/","section":"post","summary":"$$ \\begin{aligned} E{z|x}\\left[f(z)\\right] \u0026amp;= \\int P(z|x) f(z) dz \\ \u0026amp; \\approx \\frac{1}{N} \\sum{i=1}^N f(z_i) \\\u0026amp; z^{(1)}, z^{(2)}, \\cdots, z^{(N)} \\sim P(z|x) \\end{aligned} $$ $$ \\frac{1}{N} \\sum_{i=1}^{N} f\\left(x^{(i)}\\right) \\stackrel{a . s}{\\rightarrow} \\int f(x) p(x) d x $$ 概率分布采样 Standard distributions PDF如果很复杂，CDF求不出来。 Rejection Sampling adaptive rejection sampling log P(x","tags":[],"title":"Markov Chain Monte Carlo","type":"post"},{"authors":[],"categories":[],"content":" 混合模型都是生成模型，N个样本，先生成x1，x2\n$$ \\begin{aligned} p(x) \u0026amp;= \\sumz P(x,z) \u0026amp;= \\sum{k=1}^z P(x, z=Ck) \u0026amp;= \\sum{k=1}^z p(z=C_k) \\cdot p(x|z=Ck) \u0026amp;= \\sum{k=1}^z p_k \\mathcal{N}(x| \\mu_k, \\Sigma_k) \\end{aligned} $$ $$ \\log (\\Delta + \\Delta + \\Delta ) \\rightarrow \\text{连加符号很难求导，令导数为0，连乘比较方便} \\text{单变量的高斯分布可以直接用MLE求出来} $$\n用EM求解 $$ \\text{ E-Step: } P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\\n\\text{ M-Step: } \\theta^{(t+1)}=\\arg \\max {\\theta} \\underbrace{ E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]}_{Q(\\theta, \\theta^{(t)})} \\\n\\text{E-step:} \\\nQ(\\theta, \\theta^{(t)}) = \\int_z \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \\text{独立同分布} = \\sumz \\log \\prod{i=1}^N P(x_i, z_i|\\theta) \\cdot \\sumz \\log \\prod{i=1}^N P(z_i|xi, \\theta^{(t)})\n=\\sum{z_{1} z2 \\cdots z{N}} \\sum{i=1}^{N} \\log P\\left(x{i} z{i} | \\theta\\right) \\cdot \\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) \\\n=\\sum{z{1} z2 \\cdots z{N}} \\left[\\log P\\left(x{1}, z{1} | \\theta\\right)+\\log P\\left(x{2}, z{2} | \\theta\\right)+\\cdots+\\log P\\left(x{N}, z{N} | \\theta\\right)\\right] \\cdot \\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) + \\cdots + \\sum{z{N}} \\log p\\left(x{N}, z{N} | \\theta\\right) \\cdot p\\left(z{N} | x{N}, \\theta\\right) =\\sum{i=1}^{N} \\sum_{zi} \\log p\\left(x{i}, z{i} | \\theta\\right) \\cdot p\\left(z{i} | x_{i}, \\theta^{(i)}\\right) \\\n=\\sum{i=1}^{N} \\sum{z{i}} \\log p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z{i}}\\right) \\cdot \\frac{p{z{i}} \\cdot \\mathcal{N}\\left(x{i} | \\mu{i}, \\Sigma{i}\\right)}{\\sum{k=1}^{K} p{x} \\mathcal{N}\\left(x{i} | \\mu_{k}, \\Sigmak\\right)} \u0026mdash; \\begin{aligned} P(x, z) \u0026amp;=P(z) \\cdot p(x | z) \\ \u0026amp;=p{z} \\cdot N\\left(x | \\mu{z}, z{z}\\right) \\ p(z | x) \u0026amp;=\\frac{p(x, z)}{p(x)}=\\frac{p{z} \\cdot \\mathcal{N}\\left(x | \\mu{z} \\Sigma{z}\\right)}{\\sum{k=1}^{K} p{k} \\cdot \\mathcal{N}\\left(x | \\mu{k}, \\Sigma_{k}\\right)} \\end{aligned} $$\n$$ \\text{取第一项} \\sum{z{1} z2 \\cdots z{N}} \\log p\\left(x{1}, z{1} |\\theta\\right) \\cdot \\underbrace{\\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right)}{ p\\left(z_1,\\left|x1, \\theta^{(t)}\\right) \\cdot \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right)\\right. } \\\n=\\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) \\sum_{z_2 \\cdots zN} \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) \u0026mdash;- \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\prod{i=2}^{N} P(z_2|x_2)P(z_3|x_3)\\cdots P(z_N|xN) = \\sum{z_2}P(z_2|x2)\\cdot \\sum{z_3}P(z_3|x3)\\cdot \\cdots \\sum{z_N}P(z_N|x_N) = 1 $$\nE-Step: $$ \\text{ M-Step: } \\theta^{(t+1)}=\\arg \\max {\\theta} \\underbrace{ E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]}_{Q(\\theta, \\theta^{(t)})} \\begin{aligned} Q(\\theta, \\theta^{(t)}) \u0026amp;= \\intz \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \u0026amp;=\\sum{i=1}^{N} \\sum{z{i}} \\log p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z{i}}\\right) \\cdot \\underbrace{ \\frac{p{z{i}} \\cdot \\mathcal{N}\\left(x{i} | \\mu{i}, \\Sigma{i}\\right)}{\\sum{k=1}^{K} p{x} \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigmak\\right)} }{P(z_i|x_i, \\theta^{(t)}) \\rightarrow \\theta^{(t)} \\text{ is a constant.}} \\\n\u0026amp;= \\intz \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \u0026amp;=\\sum{i=1}^{N} \\sum{z{i}} \\log [p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z_{i}}\\right)] \\cdot P(z_i|xi, \\theta^{(t)}) \u0026amp;= \\sum{z{i}} \\sum{i=1}^{N} \\log [p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z_{i}}\\right)] \\cdot P(z_i|xi, \\theta^{(t)}) \u0026amp;= \\sum{k=1}^{k} \\sum{i=1}^{N} \\log [p{k} \\cdot \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigma{k}\\right)] \\cdot p\\left(z{i}=C{k} | x{i}, \\theta^{(t)}\\right) \\\n\u0026amp;= \\sum{k=1}^{k} \\sum{i=1}^{N} [\\log p{k} + \\log \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigma{k}\\right)] \\cdot p\\left(z{i}=C{k} | x_{i}, \\theta^{(t)}\\right) \\end{aligned} $$ 求 $p_k^{t+1} = (p_1^{t+1}, p_2^{t+1}, \\cdots, pk^{t+1})$ $$ \\left{ \\begin{array}{l} p{k}^{(k+1)}=\\operatorname{argmax}{p{k}} \\sum{k=1}^{k} \\sum{i=1}^{N} \\log p{k} \\cdot p\\left(z{i} = Ck | x{i}, \\theta^{(t)}\\right) s.t. \\sum{k=1}^{k} p{k}=1 \\end{array} \\right. $$ 用拉格朗日乘子法： $$ \\mathcal{L}(p, \\lambda)=\\sum{k=1}^{K} \\sum{i=1}^{N} \\log p{k} \\cdot p\\left(z{i}=C{k} | x{i}, \\theta^{(t)}\\right)+\\lambda(\\sum_{k=1}^k - 1) $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p{k}}= \\sum{i=1}^{N} \\frac{1}{p{k}} \\cdot p\\left(z{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)+\\lambda \\triangleq 0 \\rightarrow \\sum{i=1}^{N} \\cdot p\\left(z{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)+p_k \\lambda = 0 \\\n\\Rightarrow^{(k=1,\\cdots , K)} \\sum{i=1}^{N} \\underbrace{\\sum{i=1}^K \\cdot p\\left(z_{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)}1 + \\underbrace{\\sum{i=1}^K p_k}_1 \\lambda \\Rightarrow N+ \\lambda = 0 \\Rightarrow \\lambda = -N $$\n$$ p{k}^{(t+1)}=\\frac{1}{N} \\sum{i=1}^{N} p\\left(z{i}=C{k} | x_{i}, \\theta^{(t)}\\right) $$\n","date":1585021364,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585028218,"objectID":"1ae0708a82dfe0be1cc5160b25eca272","permalink":"https://faithio.cn/post/gaussian-mixture-model/","publishdate":"2020-03-23T23:42:44-04:00","relpermalink":"/post/gaussian-mixture-model/","section":"post","summary":"混合模型都是生成模型，N个样本，先生成x1，x2 $$ \\begin{aligned} p(x) \u0026amp;= \\sumz P(x,z) \u0026amp;= \\sum{k=1}^z P(x, z=Ck) \u0026amp;= \\sum{k=1}^z p(z=C_k) \\cdot p(x|z=Ck) \u0026amp;= \\sum{k=1}^z p_k \\mathcal{N}(x| \\mu_k, \\Sigma_k) \\end{aligned} $$ $$ \\log (\\Delta + \\Delta + \\Delta ) \\rightarrow \\text{连加符号很难求导","tags":[],"title":"Gaussian Mixture Model","type":"post"},{"authors":[],"categories":[],"content":" click here for link\n$MLE: P(X|\\theta)$\n$$ \\begin{aligned} \\theta_{MLE} \u0026amp;=\\arg \\max _{\\theta} \\log P(X | \\theta) \\\n\\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \u0026amp;= \\arg \\max {\\theta} E{\\mathbf{Z} | x \\theta^{t}}[\\log P(x, z | \\theta)] \\\n\\text{ E-Step: } \u0026amp; P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\\n\\text{ M-Step: } \u0026amp;\\theta^{(t+1)}=\\arg \\max {\\theta} E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]\n\\end{aligned} $$\n需要证明一定会收敛Convergence $$ \\theta^{(t)} \\rightarrow \\theta^{(t+1)} \\log p\\left(x | \\theta^{(t)}\\right) \\leqslant \\log p\\left(x | \\theta^{(t+1)}\\right) $$\n$$ \\frac{P(x, z | \\theta)}{P(z | x)} \\\n\\log P(x | \\theta)=\\log P(x, z | \\theta)-\\log P(z | x, \\theta) \\\n\\begin{aligned} left \u0026amp;=\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(x | \\theta) d z \\ \u0026amp;=\\log P(x | \\theta) \\underbrace{ \\int{z} P\\left(z | x, \\theta^{(t)}\\right) d z }_1 \\ \u0026amp;= \\log P(x | \\theta) \\end{aligned} \\\nright =\\underbrace{\\int{\\mathbb{Z}} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log P(x, z | \\theta) d z}{Q\\left(\\theta, \\theta^{(t)}\\right)} -\\underbrace{\\int{\\mathbb{Z}} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(z | x, \\theta) d z}{H\\left(\\theta, \\theta^{(t)}\\right)}\\\nQ\\left(\\theta^{(t+1)}, \\theta^{(t)}\\right) \\geqslant Q\\left(\\theta^{(t)}, \\theta^{(t)}\\right) \\\n\\begin{aligned} \u0026amp; H\\left(\\theta^{(t+1)} \\cdot \\theta^{(t)}\\right)-H\\left(\\theta^{(t)} \\cdot \\theta^{(t)}\\right) \\ \u0026amp;=\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p\\left(z | x \\theta^{(t+1)}\\right) d z \\ \u0026amp;-\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p\\left(z | x, \\theta^{(t)}\\right) d z \\\u0026amp; = \\int_{z} P\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log \\frac{p\\left(z | x, \\theta^{(t+1)}\\right)}{p\\left(z | x, \\theta^{(t)}\\right)} d z \\ \u0026amp; = -\\mathcal{KL}\\left(P(z | x, \\theta^{(t)}) | p\\left(z | x, \\theta^{(t+1)}\\right) \\right) \\ \u0026amp; \\leqslant 0\n\\end{aligned} \\\n\\begin{aligned} \u0026amp; E[\\ln x] \\leqslant \\log E[x] \\ \\leqslant \\log \\underbrace{\\int_{z} p\\left(z|x, \\theta^{(t+ 1)}\\right) d z}_1=\\log 1=0\n\\end{aligned} $$\n$$ p(x, z)=p(z | x) \\cdot p(x) \\log p(x) = \\log \\frac{p(x, z)}{p(z | x) } = \\log p(x, z) - \\log p(z | x)\nadd \\quad \\theta \u0026mdash;\n\\log P(x | \\theta)=\\log P(x, z | \\theta)-\\log P(z | x, \\theta) =\\log \\frac{P(x, z | \\theta)}{q(z)}-\\log \\frac{P(z | x, \\theta)}{q(z)} \\quad q(z) \\neq 0 \\text{左右两边对于} q(z) \\text{求期望} left = \\int{z} q(z) \\cdot \\log p(x | \\theta) d z=\\log p(x | \\theta) \\cdot \\underbrace{\\int{z} q(z) d z}{1}=\\log p(x | \\theta) rigth = \\underbrace{ \\int{z} q(z) \\log \\frac{p(x, z | \\theta)}{q(z)} d z}{ELBO: evidence lower bound} \\underbrace{ - \\int{z} q(z) \\log \\frac{p(z | x, \\theta)}{q(z)} d z}_{\\mathcal{KL}(q(z) | p(z | x, \\theta)} \\log p(x | \\theta)=ELBO+ KL(q|p) \\log p(x | \\theta) \\geqslant ELBO \\text{maximize ELBO, then posterior maximize, 最大化ELBO(期望)， 然后更新后验概率的参数} \\theta $$\n$$ \\hat{\\theta}=\\arg \\max _{\\theta} E L B O = \\arg \\max _{\\theta} \\int q(z) \\log \\frac{p (x, z|\\theta)}{q(z)} d z\n当\\log p(x | \\theta) \\geqslant ELBO 取等于号(KL=0)，q(z) = p(z|x, \\theta^{(t)}) =\\arg \\max _{\\theta} \\int p\\left(z | x, \\theta^{(t)}\\right) \\log \\frac{p(x, z | \\theta)}{p\\left(z | x,\\theta^{(t)}\\right)} d z =\\arg \\max {\\theta} \\int p\\left(z | x, \\theta^{(t)}\\right) \\left[ \\log p(x, z | \\theta) - \\underbrace{ \\log p\\left(z | x,\\theta^{(t)}\\right)}{与\\theta无关，已经变成常数} \\right]dz = \\arg \\max {\\theta} \\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(x, z | \\theta) d z\n$$\n新的角度推导EM $$ \\begin{aligned} \\log P(x|\\theta) \u0026amp; = \\log \\intz P(x, z| \\theta) \u0026amp; = \\log \\int{z} \\frac{P(x, z | \\theta)}{q(z)} \\cdot q(z) d z \u0026amp; = \\log E{q(z)}\\left[\\frac{p(x, z | \\theta)}{q(z)}\\right] \u0026amp; \\text{use jensen inequalty} \u0026amp; \\geqslant E{q(z)}\\left[\\log \\frac{p(x, z | \\theta)}{q(z)}\\right] \\rightarrow ELBO \u0026amp; \\Leftrightarrow \\frac{P(x, z | \\theta)}{q(z)}=C q(z) \u0026amp; =\\frac{1}{c} p(x, z | \\theta) 1 =\\intz q(z) d z \u0026amp;=\\int{z} \\frac{1}{c} p(x, z | \\theta) d z \u0026amp; =\\frac{1}{c} \\int_{x} p(x, z | \\theta) d z 1 \u0026amp; =\\frac{1}{c} P(x | \\theta) c \u0026amp; =P(x | \\theta) \\end{aligned} $$\n$$ q(z)=\\frac{1}{p(x | \\theta)} \\cdot p(x, z | \\theta)=p(z | x, \\theta) $$\n$$ t \\in[0.1] c= ta+ (1-t)b f\u0026copy; =f(ta+ (1-t)b) \\geqslant tf(a) + (1-t)f(b) $$\n$$ \\begin{array}{l}x(t)=x{1}+t\\left(x{2}-x{1}\\right) \\ y(t)=f\\left(x{1}\\right)+t\\left(f\\left(x{2}\\right)-f\\left(x{1}\\right)\\right) \\ t \\in \\mathbb{R}\\end{array} \\begin{array}{l}\\text { Combining like terms and replacing } t \\text { with }(1-t) \\text { (which is fine since } t \\text { is an arbitrary parameter; } \\ \\text { furthermore } 0 \\leq 1-t \\leq 1 \\Longleftrightarrow 0 \\leq t \\leq 1 \\text { ), we can write the secant line as the set of } \\ \\text { points } \\ \\qquad \\begin{array}{l}x(t)=t x{1}+(1-t) x{2} \\ y(t)=t f\\left(x{1}\\right)+(1-t) f\\left(x{2}\\right) \\ t \\in \\mathbb{R}\\end{array}\\end{array}\n$$ http://www.gtmath.com/2016/03/convexity-and-jensens-inequality.html\n广义EM 概率生成模型问题，通过z生成x，然后再通过积分把z消掉。参数learning问题\ngraph LR; z--\u0026gt;x;  $$ \\hat{\\theta} = \\arg \\max _{\\theta} \\log P(X|\\theta)\n= \\arg \\max {\\theta} \\log \\prod{i=1}^N P(x_i|\\theta) $$\n$$ \\log P(x | \\theta)=E L B O+K L(q | p) \\left{\\begin{array}{l}E L B O=E_{q(z)}\\left[\\log \\frac{p(x, z | \\theta)}{q(z)}\\right] \\ KL(q | p)=\\int q(z) \\cdot \\log \\frac{q(z)}{p(z | x, \\theta)} d z\\end{array}\\right. \\\n\\text{E-step: 固定 }\\theta \\rightarrow \\hat{q}=\\arg \\min _{q} K L(q | p)=\\arg \\max_q \\mathcal{L}(q, \\theta) \\text{M-step: 固定 }\\hat{q} \\rightarrow \\theta=\\arg \\max _{\\theta} \\mathcal{L}(\\hat{q}, \\theta) $$\n$$ \\left{\\begin{array}{l} \\text { E-stes: } q^{(t+1)}=\\arg \\max _{q} \\mathcal{L}\\left(q, \\theta^{(t)}\\right) \\ \\text { M-step: } \\theta^{(t+1)}=\\arg \\max _{\\theta} \\mathcal{L}(q^{t+1}, \\theta) \\end{array}\\right. $$\n所以EM也叫MM算法，轮流迭代q and $\\theta$\nSMO：坐标上升法/梯度上升法\nM步和E步其实可以交换\nE-Step 其实是求后验概率，假如intractable 然后用VI求出后验 就叫VBEM/VEM，如果用MC求后验那就是MCEM\nVI \u0026lt;=\u0026gt; VB\n既然是优化问题，能否用梯度的方法求解呢？\n","date":1584676534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589823101,"objectID":"9ea6f7a01fddd5d96157297ddf58bdd4","permalink":"https://faithio.cn/post/expectation-maximization/","publishdate":"2020-03-19T23:55:34-04:00","relpermalink":"/post/expectation-maximization/","section":"post","summary":"click here for link $MLE: P(X|\\theta)$ $$ \\begin{aligned} \\theta_{MLE} \u0026amp;=\\arg \\max _{\\theta} \\log P(X | \\theta) \\ \\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \u0026amp;= \\arg \\max {\\theta} E{\\mathbf{Z} | x \\theta^{t}}[\\log P(x, z | \\theta)] \\ \\text{ E-Step: } \u0026amp; P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\ \\text{ M-Step: } \u0026amp;\\theta^{(t+1)}=\\arg \\max {\\theta} E{z|x,","tags":[],"title":"Expectation Maximization","type":"post"},{"authors":[],"categories":[],"content":" click here for link\nCommon X: data\n$X=\\left(x_1, x_2 \\cdots xN\\right){N \\times p}^{T}$ $$ \\theta = \\left(\\begin{array}{cccc}x{0} \u0026amp; x{a} \u0026amp; \\ldots \u0026amp; x{1 x} \\ x{1} \u0026amp; x{12} \u0026amp; \\ldots \u0026amp; x{21} \\ \\vdots \u0026amp; \u0026amp; \u0026amp; x{n y} \\ x{m} \u0026amp; x_{n x} \u0026amp; \\ldots \u0026amp; \\end{array}\\right) $$\n频率（统计机器学习） 优化问题 $$ x \\sim p(x | \\theta) $$ $\\theta$ 未知常量， X：r v $$ MLE：\\theta_{M L E}=\\arg \\max _\\theta \\log P(X | \\theta) $$\n贝叶斯(概率图模型) 求积分（MCMC）\n$\\theta$ r v， $$ \\theta \\sim p(\\theta) $$\n$$ P(\\theta | x)=\\frac{P(x | \\theta) \\cdot P(\\theta)}{P(x)} \\propto P(x | \\theta) \\cdot P(\\theta) P(x) = \\int_{\\theta} P(x | \\theta) \\cdot P(\\theta) d \\theta $$\n$$ MAP: \\theta_{MAP}=\\arg \\max _{\\theta} P(\\theta | x)=\\arg \\max _{\\theta} P(x | \\theta) \\cdot P(\\theta) $$\nBias and Variance Avoid overfiting book  李航 统计学习方法（频率派）感K朴决逻， 支提E隐条 周志华 “西瓜书” PRML 回分神核稀 图混近采连 顺组 - 贝叶斯 MLAPP 贝叶斯 ESL 频率派 Deep Learning 圣经/张志华翻译  高斯分布 马氏距离/欧氏距离\n$X^TAX$ : 欧氏距离，中间是单位矩阵，马氏距离，中间是协方差矩阵（其实是二次型）\n","date":1584659753,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"bc2fa12456182893105148befb3b4799","permalink":"https://faithio.cn/post/foundation-of-machine-learning/","publishdate":"2020-03-19T19:15:53-04:00","relpermalink":"/post/foundation-of-machine-learning/","section":"post","summary":"click here for link Common X: data $X=\\left(x_1, x_2 \\cdots xN\\right){N \\times p}^{T}$ $$ \\theta = \\left(\\begin{array}{cccc}x{0} \u0026amp; x{a} \u0026amp; \\ldots \u0026amp; x{1 x} \\ x{1} \u0026amp; x{12} \u0026amp; \\ldots \u0026amp; x{21} \\ \\vdots \u0026amp; \u0026amp; \u0026amp; x{n y} \\ x{m} \u0026amp; x_{n x} \u0026amp; \\ldots \u0026amp; \\end{array}\\right) $$ 频率（统计机器学习） 优化问题 $$ x \\sim p(x | \\theta) $$","tags":[],"title":"Foundation of Machine Learning","type":"post"},{"authors":[],"categories":[],"content":"Approximate Inference.pdf\nApproximate Inference.html\n","date":1584656517,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"42e77f450ce9f46625dae22d128fa311","permalink":"https://faithio.cn/post/approximate-inference/","publishdate":"2020-03-19T18:21:57-04:00","relpermalink":"/post/approximate-inference/","section":"post","summary":"Approximate Inference.pdf\nApproximate Inference.html","tags":[],"title":"Approximate Inference","type":"post"},{"authors":[],"categories":[],"content":"Exponential.pdf\nExponential.html\n","date":1584656503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584657777,"objectID":"b00c82fc12ffaf3b2f6fd5dba8d770b8","permalink":"https://faithio.cn/post/the-exponential-family/","publishdate":"2020-03-19T18:21:43-04:00","relpermalink":"/post/the-exponential-family/","section":"post","summary":"Exponential.pdf\nExponential.html","tags":[],"title":"The Exponential Family","type":"post"},{"authors":[],"categories":[],"content":" pdf\ngraph TD; 概率图--\u0026gt;Representation-表示; 概率图--\u0026gt;Inference-推断; 概率图--\u0026gt;Learning-学习; Representation-表示--\u0026gt;有向图BayesianNetwork; Representation-表示--\u0026gt;高斯图-连续; Representation-表示--\u0026gt;无向图MarkovNetwork; 高斯图-连续--\u0026gt;GaussianBN; 高斯图-连续--\u0026gt;GaussianMN; Inference-推断--\u0026gt;精确推断; Inference-推断--\u0026gt;ApproximateInference; ApproximateInference--\u0026gt;DeterministicApproximation(Variantional Inference); ApproximateInference--\u0026gt;StochasticcApproximation(MCMC); Learning-学习--\u0026gt;参数学习; Learning-学习--\u0026gt;结构学习; 参数学习--\u0026gt;完备数据; 参数学习--\u0026gt;隐变量; 隐变量--\u0026gt;EM;  $$ \\begin{array}{l} \\text{Sum Rule: } P(x_1)=\\int P\\left(x_1, x2\\right) d x{2} \\ \\text{Product Rule: } P\\left(x1, x{2}\\right)=P\\left(x_{1}\\right) \\cdot P\\left(x_2 | x1\\right)=P\\left(x{2}\\right) \\cdot P\\left(x{1} | x{2}\\right)\n\\end{array} $$\nChain Rule:\nBayesian Network  拓扑排序构建图\n graph TD; a--\u0026gt;b; a--\u0026gt;c;   $$ Chain Rule: P\\left(x{1}, x{2}, \\cdots, x{p}\\right)=P\\left(x{1}\\right) \\cdot \\prod{i=2}^{p} p\\left(x{i} | x_{1:i-1}\\right) P(a, b, c) = P(a)P(b|a)(c|a) \\rightarrow 因子分解\nP(a, b, c) = P(a)P(b|a)(c|a,b) \\rightarrow Chain rule\nP(c | a)=P(c | a, b) \\Rightarrow c \\perp b | a p(c | a) \\cdot p(b | a)=p(c|a,b) \\cdot p(b | a)=p( b, c | a) p(c | a) \\cdot p(b | a)=p(b, c | a) $$\nTail to tail, 若a被观测，则路径被堵塞$tail \\rightarrow head$\ngraph LR; a--\u0026gt;b; b--\u0026gt;c;  head to tail $$ P(a,b, c) = P(a)P(b|a)P(c|b) P(a, b, c) = P(a) P(b|a) P(c|a,b) P(c|b) = P(c|a,b) $$\n$$ a \\perp c | b $$ 若b被观测，则路径被阻塞（independent）\ngraph TD; a--\u0026gt;c; b--\u0026gt;c;  head to head\n默认情况下，$a \\perp b$，路径阻塞的\n若c被观测，则路径是通的 $$ P(a, b, c)=P(a) \\cdot P(b) \\cdot P(c | a, b) P(a, b, c) = P(a)\\cdot P(b|a) \\cdot (c|a,b) P(b) = P(b|a) $$\nInference $$ \\begin{aligned} \\text { sum rule } \u0026amp; p(X)=\\sum_{Y} p(X, Y) \\ \\text { product rule } \u0026amp; p(X, Y)=p(Y | X) p(X) \\end{aligned} $$ 求概率： $ P(x)=P\\left(x_0, x_1, \\cdots, x_p\\right) $\n边缘概率marginal probability： $$ P\\left(x{i}\\right)=\\sum{x1} \\cdot \\sum{x{i-1}} \\sum{x{i+1}} \\ldots \\sum{x_{p}} p(x) $$ 条件概率conditional probability： $$ P\\left(x_A | x_B\\right) \\quad x=x_A \\cup x_B $$ MAP Inference: $$ \\hat{z}=\\arg \\max _{z} P(z | x) \\propto \\arg \\max P(z, x) $$\ngraph LR; Inference--\u0026gt;精确推论; Inference--\u0026gt;近似推断; 精确推论--\u0026gt;variableElimination/VE; 精确推论--\u0026gt;BeliefPropagation/SumProductAlgorithm树结构; 精确推论--\u0026gt;JunctionTreeAlgorithm普通图结构BasedBP; 近似推断--\u0026gt;LoopBeliefPropagation有环图BasedBP; 近似推断--\u0026gt;MenteCarloInference:ImportanceSampling,MCMC; 近似推断--\u0026gt;VariationalInference  Variable Elimination-乘法分配律 $$ M A P \\quad \\tilde{X}_{A}=\\arg \\max {X} P\\left(x{A} | x{B}\\right)=\\arg \\max P\\left(x{A}, x_{B}\\right) $$\ngraph LR; a--\u0026gt;b; b--\u0026gt;c; c--\u0026gt;d;  假设a,b,c,d均是离散的二值r,v {0,1}\n$$ p(d) = \\sum_{a, b, c} p(a, b, c, d) \\\n= \\sum_{a, b, c} p(a) \\cdot p(b | a) \\cdot p(c | b) \\cdot p(d | c) \\\n= p(a=0) \\cdot p(b=0 | a=0) \\cdot p(c=0 | b=0) \\cdot p(d=0|c=0) + p(a=1) \\cdot p(b=0 | a=1) \\cdot p(c=0 | b=0) \\cdot p(d=0|c=0) \\\n \\cdots  p(a=1) \\cdot p(b=1 | a=1) \\cdot p(c=1 | b=1) \\cdot p(d=1|c=1) = \\sum{b, c} p(c | b) \\cdot p(d | c) \\cdot \\underbrace{\\sum{a} p(a) \\cdot p(b | a)}_{\\phi_a(b)}   = \\sumc p(d | c) \\cdot \\underbrace{\\sum{b} p(c | b)\\cdot \\phia(b) }{\\phi_b\u0026copy;} = \\phi_c(d) $$ 乘法对加法的分配律$ab+cb = b(a+c)$\nCons:\n Memoryless.重复计算 Ordering NP-hard  Belief Propagation graph LR; a--\u0026gt;b; b--\u0026gt;c; c--\u0026gt;d; d--\u0026gt;e;  $$ \\text{ Forward Algorithm} P(a, b, c, d, e)=P(a) P(b | a) \\cdot P(c | b) \\cdot P(d | c) \\cdot P(e|d) P(e)=\\sum{a, b,c, d} P(a, b, c, d, e) =\\sum{d} p(e | d) \\sum{c} p(d | c) \\underbrace{ \\sum{b} p(c | b) \\underbrace{ \\sum{a} p(b | a) p(a) }{m{a\\rightarrow b }(b)}}{m_{b \\rightarrow c}\u0026copy;} $$\n$$ p\u0026copy;=\\sum{a, b, d, e} p(a, b, c, d, e) = \\left(\\sum{b} p(c | b) \\cdot \\sum{a} p(b | a) \\cdot p(a) \\right) \\left(\\sum{d} p(d | c) \\sum_{e} p(e | d)\\right)\n\n\\text{ Forward-Backward Algorithm} $$\ngraph TD; a---b; b---d; b---c;  $$ \\begin{aligned} \u0026amp; p(a, b, c, d) \\=\u0026amp; \\frac{1}{z} \\psi{a}(a) \\psi{b}(b) \\cdot \\psi{c}\u0026copy; \\cdot \\varphi(d) \\ \u0026amp; \\cdot \\psi{a, b}(a, b) \\cdot \\psi{b, c}(b, c) \\cdot \\psi{b, d}(b, d) \\end{aligned} $$\n","date":1584654998,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584678125,"objectID":"97dc121d7ddd7c67d1b89d3e4f7cf1a1","permalink":"https://faithio.cn/post/probabilistic-graphical-model/","publishdate":"2020-03-19T17:56:38-04:00","relpermalink":"/post/probabilistic-graphical-model/","section":"post","summary":"pdf graph TD; 概率图--\u0026gt;Representation-表示; 概率图--\u0026gt;Inference-推断; 概率图--\u0026gt;Learning-","tags":[],"title":"Probabilistic Graphical Model","type":"post"},{"authors":[],"categories":[],"content":"When I run some python code from github, it occur the following problem as screenshot.\n RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of \u0026lsquo;python\u0026rsquo; with \u0026lsquo;pythonw\u0026rsquo;. See \u0026lsquo;Working with Matplotlib on OSX\u0026rsquo; in the Matplotlib FAQ for more information.\n Solution:(https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python)\nProblem Cause In mac os image rendering back end of matplotlib (what-is-a-backend to render using the API of Cocoa by default). There is Qt4Agg and GTKAgg and as a back-end is not the default. Set the back end of macosx that is differ compare with other windows or linux os.\nI resolve this issue following ways:\n I assume you have installed the pip matplotlib, there is a directory in you root called ~/.matplotlib. Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg  From this link you can try different diagram.\n","date":1583775429,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583802329,"objectID":"f401314725b6ff0b004bf2f679a80813","permalink":"https://faithio.cn/post/run-issue-with-matplotlib-in-mac-os-x/","publishdate":"2020-03-09T13:37:09-04:00","relpermalink":"/post/run-issue-with-matplotlib-in-mac-os-x/","section":"post","summary":"When I run some python code from github, it occur the following problem as screenshot.\n RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends.","tags":[],"title":"Run Issue With Matplotlib in Mac OS X","type":"post"},{"authors":[],"categories":[],"content":" Math Formula Factor graphs Shows how a function of several variables can be factored into a product of simpler functions.\n $$ f(x,y,z) = (x+y) \\cdot (y + z) \\cdot (x +z) $$\n Very useful for representing posteriors.\n$ $$ P(x1, ..., x_n) = P(x_1) \\Pi P( x_i | x_{i-1} ) $$ $\n$$ P(m|x1, \u0026hellip;, x_n) = P(m) \\cdot \\Pi P(x_i|m)$$\nmodeling  What graph should I use for this data?  Inference  Given the graph and data, what is the mean of x algorithm  Sampling Variable elimination Message-passing(Expectation Propagation, Variational Bayes)   Cutter problem  Want to estimate x given multiple y\u0026rsquo;s $$ p(x) = \\mathcal{N}(x; 0, 100) $$ $$ p(y_i|x) = (0.5)\\mathcal{N}(y_i; x, 1) + (0.5)\\mathcal{N} (y_i;0,10)$$  -\u0026gt; $ P(x|y1, \u0026hellip;, y_n) = P(x) \\cdot \\Pi P(y_i|x)$\nif we only have 2 points:\n$$ P(x) \\cdot P(y_1|x) \\cdot P(y_2|x) \\rightarrow p(y_i|x) = (0.5)\\mathcal{N}(y_i; x, 1) + (0.5)\\mathcal{N} (y_i;0,10)$$\n2 points have 4 Gaussians -\u0026gt; N points $$2^N$$ Gaussians\n https://zhuanlan.zhihu.com/p/75617364 $$ p(z | w)=\\frac{p(w | z) p(z)}{p(w)}=\\frac{p(w | z) p(z)}{\\int_{z} p(w | z) p(z) d z} $$ Because it extends belief propagation. Belief propagation passes the entire distribution is the message. While EP will only pass onto the distribution certain expectation distribution allows you to you get a very compact message.\n Expectation Propagation  Fits an exponential-family approximation to the posterior. Belief propagation is a special case Kalman filtering is a special case Does not always converge.  May get stuck due to improper distributions May oscillate due to loopy graph   AGM $$ p(\\mathbf{X} | \\Theta)=\\sum{j=1}^{M} p{j} p\\left(\\mathbf{X} | \\xi_{j}\\right) $$\n $\\xi_j$ is the set of the parameters of component j. $ p_j$ are the mixing proptions which must be positive and sum to one. $\\Theta = {p_1, \\ldots, p_M, \\xi_1, \\ldots, \\xi_M}$ is the complete set of parameters fully characterizing the mixture. $ M \\geq 1$ is number of components in the mixture.  $$ p\\left(X | \\theta\\right)=\\prod{d=1}^{D} \\sqrt{\\frac{2}{\\pi}} \\frac{1}{\\left(\\sigma{l{d}}+\\sigma{r{d}}\\right)} \\times\\left{\\begin{array}{ll}\\exp \\left[-\\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 \\sigma{l{d} }^{2}}\\right] \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\ \\exp \\left[-\\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 \\sigma{r{d}}^{2}}\\right] \u0026amp; \\text { if } X{d} \\geq \\mu{d}\\end{array}\\right. $$ - $\\vec{\\mu}=\\left(\\mu{1}, \\ldots, \\mu{D}\\right)$ is the mean - $\\vec{\\sigma}{l}=\\left(\\vec{\\sigma}{l{1}}, \\ldots, \\vec{\\sigma}{l{D}}\\right)$ is the left standard deviation - $\\vec{\\sigma}{r}=\\left(\\vec{\\sigma}{r{1}}, \\ldots, \\vec{\\sigma}{r_{D}}\\right)$ is the right standard deviation\n$$ \\log P = \\sum{d=1}^{D} \\log \\sqrt{\\frac{2}{\\pi}} - \\frac{1}{2}\\log (\\sqrt{v{l{d}}} + \\sqrt{v{r{d}}}) - \\left{\\begin{array}{ll} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{l{d} }} \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{r{d} }} \u0026amp; \\text { if } X{d} \\geq \\mu{d} \\end{array}\\right. \\frac{\\partial \\log P}{\\partial v{l{d}}} = -\\frac{1}{4}\\frac{1}{v{l{d}} + \\sqrt{v{l{d}} v{r{d}} }} + \\left{\\begin{array}{ll} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{l{d}}^2} \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} 0 \u0026amp; \\text { if } X{d} \\geq \\mu_{d} \\end{array}\\right. $$\n$$ p(X, \\boldsymbol{\\theta})=\\prod{i} f{i}(\\boldsymbol{\\theta}) = \\prod_{i} p(xi|\\boldsymbol{\\theta})\n%p\\left(\\theta | X \\right) = \\frac{1}{p(X)} \\prod{i} f_{i}(\\boldsymbol{\\theta}) $$\n$$ %p(X)= \\int \\prod{i} f{i}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} $$\nHere, $p(\\vec{X})$ is very intractable to calculate and we don\u0026rsquo;t know $ f_{i}(\\boldsymbol{\\theta}) $.\nNow we consider using EP. The approximation, $q\\left(\\theta_j \\right)$ , of the posterior, $p\\left( \\theta_j | \\vec{X} \\right)$ , is assumed to have same functional form. $$ q(\\theta_j)=\\frac{1}{Z} \\prod_i \\widetilde{f}_i(\\theta_j) $$\nWe hope that: $$ \\mathrm{KL}(p | q)=\\mathrm{KL}\\left(\\frac{1}{p(X)} \\prod{i} f{i}(\\boldsymbol{\\theta}) | \\frac{1}{Z} \\prod{i} \\widetilde{f}{i}(\\boldsymbol{\\theta})\\right) $$\nIn general, this minimization will be intractable because the KL divergence involves averaging with respect to the true distribution.\nBut We can use EP:\n first choose a factor $\\widetilde{f}_{j}$ to approximate.  Begin Loop, until the following steps are convergence.\n second compute the cavity distribution $q^{\\backslash j}(\\boldsymbol{\\theta})$:  $$ q^{\\backslash j}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}_{j}(\\boldsymbol{\\theta})} \\\n\\hat{p} = \\frac{1}{Z{j}} f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta}) $$\nHere $q^{\\backslash j}(\\boldsymbol{\\theta})$ is called the cavity distribution. $\\hat{p}$ is defined as a product of the exact factor $f_i$ with the rest of the factors approximated, normalised to 1, and the cavity distribution needs to be computed in order to express $\\hat{p}$.\n $$ q^{\\text {new }}(\\boldsymbol{\\theta}) \\propto \\widetilde{f}{j}(\\boldsymbol{\\theta}) \\prod{i \\neq j} \\tilde{f}{i}(\\boldsymbol{\\theta}) p \\propto \\hat{p} = f{j}(\\boldsymbol{\\theta}) \\prod{i \\neq j} \\tilde{f}{i}(\\boldsymbol{\\theta}) $$\n  Then compute the approximative distribution $q^{new}$  $$ \\arg \\min \\mathrm{KL}(\\hat{p} | q^{new}(\\theta)) = \\arg \\min \\mathrm{KL}\\left(\\frac{f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta})}{Z{j}} | q^{\\mathrm{new}}(\\boldsymbol{\\theta})\\right) $$\n More generally, it is straightforward to obtain the required expectations for any member of the exponential family, provided it can be normalized, because the expected statistics can be related to the derivatives of the normalization coefficient. $$ \\text{bishop:} p(\\mathbf{x} | \\boldsymbol{\\eta})=h(\\mathbf{x}) g(\\boldsymbol{\\eta}) \\exp \\left{\\boldsymbol{\\eta}^{\\mathrm{T}} \\mathbf{u}(\\mathbf{x})\\right} -\\nabla \\ln g(\\boldsymbol{\\eta})=\\mathbb{E}[\\mathbf{u}(\\mathbf{x})] $$\n  Update the factor  $$ q^{\\text {new }}(\\boldsymbol{\\theta}) \\propto \\hat{p} = \\frac{1}{Z{j}} f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta}) $$\nThen we easily obtain the formula for the approximation of $fi$: $$ f{i} \\approx \\tilde{f}{i}=Z{i} \\frac{q^{\\text {new }}(\\boldsymbol{\\theta})}{q^{\\backslash j}(\\boldsymbol{\\theta})} $$ This division of distributions is from exponetial family, so does the result $\\tilde{f}_{i}$. Now repeat it until parameter covergence.\nEnd Loop.\n Evaluate the approximation to the model evidence  After the algorithm has converged to a set of factors $\\left{\\tilde{f}{i}\\right}$, the approximate posterior as well as the model evidence can be computed as following: $$ p(X, \\boldsymbol{\\theta}) \\simeq \\prod{i} \\tilde{f}{i}(\\boldsymbol{\\theta}) p(X) \\simeq \\int \\prod{i} \\tilde{f}_{i}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} $$\n$$ p(\\mathbf{X} | \\boldsymbol{\\theta})=(1-w) \\mathcal{A}(\\mathbf{X} | \\boldsymbol{\\theta}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}) $$\nwhere w is the proportion of background clutter. And the prior over $\\mathbf{\\theta}$(mean) is taken to be Asymmetric Gaussian.\nAnd $$ p(\\boldsymbol{\\theta})= \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{Ir}) $$ $$ p(X, \\boldsymbol{\\theta})=p(\\boldsymbol{\\theta}) \\prod{n=1}^{N} p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) $$\n1. initialize the approximating factors we select an approximating distribution from the exponential family to approximate the stochastic variables $\\theta$ $$ q_0(\\boldsymbol{\\theta})\n= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{I_r}) $$\n$$ \\widetilde{f}_{n}(\\boldsymbol{\\theta})=s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{\\sigma{rn}^2}, \\mathbf{\\sigma{l_n}^2} \\right) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) $$\n$$ sn = \\prod{d=1}^{D} \\sqrt{\\frac{2}{\\pi}} \\frac{1}{\\left(\\sigma{l{d}}+\\sigma{r{d}}\\right)} $$ While $\\sigma_{ln} \\rightarrow \\infty, \\sigma{r_n} \\rightarrow \\infty $ and $ \\mu_n = 0 $.\n###2. initialize the posterior approximation $q(\\boldsymbol{\\theta})$\nWe chooses the parameter values a = 10, b = 100 and w = 0.5 and use $v$ denote $ \\sigma^2$ as following, then $\\mathbf{v_r} = \\mathbf{v_l} = b = 100$\n3. Until all $(\\mun, v{ln}, v{r_n}, s_n)$ converge: $$ q^{\\backslash n}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}_n(\\boldsymbol{\\theta})} = \\frac{\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu}, \\mathbf{v_r I}, \\mathbf{v_l I})}{s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right)} \\propto \\left{\\begin{array}{ll}\n{\\frac{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_l \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu})\\right}}{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{l_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right}}} \u0026amp;\u0026amp; \\text { if } X\u0026lt;\\mu \\\n{\\frac{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_r \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu})\\right}}{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{r_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right}}} \u0026amp;\u0026amp; \\text { if } X\u0026gt;\\mu\n\\end{array}\\right. \\\n= \\left{\\begin{array}{ll}\n\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_l \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu}) + \\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{l_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right} \u0026amp; \\text { if } X\u0026lt;\\mu \\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_r \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu}) +\n\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{r_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n}) \\right} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$ - Remove the current estimate $\\widetilde{f}_j(\\boldsymbol{\\theta})$ from $q(\\theta)$, then we has mean and inverse variance given by: $$ \\left{\\begin{array}{ll} \\left({v_l}^{\\backslash n}\\right)^{-1}={v_l}^{-1}-{vl}{n}^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\left({v_r}^{\\backslash n}\\right)^{-1}={v_r}^{-1}-{vr}{n}^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$\n$$ \\mathbf{\\mu}^{\\backslash n}= \\mathbf{\\mu}+\n\\left{\\begin{array}{ll} {v_l}^{\\backslash n} {vl}{n}^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_{n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n{v_r}^{\\backslash n} {vr}{n}^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_{n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. \u0026mdash;-\n\\begin{aligned} {v^{\\backslash{n}}}^{-1} \u0026amp;= v^{-1} - v_n^{-1} {\\mu}^{\\backslash n} \u0026amp;= v^{\\backslash{n}}(\\mu v^{-1} - \\mu_n v_n^{-1}) \u0026amp;= v^{\\backslash{n}}[\\mu ({v^{\\backslash{n}}}^{-1} + v_n^{-1}) - \\mu_n v_n^{-1}] \u0026amp;= \\mu + v^{\\backslash{n}} v_n^{-1} \\mu - v^{\\backslash{n}} v_n^{-1} \\mu_n \u0026amp;= \\mu + v^{\\backslash{n}} v_n^{-1} (\\mu -\\mun) \\end{aligned} $$ \u0026gt; Cavity Distribution: \u0026gt; $$ \u0026gt; q^{\\backslash n}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}{n}(\\boldsymbol{\\theta})} \u0026gt; $$\n Recompute $(\\mu, v, Z)$ from $(\\mathbf{\\mu}^{\\backslash n}, {v_l}^{\\backslash n}, {vr}^{\\backslash n})$ $$ Z{n}=(1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir}\\right) $$ \u0026gt;$$ \u0026gt;\\begin{aligned} \u0026gt;Z{n} \u0026amp;=\\int q^{\\backslash n}(\\boldsymbol{\\theta}) f_{n}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} \\ \u0026gt;\u0026amp;=\\int q^{\\backslash n}(\\boldsymbol{\\theta}) P(X|\\mu) \\mathrm{d} \\boldsymbol{\\theta} \u0026gt; \u0026gt;\u0026amp;=\\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \\cdot { (1-w) \\mathcal{A}(\\mathbf{x_n} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{x_n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r})} \\mathrm{d} \\boldsymbol{\\theta} \u0026gt; \u0026gt;\u0026amp;= (1-w)\\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \\mathcal{A}(\\mathbf{x_n} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r}) \\mathrm{d} \\boldsymbol{\\theta} \u0026gt;\u0026amp;+ w \\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \u0026gt;\\mathcal{A}(\\mathbf{x_n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir})} \\mathrm{d} \\boldsymbol{\\theta} \u0026gt;\u0026amp;=(1-w) \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \u0026gt;\\end{aligned} \u0026gt;$$  we assumed that $f{0}(\\boldsymbol{\\theta})=p(\\boldsymbol{\\theta})$ and $ f{n}(\\boldsymbol{\\theta})=p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) = (1-w) \\mathcal{A}(\\mathbf{X} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}) $, also $q(\\boldsymbol{\\theta})=\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{m}, v_l \\mathbf{I}, vr \\mathbf{I}) $ $$ \\begin{aligned} \\rho{n} \u0026amp;=\\frac{1}{Z{n}}(1-w) \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right) \u0026amp;= \\frac{1}{Z{n}}(1-w)\\cdot \\frac{Zn - w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right)}{1-w} \u0026amp;= 1 - \\frac{w}{Zn} \\cdot \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir}\\right) \\end{aligned} $$ \u0026gt;Then our goal is to minimize: \u0026gt;$$ \u0026gt;\\mathrm{KL}\\left(\\frac{f{n}(\\boldsymbol{\\theta}) q^{\\backslash n}(\\boldsymbol{\\theta})}{Z_{n}} | q^{\\mathrm{new}}(\\boldsymbol{\\theta})\\right) \u0026gt;$$\nBasic rule for Asymmetric Gaussian:\nhttps://stats.stackexchange.com/questions/27436/how-to-take-derivative-of-multivariate-normal-density $$ \\nabla_{\\boldsymbol{\\mu}} \\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r})=\n\\left{\\begin{array}{ll}\n\\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r}) \\cdot(\\mathbf{x}-\\boldsymbol{\\mu}) \\mathbf{v_l}^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r}) \\cdot(\\mathbf{x}-\\boldsymbol{\\mu}) \\mathbf{v_r}^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$ So we compute the mean and variance: $$ \\begin{aligned} \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\ln Z{n} \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} Z_{n} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta})f_{n}(\\boldsymbol{\\theta}) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta}) p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int\\left{\\nabla{\\mathbf{\\mu}^{\\backslash n}} q^{\\backslash n}(\\boldsymbol{\\theta})\\right} \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int \\frac{1}{v^{\\backslash n}}\\left(\\boldsymbol{\\theta}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\theta\\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\frac{1}{v^{\\backslash n}} \\cdot\\left{\\int \\boldsymbol{\\theta} \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta}-\\int \\mathbf{\\mu}^{\\backslash n} \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta}\\right} \\\n\u0026amp;=\\frac{1}{v^{\\backslash n}} \\cdot\\left{\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right} \\\n\u0026amp;= \\left{\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right} \\cdot \\left{\\begin{array}{ll} \\frac{1}{vl^{\\backslash n}} \u0026amp; \\text { if } X{d}\u0026lt;\\mu_{d} \\frac{1}{vr^{\\backslash n}} \u0026amp; \\text { if } X{d} \\geqslant \\mu_{d} \\end{array}\\right. \\end{aligned} $$\n$$ \\text{According to the following}: q^{\\backslash n}(\\boldsymbol{\\theta})=\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, vr^{\\backslash n} \\mathbf{I}) q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right)=Z_{n} \\cdot q^{new}(\\theta) $$\n$$ \\begin{aligned} \\mathbb{E}[\\boldsymbol{\\theta}] \u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\ln Z{n} \\ \u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}} \\nabla{\\mathbf{\\mu}^{\\backslash n}} Z_n \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}} \\nabla{\\mathbf{\\mu}^{\\backslash n}} (1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}}(1-w) \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(v_r^{\\backslash n}+1\\right) \\mathbf{I}\\right)\n%\\cdot \\frac{1}{v^{\\backslash n}+1}\\left(\\mathbf{x}_{n}-\\mathbf{\\mu}^{\\backslash n}\\right)\n\\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\rho{n} \\cdot \\frac{1}{v^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+ \\rho_{n} \\cdot\n\\left{\\begin{array}{ll} \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n}\n\u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\frac{1}{vr^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot vl^{\\backslash n} \u0026amp; \\text { if } X{d} \\geqslant \\mu_{d} \\end{array}\\right.\n\\\n\\text{According to: }\u0026amp; \\rho{n} = 1 - \\frac{w}{Zn} \\cdot \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \\\n\u0026amp;\\text{Here we match first moment}: \\mathbb{E}[\\boldsymbol{\\theta}] = \\mathbf{\\mu^{new}} \\end{aligned} $$\nNow we consider when: $$ \\text { if } X{d}\u0026lt;\\mu{d} $$\n$$ \\begin{aligned} \\nabla_{vl^{\\backslash n}} \\ln Z{n} \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{vl^{\\backslash n}} Z{n} \\ \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{vl^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta}) p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int\\left{\\nabla{vl^{\\backslash n}} q^{\\backslash n}(\\boldsymbol{\\theta})\\right} p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z_{n}} \\cdot \\int\\left{\n\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left| \\boldsymbol{\\theta} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right}\nq^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\int q^{\\mathrm{new}}(\\boldsymbol{\\theta}) \\cdot\\left{\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left(\\mathbf{\\mu}^{\\backslash n}-\\boldsymbol{\\theta}\\right)^{T}\\left(\\mathbf{\\mu}^{\\backslash n}-\\boldsymbol{\\theta}\\right)-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\\right} d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]-2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{\\mu}^{\\backslash n}+\\left|\\mathbf{\\mu}^{\\backslash n}\\right|^{2}\\right}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\end{aligned} $$\nSo we rearrange the above equation: $$ \\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]=2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n}+2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{m}^{\\backslash n}-\\left|\\mathbf{m}^{\\backslash n}\\right|^{2}+ \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } $$ Also according to: $$ Z{n}=(1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) $$\n$$ \\nabla_{vl^{\\backslash n}} \\ln Z{n} = (1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(v_r^{\\backslash n}+1\\right) \\mathbf{I}\\right) \\cdot \\\n\\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right) \\\n= \\rho_n \\cdot \\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right) $$\nAccording to the bellow formula: $$ v \\mathbf{I}=\\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]-\\mathbb{E}[\\boldsymbol{\\theta}] \\mathbb{E}\\left[\\boldsymbol{\\theta}^{T}\\right] $$\n$$ \\begin{aligned} v_l^{new} \u0026amp;=\\frac{1}{D} \\cdot\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T} \\boldsymbol{\\theta}\\right]-\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T}\\right] \\mathbb{E}[\\boldsymbol{\\theta}]\\right}=\\frac{1}{D} \\cdot\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T} \\boldsymbol{\\theta}\\right]-|\\mathbb{E}[\\boldsymbol{\\theta}]|^{2}\\right} \u0026amp;=\\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n}+2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{\\mu}^{\\backslash n}-\\left|\\mathbf{\\mu}^{\\backslash n}\\right|^{2}\n \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } - |\\mathbb{E}[\\boldsymbol{\\theta}]|^{2} \\right}\n  \u0026amp;=\\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left|\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \\\n\u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right}\n\\end{aligned} $$ substitute $\\nabla_{vl^{\\backslash n}} \\ln Z{n}$: $$ \\begin{aligned} v_l^{new} \u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \\\n\u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(v_l^{\\backslash n}\\right)^{2} \\cdot\n\\rho_n \\cdot \\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right)\n \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \u0026amp;=\\frac{\\left(v_l^{\\backslash n}\\right)^{2} - 2 \\left(v_l^{\\backslash n}\\right)^{2} \\rho_n}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } + \\rho{n}\\left(1-\\rho_{n}\\right) \\frac{\\left(vl^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_l^{\\backslash n}+1\\right)^{2}}  \\end{aligned} $$ So in conclusions: we have:\n$$ \\mathbf{\\mu^{new}}=\\mathbf{\\mu}^{\\backslash n}+\n\\left{\\begin{array}{ll}\n\\rho_{n} \\frac{v_l^{\\backslash n}}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\rho_{n} \\frac{v_r^{\\backslash n}}{vr^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$\n$$ \\left{\\begin{array}{ll} v_l^{new}= \\frac{\\left(v_l^{\\backslash n}\\right)^{2} - 2 \\left(v_l^{\\backslash n}\\right)^{2} \\rho_n}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } + \\rho{n}\\left(1-\\rho_{n}\\right) \\frac{\\left(vl^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_l^{\\backslash n}+1\\right)^{2}}\n\u0026amp; \\text { if } X\u0026lt;\\mu \\\nv_r^{new}= \\frac{\\left(v_r^{\\backslash n}\\right)^{2} - 2 \\left(v_r^{\\backslash n}\\right)^{2} \\rho_n}{4 v_r^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n+\\rho{n}\\left(1-\\rho{n}\\right) \\frac{\\left(vr^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_r^{\\backslash n}+1\\right)^{2}} \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$ - Evaluate and store the new factor\n Update formula for $\\hat{f}i$ $$ \\left{\\begin{array}{ll} \\left({v{l_n}}\\right)^{-1}={(v_l^{new})}^{-1}-({vl}^{\\backslash n})^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\left({v{r_n}}\\right)^{-1}={(v_r^{new})}^{-1}-({v_r}^{ \\backslash n})^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$\n $$ \\mathbf{\\mu}_{n}=\\mathbf{\\mu}^{\\backslash n}+ \\left{\\begin{array}{ll}\n\\left(v_{n}+v^{\\backslash n}\\right)\\left(v^{\\backslash n}\\right)^{-1}\\left(\\mathbf{\\mu}^{\\mathrm{new}}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\left(v_{n}+v^{\\backslash n}\\right)\\left(v^{\\backslash n}\\right)^{-1}\\left(\\mathbf{\\mu}^{\\mathrm{new}}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$\n$$ \\begin{aligned} \u0026amp; \\widetilde{f}{n}(\\boldsymbol{\\theta})=Z{n} \\frac{q^{\\mathrm{new}}(\\boldsymbol{\\theta})}{q^{\\backslash n}(\\boldsymbol{\\theta})} \\\n\\Rightarrow \u0026amp; Z_n q^{\\mathrm{new}}(\\boldsymbol{\\theta}) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) q^{\\backslash n}(\\boldsymbol{\\theta}) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) \\\n\\Rightarrow \u0026amp; \\int Z_n q^{\\mathrm{new}}(\\boldsymbol{\\theta}) d\\theta = \\int s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) d \\theta \\\n\\Rightarrow \u0026amp; Z_n = s_n \\int q^{\\mathrm{new}}(\\boldsymbol{\\theta}) d\\theta =\n\\int s_n \\mathcal{A}\\left( \\mathbf{\\mu}n - \\boldsymbol{\\theta} | 0, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) d \\theta \\\n\\Rightarrow \u0026amp; Z_n = s_n \\mathcal{A}\\left(\\mathbf{\\mu}_n | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{(vr^{\\backslash n}+ v{r_n}) I}, \\mathbf{(vl^{\\backslash n}+v{r_n}) I} \\right) \\end{aligned} $$\n$$ s_n = \\frac{Z_n} {\\mathcal{A}\\left(\\mathbf{\\mu}_n | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{(vr^{\\backslash n}+ v{r_n}) I}, \\mathbf{(vl^{\\backslash n}+v{r_n}) I} \\right)} $$\n Evaluate the approximation to the model evidence - Posterior probability. (When $(\\mathbf{\\mu}_n, {vl} n, {v_r}_n, S_n)$ unchanged )  $$ p(X) \\simeq q(\\boldsymbol{\\theta})= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu}, \\mathbf{v_l}, \\mathbf{vr}) = \\prod{n=0}^{N} \\widetilde{f}{n}(\\boldsymbol{\\theta})=f{0}(\\boldsymbol{\\theta}) \\prod{n=1}^{N} \\widetilde{f}{n}(\\boldsymbol{\\theta})\n= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{Ir})\\cdot \\prod{i=1}^{N} \\mathcal{A}\\left(\\boldsymbol{\\mu}_{i}, \\mathbf{vl}{i}, \\mathbf{vr}{i}\\right) $$\n$$ \\begin{aligned} p(X, \\boldsymbol{\\Theta}) \u0026amp; =\\prod{i} f{i}(\\boldsymbol{\\Theta}) = \\prod_{i} p(xi|\\boldsymbol{\\Theta})\n\\text{choose a factor:} q^{*}(\\Theta)\u0026amp;=\\frac{\\prod{i} \\widetilde{f}{i}(\\Theta)}{\\int \\prod{i} \\tilde{f}{i}(\\Theta) d \\Theta} \\propto \\prod{i} \\widetilde{f}_{i}(\\Theta) \\\nq^{\\backslash j}(\\Theta)\u0026amp; =\\frac{q^{*}(\\Theta)}{\\widetilde{f}_{j}(\\Theta)} \\\n\\arg \\min \\mathrm{KL}(\\hat{p} | q^{new}(\\Theta)) \u0026amp; = \\arg \\min \\mathrm{KL}\\left(\\frac{f{j}(\\boldsymbol{\\Theta}) q^{\\backslash j}(\\boldsymbol{\\Theta})} { \\underbrace{ Z{j} }{ Z{j}=\\int q^{\\backslash j}(\\boldsymbol{\\Theta}) f_{j}(\\boldsymbol{\\Theta}) \\mathrm{d} \\boldsymbol{\\Theta}} }\n| q^{\\mathrm{new}}(\\boldsymbol{\\Theta})\\right) \\\n\\tilde{f}{j}(\\boldsymbol{\\Theta}) \u0026amp;=Z{j} \\frac{q^{\\text {new }}(\\boldsymbol{\\Theta})}{q^{\\backslash j}(\\boldsymbol{\\Theta})}\n\\end{aligned} $$\n","date":1582994068,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589841215,"objectID":"985b28a7398b99c38e892b86d015b478","permalink":"https://faithio.cn/post/stochastic-expectation-propagation/","publishdate":"2020-02-29T11:34:28-05:00","relpermalink":"/post/stochastic-expectation-propagation/","section":"post","summary":"Math Formula Factor graphs Shows how a function of several variables can be factored into a product of simpler functions.\n $$ f(x,y,z) = (x+y) \\cdot (y + z) \\cdot (x +z) $$\n Very useful for representing posteriors.\n$ $$ P(x1, ..., x_n) = P(x_1) \\Pi P( x_i | x_{i-1} ) $$ $\n$$ P(m|x1, \u0026hellip;, x_n) = P(m) \\cdot \\Pi P(x_i|m)$$\nmodeling  What graph should I use for this data?","tags":[],"title":"Stochastic Expectation Propagation","type":"post"},{"authors":[],"categories":[],"content":" Introduction A hypothesis h(x), takes an input and gives us the estimated output value.\nThis hypothesis can be a as simple as a one variable linear equation, .. up to a very complicated and long multivariate equation with respect to the type of the algorithm we’re using (i.e. linear regression, logistic regression..etc).\nOur task is to find the best Parameters (a.k.a Thetas or Weights) that give us the least error in predicting the output. We call this error a Cost or Loss Function and apparently our goal is to minimize it in order to get the best predicted output!\nOne more thing to recall, that the relation between the parameter value and its effect on the cost function (i.e. the error) looks like a bell curve (i.e. Quadratic; recall this because it’s very important) .\nSo if we start at any point in that curve and if we keep taking the derivative (i.e. tangent line) of each point we stop at, we will end up at what so called the Global Optima as shown in this image: If we take the partial derivative at minimum cost point (i.e. global optima) we find the slope of the tangent line = 0 (then we know that we reached our target).\nThat’s valid only if we have Convex Cost Function, but if we don’t, we may end up stuck at what so called Local Optima; consider this non-convex function:\nNow you should have the intuition about the hack relationship between what we are doing and the terms: Deravative, Tangent Line, Cost Function, Hypothesis ..etc.\nSide Note: The above mentioned intuition also related to the Gradient Descent Algorithm (see later).\nBackground Linear Approximation:\nGiven a function, f(x), we can find its tangent at x=a. The equation of the tangent line L(x) is: L(x)=f(a)+f′(a)(x−a).\nTake a look at the following graph of a function and its tangent line:\nFrom this graph we can see that near x=a, the tangent line and the function have nearly the same graph. On occasion we will use the tangent line, L(x), as an approximation to the function, f(x), near x=a. In these cases we call the tangent line the linear approximation to the function at x=a.\nQuadratic Approximation:\nSame like linear approximation but this time we are dealing with a curve but we cannot find the point near to 0 by using the tangent line.\nInstead, we use a parabola (which is a curve where any point is at an equal distance from a fixed point or a fixed straight line), like this:\nAnd in order to fit a good parabola, both parabola and quadratic function should have same value, same first derivative, AND second derivative, \u0026hellip; the formula will be (just out of curiosity): Qa(x) = f(a) + f'(a)(x-a) + f''(a)(x-a)2/2\nNow we should be ready to do the comparison in details.\nComparison between the methods 1. Newton’s Method(newton-cg): Recall the motivation for gradient descent step at x: we minimize the quadratic function (i.e. Cost Function).\nNewton’s method uses in a sense a better quadratic function minimisation. A better because it uses the quadratic approximation (i.e. first AND second partial derivatives).\nYou can imagine it as a twisted Gradient Descent with The Hessian (The Hessian is a square matrix of second-order partial derivatives of order nxn).\nMoreover, the geometric interpretation of Newton\u0026rsquo;s method is that at each iteration one approximates f(x) by a quadratic function around xn, and then takes a step towards the maximum/minimum of that quadratic function (in higher dimensions, this may also be a saddle point). Note that if f(x) happens to be a quadratic function, then the exact extremum is found in one step.\nDrawbacks:\n It’s computationally expensive because of The Hessian Matrix (i.e. second partial derivatives calculations). It attracts to Saddle Points which are common in multivariable optimization (i.e. a point its partial derivatives disagree over whether this input should be a maximum or a minimum point!).  2. Limited-memory Broyden–Fletcher–Goldfarb–Shanno Algorithm(lbfgs): In a nutshell, it is analogue of the Newton’s Method but here the Hessian matrix is approximated using updates specified by gradient evaluations (or approximate gradient evaluations). In other words, using an estimation to the inverse Hessian matrix.\nThe term Limited-memory simply means it stores only a few vectors that represent the approximation implicitly.\nIf I dare say that when dataset is small, L-BFGS relatively performs the best compared to other methods especially it saves a lot of memory, however there are some “*serious*” drawbacks such that if it is unsafeguarded, it may not converge to anything.\n3. A Library for Large Linear Classification(liblinear): It’s a linear classification that supports logistic regression and linear support vector machines (A linear classifier achieves this by making a classification decision based on the value of a linear combination of the characteristics i.e feature value).\nThe solver uses a coordinate descent (CD) algorithm that solves optimization problems by successively performing approximate minimization along coordinate directions or coordinate hyperplanes.\nLIBLINEAR is the winner of ICML 2008 large-scale learning challenge. It applies Automatic parameter selection (a.k.a L1 Regularization) and it’s recommended when you have high dimension dataset (recommended for solving large-scale classification problems)\nDrawbacks:\n It may get stuck at a non-stationary point (i.e. non-optima) if the level curves of a function are not smooth. Also cannot run in parallel. It cannot learn a true multinomial (multiclass) model; instead, the optimization problem is decomposed in a “one-vs-rest” fashion so separate binary classifiers are trained for all classes.  Side note: According to Scikit Documentation: The “liblinear” solver is used by default for historical reasons.\n4. Stochastic Average Gradient(sag): SAG method optimizes the sum of a finite number of smooth convex functions. Like stochastic gradient (SG) methods, the SAG method\u0026rsquo;s iteration cost is independent of the number of terms in the sum. However, by incorporating a memory of previous gradient values the SAG method achieves a faster convergence rate than black-box SG methods.\nIt is faster than other solvers for large datasets, when both the number of samples and the number of features are large.\nDrawbacks:\n It only supports L2 penalization. Its memory cost of O(N), which can make it impractical for large N (because it remembers the most recently computed values for approx. all gradients).  5. SAGA(saga): The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization). This is therefore the solver of choice for sparse multinomial logistic regression and it’s also suitable very Large dataset.\nSide note: According to Scikit Documentation: The SAGA solver is often the best choice.\nSummary The following table is taken from Scikit Documentation\n","date":1582962364,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"25e50f2219880ef0b8c0c1f286c67275","permalink":"https://faithio.cn/post/logistic-regression-solvers-defintions-in-sklearn/","publishdate":"2020-02-29T02:46:04-05:00","relpermalink":"/post/logistic-regression-solvers-defintions-in-sklearn/","section":"post","summary":"Introduction A hypothesis h(x), takes an input and gives us the estimated output value.\nThis hypothesis can be a as simple as a one variable linear equation, .. up to a very complicated and long multivariate equation with respect to the type of the algorithm we’re using (i.e. linear regression, logistic regression..etc).\nOur task is to find the best Parameters (a.k.a Thetas or Weights) that give us the least error in predicting the output.","tags":[],"title":"Logistic Regression","type":"post"},{"authors":null,"categories":null,"content":" K-Means 及其衍生算法\n生成模型与判别模型 在机器学习中，通常有两种模型，生成模型 (generative model) 和判别模型 (discriminative model)。对于无监督学习，聚类问题中，同样是也是以 K-Means 和 高斯混合模型 (Gaussian Mixture Model) 为经典的代表。\n 还记得今年年初刚开始系统性学习机器学习的时候，这两个概念不是很清楚，现在弄懂了，以后有时间可以专门讲下。\n 对于判别模型，通常就是计算边界 (boudary)，如果以数学公式来表达通常就是直接从 training data 计算$P(\\mathcal{predict} | \\mathcal{data})$。相反的，生成模型则会假设我们的先验概率 (prior) 和 近似概率 (likelihood) 的模型，从 training data求出他们的参数，最后通过经典的贝叶斯公式求出： $$ P(\\mathcal{predict} | \\mathcal{data}) = \\frac{P(\\mathcal{data} | \\mathcal{predict}) \\times P(predict)}{P(data)} $$\nK-Means 及衍生算法 K-Means K-Means 是 EM 算法的特殊例子，因为它用的是欧几里德 (Euclidean Distance) 距离，它的目标functon如下： $$ J=\\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}\\left|x^{i}-\\mu{k}\\right|^{2} $$ m 代表data instances，K代表目前cluster的数量。当$w{ik}=1$表示这个数据点属于cluster k，若$w{ik}= 0$则表示这个点不属于这个cluster。\n那么算法本身可以分为 E-Step 和 M-Step。E-Step 主要计算欧几里德距离，M-Step则是算objective function J对于$\\mu$的梯度。 $$ \\begin{aligned} \u0026amp; \\text{E-Step：} \\frac{\\partial J}{\\partial w{i k}}=\\sum{i=1}^{m} \\sum{k=1}^{K} \u0026amp;\\left|x^{i}-\\mu{k}\\right|^{2} \\\n\\Rightarrow w{i k} \u0026amp;=\\left{\\begin{array}{ll}1 \u0026amp; \\text { if } k=\\operatorname{argmin}{j}\\left|x^{i}-\\mu_{j}\\right|^{2} \\ 0 \u0026amp; \\text { otherwise. }\\end{array}\\right. \u0026amp; \\text{M-Step：} \\\n\\frac{\\partial J}{\\partial \\mu{k}}=2 \\sum{i=1}^{m} w{i k}\\left(x^{i}-\\mu{k}\\right)=\u0026amp; 0 \\\n\\Rightarrow \\mu{k} \u0026amp;=\\frac{\\sum{i=1}^{m} w{i k} x^{i}}{\\sum{t-1}^{m} w_{i k}}\n\\end{aligned} \\\n$$\n 需要注意以下几点：\n 如果数据集的variance过大，最好对数据做归一化 (Standardize)，使得他们的mean等于0，标准差等于1，以避免某些feature对于其他feature的影响。 K-Means 依赖于初始化状态，很有可能陷入局部最优，所以建议多初始化几次，然后取最小的J   Fuzzy C-Means (FCM) 由于K-Means是硬分类，Fuzzy C-Means就是相当于Soft K-Means。这里的Soft是指给数据点对于每个cluster不再是硬分配，而且给每个cluster分配响应的概率。\n 同理类似于SVM也有硬间隔和软间隔。\n 这里我们同样可以写出它的objective function J： $$ \\begin{array}{l} \\underset{C}{\\arg \\min } \\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}^{m}\\left|\\mathbf{x}{i}-\\mathbf{\\mu}_{k}\\right|^{2}\n\\ \\text { where: } \\ w{i j}=\\frac{1}{\\sum{k=1}^{K}\\left(\\frac{\\left|\\mathbf{x}{i}-\\mathbf{\\mu}{j}\\right|}{\\left|\\mathbf{x}{i}-\\mathbf{\\mu}{k}\\right|}\\right)^{\\frac{2}{m-1}}}\\end{array} $$\n FCM也是稍微将K-Means 变形，将w改为一个相对值，相对于其他所有点对应clusters的距离。分母其实就是Normalization constant，为了保证w处于0和1之间。\n Hierarchical clustering 如果你留意上述的算法，他们都是要实现知道或者推断clusters的数量，我们可以通过下述方法推断：\n model selection criteria (MML/LEC/AIC/BIC等等) Elbow method (which uses the within cluster sums of squares) Average silhouette method Gap statistic method  但是与K-Means Clustering不同的是，Hierarchical Clustering 可以帮我们找到最优的clusters数量。\n其算法很简单过程如下：\n 首先假设每一个点都是一个cluster，因此N个数据点就有N个clusters 通过计算cluster与cluster的距离并存在distance matrix里，将数据集中距离最近的两个点合并成一个cluster，此时有N-1个clusters 重新计算距离distanc matrix 不断重复知道只剩下一个cluster  注意有五种方式计算距离：\n Single linkage: computes the minimum distance between clusters before merging them. Complete linkage: computes the maximum distance between clusters before merging them. Average linkage: computes the average distance between clusters before merging them. Centroid linkage: calculates centroids for both clusters, then computes the distance between the two before merging them. Ward’s (minimum variance) criterion: minimizes the total within-cluster variance and find the pair of clusters that leads to minimum increase in total within-cluster variance after merging.  举例：\n根据第一种距离公式： $$ \\sqrt{\\left(x{a}-x{b}\\right)^{2}+\\left(y{a}-y{b}\\right)^{2}} $$ 我们可以算出distance matrix：\n可以看出0.328是最小的，所以我们将2和4合并，此时合并高度为0.328：\n然后再将2\u0026amp;4和3合并，合并高度为0.483：\n合并1和5，合并高度为0.942：\n然后根据我们每次合并的数据绘制成树状图，最后的高度为1.530：\n此时最优的cluster 数目应该就是最大的合并高度下的竖线条数也就是2.\n 注意：其实这里蕴涵了两种策略，Top-Down （从一个cluster开始，不断分解到N个clusters）或者 Bottom-Up （从N个clusers开始合并为一个cluser）\n Hierarchical K-Means (HKMeans) 其实是Top-Down approach，就是递归调用K-Means不断将其划为clusters中。这种方式相对较快，时间复杂度为$O(K \\log_kn)$。但是这种划分方法是greedy的也是hard的，相邻的两个点如果划为两个不同的cluster，他们再也不会划为同一个clusters.\n总结 本次我们细讲了无监督学习聚类的判别模型，对于判别模型最大的问题是无法解决数据集overlapping的问题，更无法做一些推断和预测。这时生成模型的好处就体现出来，他可以预测出数据集中没有的数据的。后面我会讲一下生成模型和判别模型在深度学习中的应用，欢迎继续关注。\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d0f14e1d792c8e64ca3fca4e638fc92d","permalink":"https://faithio.cn/post/k-means-vs-fuzzy-c-means/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/k-means-vs-fuzzy-c-means/","section":"post","summary":"K-Means 及其衍生算法\n生成模型与判别模型 在机器学习中，通常有两种模型，生成模型 (generative model) 和判别模型 (discriminative model)。对于无监督学习，聚类问题中，同样是也是以 K-Means 和 高斯混合模型 (Gaussian Mixture Model) 为经典的代表。\n 还记得今年年初刚开始系统性学习机器学习的时候，这两个概念不是很清楚，现在弄懂了，以后有时间可以专门讲下。\n 对于判别模型，通常就是计算边界 (boudary)，如果以数学公式来表达通常就是直接从 training data 计算$P(\\mathcal{predict} | \\mathcal{data})$。相反的，生成模型则会假设我们的先验概率 (prior) 和 近似概率 (likelihood) 的模型，从 training data求出他们的参数，最后通过经典的贝叶斯公式求出： $$ P(\\mathcal{predict} | \\mathcal{data}) = \\frac{P(\\mathcal{data} | \\mathcal{predict}) \\times P(predict)}{P(data)} $$\nK-Means 及衍生算法 K-Means K-Means 是 EM 算法的特殊例子，因为它用的是欧几里德 (Euclidean Distance) 距离，它的目标functon如下： $$ J=\\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}\\left|x^{i}-\\mu{k}\\right|^{2} $$ m 代表data instances，K代表目前cluster的数量。当$w{ik}=1$表示这个数据点属于cluster k，若$w{ik}= 0$则表示这个点不属于这个cluster。\n那么算法本身可以分为 E-Step 和 M-Step。E-Step 主要计算欧几里德距离，M-Step则是算objective function J对于$\\mu$的梯度。 $$ \\begin{aligned} \u0026amp; \\text{E-Step：} \\frac{\\partial J}{\\partial w{i k}}=\\sum{i=1}^{m} \\sum{k=1}^{K} \u0026amp;\\left|x^{i}-\\mu{k}\\right|^{2} \\","tags":null,"title":"","type":"post"}]