[{"authors":["admin"],"categories":null,"content":"Zixiang Xian is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1582962603,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://faithio.cn/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Zixiang Xian is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.","tags":null,"title":"Zixiang Xian","type":"authors"},{"authors":["zi_xian"],"categories":null,"content":"Xian Zixiang is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\nBefore his graduate study, he is a senior backend engineer at Kingsoft Company, skilling at Golang, Java, JavaScript, and Python.\nHe is so motivative and passion for exploring the new world of computer science.\nFeel free to contact me.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1582962603,"objectID":"b531f07f2ad34c1997a37315504c48d8","permalink":"https://faithio.cn/authors/zi_xian/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/zi_xian/","section":"authors","summary":"Xian Zixiang is a master student of Machine Learning at Concordia University AI Lab. His research interests include Machine Learning and Computer Vision. He is under the supervision of Professor Nizar Bouguila.\nBefore his graduate study, he is a senior backend engineer at Kingsoft Company, skilling at Golang, Java, JavaScript, and Python.\nHe is so motivative and passion for exploring the new world of computer science.\nFeel free to contact me.","tags":null,"title":"XIAN ZIXIANG","type":"authors"},{"authors":[],"categories":[],"content":" Confusion Matrix Sensitivity vs Specificity AUC vs ROC ","date":1588885534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"af80896f9c59632f8f07a607c95e9a2c","permalink":"https://faithio.cn/post/auc-vs-roc/","publishdate":"2020-05-07T17:05:34-04:00","relpermalink":"/post/auc-vs-roc/","section":"post","summary":" Confusion Matrix Sensitivity vs Specificity AUC vs ROC ","tags":[],"title":"AUC vs ROC","type":"post"},{"authors":[],"categories":[],"content":" éœ€è¦åŸºäºå‡è®¾ï¼Œè€ƒè™‘ä½ çš„å‡è®¾åˆä¸åˆç†\nGenerative Model åˆå§‹åŒ–ä¸€ç³»åˆ—å‚æ•°ï¼Œå¯ä»¥randomä¹Ÿå¯ä»¥ä»å·²ç»è®­ç»ƒçš„æ•°æ®å¾—æ¥ã€‚\næ¯æ¬¡å¢åŠ loglikelihood ç»“æŸåœ¨local minimum\nLow-density Separation Assumption é€šè¿‡ä¸€å®šç­–ç•¥å°†pseudo-label data å¢åŠ åˆ°train setï¼Œä¹Ÿå¯ä»¥ç»™ä¸€å®šweightï¼Œconfidentæœ‰é«˜weight\noutputä¸€ä¸ªæ•°å­—å…¶å®ä¸ä¼šå½±å“ç»“æœ\nå¯¹äºç¥ç»ç½‘ç»œå“ªä¸ªæœ‰ç”¨ Entropy-based Regularization entropyè¶Šå°è¶Šå¥½ï¼Œ labelled data cross entropyè¶Šå°è¶Šå¥½ï¼Œä¹Ÿå¯ä»¥åŠ ä¸Šweight\nçœ‹å€¾å‘äºå“ªè¾¹\nOutlook: Semi-supervised SVM ç©·ä¸¾æ‰€æœ‰unlabeled dataã€‚æ”¹ä¸€äº›label å¦‚æœobjective functionå¤§ï¼Œé‚£å°±æ”¹\nSmoothness Assumption  è¿‘æœ±è€…èµ¤ï¼Œè¿‘å¢¨è€…é»‘ â€œYou are known by the company you keepâ€\n x1 å’Œ x2 ä¹‹é—´æœ‰high density\næ–‡æœ¬åˆ†ç±»\nCluster and then Label åœ¨image ä¸Šå¯èƒ½ä¸ä¼šworkï¼Œå› ä¸ºpixelå¯èƒ½å·®ä¸å¤šï¼Œä½†æ˜¯å¹¶ä¸åƒ\näººçš„å·¦å³ä¾§é¢/æ‰‹å†™\n Deep Autoencoder call feature, call clustering.\n Graph-based Approach ç½‘é¡µçš„hyperlink/è®ºæ–‡çš„å¼•ç”¨å¯ä»¥åšåˆ†ç±»\nå› ä¸ºæœ‰å–expï¼Œæ‰€ä»¥ä¸‹é™å¾ˆå¿«ï¼Œsingularityæ‰ä¼šå¤§ã€‚éœ€è¦æœ‰è¿™æ ·çš„æœºåˆ¶æ‰ä¸ä¼šè¿åˆ°è·¨æµ·æ²Ÿçš„link\n data éœ€è¦å¤Ÿå¤šï¼Œä¸ç„¶ä¼šæ–­æ‰\n ä¸¤ä¸¤æ‹¿å‡ºæ¥ï¼Œä¹˜ä»¥weights\nè®©ç¥ç»ç½‘ç»œçš„labeled data å’ŒçœŸæ­£çš„label è¶Šæ¥è¿‘è¶Šå¥½ï¼Œè¿˜è¦ç¬¦åˆsmoothness assumptionçš„å‡è®¾ã€‚åšgradient descent\nBetter Representation ","date":1587850047,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"fe29690851b31ba92744a5bedd4cce3b","permalink":"https://faithio.cn/post/semi-supervised-learning/","publishdate":"2020-04-25T17:27:27-04:00","relpermalink":"/post/semi-supervised-learning/","section":"post","summary":"éœ€è¦åŸºäºå‡è®¾ï¼Œè€ƒè™‘ä½ çš„å‡è®¾åˆä¸åˆç† Generative Model åˆå§‹åŒ–ä¸€ç³»åˆ—å‚æ•°ï¼Œå¯ä»¥randomä¹Ÿå¯ä»¥ä»å·²ç»è®­ç»ƒçš„æ•°æ®å¾—æ¥ã€‚ æ¯æ¬¡å¢åŠ loglikelihood ç»“æŸåœ¨","tags":[],"title":"Semi Supervised Learning","type":"post"},{"authors":[],"categories":[],"content":" è®²è®²Ensemble Methodsçš„Boosting/Bagging/Stacking\nåœ¨Kaggleæ¯”èµ›æœ€åéƒ½ä¼šç”¨åˆ°Ensemble Methodsæ¥æé«˜performanceã€‚\nç®€å•æ¥è¯´å°±æ˜¯ï¼šEnsemble of various models into one more effective model\nä¸€èˆ¬æ¥è¯´model \u0026rsquo;s learning error æ¥è‡ªäº variance, noise, and bias.\nensembleçš„å‡ºç°å°±æ˜¯ä¸ºäº†è§£å†³è¿™ä¸‰ä¸ªé—®é¢˜ï¼Œè®©model æ›´åŠ robustã€‚\nBagging to decrease the modelâ€™s variance;  ä¸»è¦è§£å†³overfitingé—®é¢˜ï¼Œè®©error surfaceæ›´åŠ å¹³ç¼“ã€‚\n å¯ä»¥å¹¶è¡Œè¿›è¡Œã€‚\n é‡‡å–voting æˆ–è€…averageæ–¹æ³•é€‰å–modelï¼Œæ‰€ä»¥weightæ˜¯ç›¸åŒçš„\n ä¸€èˆ¬é‡‡ç”¨subsampleæ–¹æ³•ï¼Œåˆ†ä¸ºbootstraping and aggregatingã€‚ä½†æ˜¯åœ¨sampleçš„è¿‡ç¨‹ä¸­æ ·æœ¬æ˜¯æœ‰æ”¾å›çš„\n  # Get some classifiers to evaluate from sklearn.model_selection import cross_val_score from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier from sklearn.neighbors import KNeighborsClassifier from sklearn.linear_model import RidgeClassifier from sklearn.svm import SVC seed = 1075 np.random.seed(seed) # Create classifiers rf = RandomForestClassifier() et = ExtraTreesClassifier() knn = KNeighborsClassifier() svc = SVC() rg = RidgeClassifier() clf_array = [rf, et, knn, svc, rg] for clf in clf_array: vanilla_scores = cross_val_score(clf, X, y, cv=10, n_jobs=-1) bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=seed) bagging_scores = cross_val_score(bagging_clf, X, y, cv=10, n_jobs=-1) print \u0026quot;Mean of: {1:.3f}, std: (+/-) {2:.3f [{0}]\u0026quot; .format(clf.__class__.__name__, vanilla_scores.mean(), vanilla_scores.std()) print \u0026quot;Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\u0026quot; .format(clf.__class__.__name__, bagging_scores.mean(), bagging_scores.std())  Mean of: 0.632, std: (+/-) 0.081 [RandomForestClassifier] Mean of: 0.639, std: (+/-) 0.069 [Bagging RandomForestClassifier] Mean of: 0.636, std: (+/-) 0.080 [ExtraTreesClassifier] Mean of: 0.654, std: (+/-) 0.073 [Bagging ExtraTreesClassifier] Mean of: 0.500, std: (+/-) 0.086 [KNeighborsClassifier] Mean of: 0.535, std: (+/-) 0.111 [Bagging KNeighborsClassifier] Mean of: 0.465, std: (+/-) 0.085 [SVC] Mean of: 0.535, std: (+/-) 0.083 [Bagging SVC] Mean of: 0.639, std: (+/-) 0.050 [RidgeClassifier] Mean of: 0.597, std: (+/-) 0.045 [Bagging RidgeClassifier]  åœ¨åšcross validation éªŒè¯çš„æ—¶å€™ï¼Œåªæœ‰ridge classifierçš„å‡†ç¡®ç‡ä¸‹é™äº†ï¼Œå…¶ä»–çš„æ–¹æ³•éƒ½èƒ½æé«˜accuracyã€‚\né‚£ç°åœ¨bagged classifieréƒ½æ¯”åŸæ¥å¥½äº†ï¼Œæˆ‘ä»¬é€‰æ‹©å“ªä¸ªå‘¢ï¼Ÿ\nVotingï¼Œå¯ä»¥åšhard votingæˆ–è€…soft votingï¼ˆvote by weightï¼‰ã€\nä»¥ä¸‹æ˜¯hard voting\nå®é™…æƒ…å†µï¼Œweightæ˜¯æ¯”è¾ƒéš¾è°ƒæ•´çš„ã€‚\nBoosting to decreasing the modelâ€™s bias é›†åˆweak classifierï¼Œé™ä½error rateã€‚ç›¸å½“äºsequentialï¼Œåªèƒ½ä¸€ä¸ªä¸ªè¿›è¡Œã€‚\nä»£è¡¨modelï¼šAdaboost\n find a weak classifer with less then 50% accuracy. æƒ©ç½šåˆ†ç±»ç»“æœï¼Œé”™è¯¯çš„å¢åŠ weightï¼Œæ­£ç¡®çš„é™ä½weight ç»§ç»­train  åˆå¯ä»¥æ¼”åŒ–ä¸ºGradient Boosting\nStacking to increasing the predictive force of the classifier. stacking ä¸»è¦å°±æ˜¯å°†å¤šä¸ªè®­ç»ƒå¥½çš„æ¯”è¾ƒè´Ÿè´£æ¨¡å‹çš„output ä½œä¸ºLogistics Regression1çš„inputã€‚\n å…¶å®ä»”ç»†æ€è€ƒä¸‹æœ‰ç‚¹åƒç¥ç»ç½‘ç»œçš„fine tunedã€‚\n åœ¨Kaggleä¸­æœ€å¹¿æ³›è¢«ä½¿ç”¨å°±æ˜¯stacking\nå› ä¸ºå¯ä»¥å¹¶è¡Œè®­ç»ƒï¼Œå¤šä¸ªä¸åŒmodelä¹‹é—´weightè®¾ç½®å¥½å¯ä»¥æ¶ˆé™¤variance\nä¸‹é¢æ˜¯ä¸€ä¸ªæ¯”èµ›ç¬¬ä¸‰åé‡‡ç”¨æ–¹æ³•\n My final submission is ensemble of resnet34 x 5, inception-v3 and se-resnext50\n   Model GPUs Image size Training Epochs Training Time     resnet34 1x TitanX 512 40 16 hours   inception-v3 3x TitanX 1024 27 1day 15 hours   se-resnext50 2x TitanX 1024 22 2days 15 hours     ä»€ä¹ˆæ˜¯TTA Test Time Augmentation\ncitedï¼šhttps://towardsdatascience.com/augmentation-for-image-classification-24ffcbc38833\nå› ä¸ºå¯¹æ¯”åº¦ï¼Œæˆªå–ç­‰åŸå› å¯èƒ½misclassifiedï¼Œå¯ä»¥ä½¿ç”¨TTA\nTo mitigate errors such as these we use TTA wherein we predict class for the original test image along with 4 random tranforms of the same image. We then take an average of the predictions to determine which class the image belongs to.\n The intuition behind this is that even if the test image is not too easy to make a prediction, the transformations change it such that the model has higher chances of capturing the dog/cat shape and predicting accordingly.\n ç®€å•æ¥è¯´å°±æ˜¯åŒä¸€ç§imageï¼Œé‡‡ç”¨ä¸åŒtransformï¼Œç„¶åå–average predictionã€‚å½“åŒä¸€ä¸ªå›¾ç‰‡æœ‰ä¸åŒçš„å˜æ¢ï¼Œmodelæ›´å®¹æ˜“learnåˆ°featureã€‚\nå½“ç„¶ç°åœ¨GAN èƒ½ç”Ÿæˆæ›´å¤šæ›´å¤æ‚çš„å›¾ç‰‡äº†å‚è€ƒï¼šhttps://arxiv.org/pdf/1712.04621.pdf\n","date":1587842825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"a667464f4bde667d37be950a8981a824","permalink":"https://faithio.cn/post/ensemble-methods/","publishdate":"2020-04-25T15:27:05-04:00","relpermalink":"/post/ensemble-methods/","section":"post","summary":"è®²è®²Ensemble Methodsçš„Boosting/Bagging/Stacking åœ¨Kaggleæ¯”èµ›æœ€åéƒ½ä¼šç”¨åˆ°Ensemble Meth","tags":[],"title":"Ensemble Methods","type":"post"},{"authors":[],"categories":[],"content":"Both of Cross-entropy and KL divergence are tools to measure the distance between two probability distribution. What is the difference?\nğ»(ğ‘ƒ,ğ‘„)=âˆ’âˆ‘ğ‘¥ğ‘ƒ(ğ‘¥)logğ‘„(ğ‘¥)H(P,Q)=âˆ’âˆ‘xP(x)logâ¡Q(x)\nğ¾ğ¿(ğ‘ƒ|ğ‘„)=âˆ‘ğ‘¥ğ‘ƒ(ğ‘¥)logğ‘ƒ(ğ‘¥)ğ‘„(ğ‘¥)KL(P|Q)=âˆ‘xP(x)logâ¡P(x)Q(x)\nMoreover, minimization of KL is equivalent to minimization of Cross-Entropy.\nI want to know them instinctively.\nYou will need some conditions to claim the equivalence between minimizing cross entropy and minimizing KL divergence. I will put your question under the context of classification problems using cross entropy as loss functions.\nLet us first recall that entropy is used to measure the uncertainty of a system, which is defined as\nğ‘†(ğ‘£)=âˆ’âˆ‘ğ‘–ğ‘(ğ‘£ğ‘–)logğ‘(ğ‘£ğ‘–),S(v)=âˆ’âˆ‘ip(vi)logâ¡p(vi),\nfor\nFor instance, the event A I will die eventually is almost certain (maybe we can solve the aging problem for word almost), therefore it has low entropy which requires only the information of the aging problem cannot be solved to make it certain. However, the event B The president will die in 50 years is much more uncertain than A, thus it needs more information to remove the uncertainties.\nNow look at the definition of KL divergence between events A and B\nğ·ğ¾ğ¿(ğ´âˆ¥ğµ)=âˆ‘ğ‘–ğ‘ğ´(ğ‘£ğ‘–)logğ‘ğ´(ğ‘£ğ‘–)âˆ’ğ‘ğ´(ğ‘£ğ‘–)logğ‘ğµ(ğ‘£ğ‘–),DKL(Aâˆ¥B)=âˆ‘ipA(vi)logâ¡pA(vi)âˆ’pA(vi)logâ¡pB(vi),\nwhere the first term of the right hand side is the entropy of event A, the second term can be interpreted as the expectation of event B in terms of event A. And the\nTo relate cross entropy to entropy and KL divergence, we formalize the cross entropy in terms of events A and B as\nğ»(ğ´,ğµ)=âˆ’âˆ‘ğ‘–ğ‘ğ´(ğ‘£ğ‘–)logğ‘ğµ(ğ‘£ğ‘–).H(A,B)=âˆ’âˆ‘ipA(vi)logâ¡pB(vi).\nFrom the definitions, we can easily seeğ»(ğ´,ğµ)=ğ·ğ¾ğ¿(ğ´âˆ¥ğµ)+ğ‘†ğ´.H(A,B)=DKL(Aâˆ¥B)+SA. .\nA further question follows naturally as how the entropy can be a constant. In a machine learning task, we start with a dataset (denoted as ğ‘ƒ(îˆ°)P(D)) which represent the problem to be solved, and the learning purpose is to make the model estimated distribution (denoted as ğ‘ƒ(ğ‘šğ‘œğ‘‘ğ‘’ğ‘™)P(model)) as close as possible to true distribution of the problem (denoted as ğ‘ƒ(ğ‘¡ğ‘Ÿğ‘¢ğ‘¡â„)P(truth)). ğ‘ƒ(ğ‘¡ğ‘Ÿğ‘¢ğ‘¡â„)P(truth) is unknown and represented by ğ‘ƒ(îˆ°)P(D). Therefore in an ideal world, we expect\nğ‘ƒ(ğ‘šğ‘œğ‘‘ğ‘’ğ‘™)â‰ˆğ‘ƒ(îˆ°)â‰ˆğ‘ƒ(ğ‘¡ğ‘Ÿğ‘¢ğ‘¡â„)P(model)â‰ˆP(D)â‰ˆP(truth)\nand minimize . And luckily, in practiceîˆ°Dis given, which means its entropyğ‘†(ğ·)S(D)is fixed as a constant.\n","date":1587836497,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"8372b9139b33d3334de203cf7f9bc11b","permalink":"https://faithio.cn/post/crossentropy-vs-kl-divergence/","publishdate":"2020-04-25T13:41:37-04:00","relpermalink":"/post/crossentropy-vs-kl-divergence/","section":"post","summary":"Both of Cross-entropy and KL divergence are tools to measure the distance between two probability distribution. What is the difference?\nğ»(ğ‘ƒ,ğ‘„)=âˆ’âˆ‘ğ‘¥ğ‘ƒ(ğ‘¥)logğ‘„(ğ‘¥)H(P,Q)=âˆ’âˆ‘xP(x)logâ¡Q(x)\nğ¾ğ¿(ğ‘ƒ|ğ‘„)=âˆ‘ğ‘¥ğ‘ƒ(ğ‘¥)logğ‘ƒ(ğ‘¥)ğ‘„(ğ‘¥)KL(P|Q)=âˆ‘xP(x)logâ¡P(x)Q(x)\nMoreover, minimization of KL is equivalent to minimization of Cross-Entropy.\nI want to know them instinctively.\nYou will need some conditions to claim the equivalence between minimizing cross entropy and minimizing KL divergence. I will put your question under the context of classification problems using cross entropy as loss functions.","tags":[],"title":"CrossEntropy vs KL Divergence","type":"post"},{"authors":[],"categories":[],"content":" Why use GNN?\nClassificationé—®é¢˜ï¼Œä¸¢ä¸€ä¸ªæ²¡æœ‰è§è¿‡çš„å›¾ç‰‡è¿›å»\næ€ä¹ˆçŸ¥é“node å’Œ edgeçš„ feature\nNN4G Aggregation Readout DCNN DGC MoNet GAT GIN dgl.ai\nGraph Signal Processing and Spectral-based GNN ","date":1587308472,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"0eec5fe9e6c0716cf0513348d26681c0","permalink":"https://faithio.cn/post/gnn/","publishdate":"2020-04-19T11:01:12-04:00","relpermalink":"/post/gnn/","section":"post","summary":"Why use GNN? Classificationé—®é¢˜ï¼Œä¸¢ä¸€ä¸ªæ²¡æœ‰è§è¿‡çš„å›¾ç‰‡è¿›å» æ€ä¹ˆçŸ¥é“node å’Œ edgeçš„ feature NN4G Aggregation Readout DCNN DGC MoNet GAT GIN dgl.ai Graph Signal Processing and Spectral-based GNN","tags":[],"title":"GNN","type":"post"},{"authors":[],"categories":[],"content":" Adaptive Learning Rates  ä¸å¢åŠ è¿ç®—é‡çš„æƒ…å†µä¸‹ï¼Œç®—äºŒæ¬¡å¾®åˆ†ï¼Œå…¶å®æ˜¯é‡‡æ ·\n Stochastic Gradient Descent Feature scaling  x1å¯¹æ¢¯åº¦å½±å“å¾ˆå°ï¼Œupdateæ…¢ï¼Œ error surface ä¸ä¸€æ ·ï¼Œæ­£åœ†é€Ÿåº¦æ›´å¿«\n Gradient Descent Theory Limitation of Gradient Descent New Optimizers for deep learning Exponential moving average (EMA)\næ‰¾åˆ°ä¸€ç»„å‚æ•°ä½¿å¾—Loss functionçš„å’Œæœ€å°\nOptimizer: Real Application Bert: QA/æ–‡ç« ç”Ÿæˆ/é˜…è¯»ç†è§£\ntransformerï¼š ç¿»è¯‘\nTacotronï¼šè¯­éŸ³ç”Ÿæˆ\nBig-Gan\nMEMOï¼šåœ¨ä¸åŒåˆ†ç±»å­¦ä¹ å…±åŒçš„åˆ†ç±»\néƒ½æ˜¯Adam\nYOLOï¼šå½±åƒä¾¦æµ‹\nMask R-CNN\nResNet\néƒ½æ˜¯ï¼ˆSGDMï¼‰\nhttps://shaoanlu.wordpress.com/2017/05/29/sgd-all-which-one-is-the-best-optimizer-dogs-vs-cats-toy-experiment/\nSGDM æ¯”è¾ƒç¨³å®šï¼Œä¸ä¼šæœ‰å¾ˆå¤§è½å·®ï¼Œcovergeå¾ˆå¥½ã€‚\nTtrainingå’Œtestingçš„functionæœ‰å·®å¼‚ã€‚\nSWATS ä»€ä¹ˆåˆ‡æ¢ç‚¹ä¸å¤ªåˆé€‚ï¼Œæ²¡æœ‰è¯æ˜ã€‚Adamæ˜¯adaptiveï¼Œä¼šè¢«åˆ†æ¯å½±å“\nåˆ‡æ¢çš„æ–¹æ³•ä¸ç§‘å­¦\nAdamçš„é—®é¢˜\nAMSGrad adaptive learning rate å¯ä»¥åŠ¨æ€è°ƒæ•´ï¼Œéœ€è¦å¤§æ­¥èµ°å¤§æ­¥ï¼Œå¹³ç¼“çš„åœ°æ–¹å¯ä»¥å¤§æ­¥èµ°è¿‡å»ã€‚\nLR range test Cyclical LR learning rate å¤§çš„æ—¶å€™å°±æ˜¯exploringï¼Œå°çš„æ—¶å€™fine-tuning, step sizeå¦‚ä½•è®¾è®¡ï¼Ÿ\nDoes Adam need warm-up? æ€»ç»“ ","date":1587135393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"c43035c82a56d3f87b7c42d9cf68bf8a","permalink":"https://faithio.cn/post/gradient-descent/","publishdate":"2020-04-17T10:56:33-04:00","relpermalink":"/post/gradient-descent/","section":"post","summary":"Adaptive Learning Rates ä¸å¢åŠ è¿ç®—é‡çš„æƒ…å†µä¸‹ï¼Œç®—äºŒæ¬¡å¾®åˆ†ï¼Œå…¶å®æ˜¯é‡‡æ · Stochastic Gradient Descent Feature scaling x1å¯¹æ¢¯åº¦å½±å“å¾ˆå°ï¼Œupdateæ…¢ï¼Œ error surface ä¸ä¸€æ ·ï¼Œæ­£åœ†é€Ÿåº¦æ›´å¿« Gradient Descent Theory Limitation of Gradient Descent New Optimizers for","tags":[],"title":"Gradient Descent","type":"post"},{"authors":[],"categories":[],"content":" bert - semi-supervisored learning\nRNN - Hard to parallel\nCNN can parallel, ä½†æ˜¯éœ€è¦å å¾ˆé•¿æ—¶é—´çš„å’¨è¯¢\nå¯ä»¥å®Œå…¨æ›¿ä»£RNNï¼Œä¹Ÿæ˜¯sequence2sequenceçš„æ¨¡å‹\né™¤ä»¥dimensionsæ˜¯ä¸ºäº†å‡å°‘varianceï¼Œç›¸ä¹˜ä¼šäº§ç”Ÿæ›´å¤šerror\nSummary å˜å½¢ ä½ç½®å¹¶ä¸é‡è¦ï¼ˆå¤©æ¶¯è‹¥æ¯”é‚»ï¼‰\nseq2seq mask: åªä¼šattend äº§ç”Ÿå‡ºæ¥çš„sequenceã€‚\n","date":1587008752,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"77d740a99bda7443b0674a7a636abf6b","permalink":"https://faithio.cn/post/transformer/","publishdate":"2020-04-15T23:45:52-04:00","relpermalink":"/post/transformer/","section":"post","summary":"bert - semi-supervisored learning RNN - Hard to parallel CNN can parallel, ä½†æ˜¯éœ€è¦å å¾ˆé•¿æ—¶é—´çš„å’¨è¯¢ å¯ä»¥å®Œå…¨æ›¿ä»£RNNï¼Œä¹Ÿæ˜¯sequence2sequenceçš„æ¨¡å‹ é™¤ä»¥dimensionsæ˜¯ä¸º","tags":[],"title":"Transformer","type":"post"},{"authors":[],"categories":[],"content":" Generating Word Vector is unsupervised.\nHow about auto-encoder?\nCount based Prediction-based å°±ä¹Ÿæ˜¯one of encodingï¼Œoutput æ¥è¿‘\nå˜å½¢  ä¸æ˜¯deep ï¼Œåªæ˜¯ä¸€ä¸ªlinear hidden layerã€‚\n æœ‰å¾ˆå¤štipï¼Œå¾ˆå¤šäººå…¶å®ä¹Ÿåšè¿‡ï¼Œå¹¶ä¸”ç”¨deepã€‚ä¸ç”¨deepå¯ä»¥åšå¾ˆå¤šè¿ç®—é‡   Unsupervised Learning: Neighbor Embedding TSNE\nx\u0026ndash;\u0026gt;zæ²¡æœ‰å¾ˆå¥½çš„ä¾æ®\nELMO/BERT/GPT\nå¦‚æœåŒä¸€ä¸ªè¯æ±‡æœ‰å¤šç§senses\nä¸åŒæ„æ€çš„tokenåŒæ ·çš„typeä¹Ÿæœ‰ä¸åŒçš„embedding\nè¿‡å»æ˜¯æŸ¥å­—å…¸ï¼Œç”¨ä¸åŒçš„embedding\nç„¶åæ¯ä¸ªword token has its own embedding\nELMO Embeddings from Language Model\nä¸åŒè¯­ä¹‰ä¸‹çš„hidden layerçš„input ä½œä¸ºContextualized embedding\nä¸åŒçš„äººç‰©å–çš„hidderlayerä¸ä¸€æ ·\nSRL:\nCoref: ä»£åè¯æ‰¾åˆ°äººç‰©æ‰¾å‡º\nSNLI:\nSQuAD: QAé—®é¢˜\nSST-5: Semantic classification\nBidirectional Encoder Representations from Transformers (BERT) è®­ç»ƒbertçš„æ—¶å€™ï¼Œä¸­æ–‡æœ€å¥½ç”¨å­—æ›´å¥½ï¼Œinput wordï¼Œä¼šäº§å‡ºä¸€å †embedding\nä¸­æ–‡çš„å­—ï¼Œå¸¸ç”¨çš„åªæœ‰4k one of encoding å°å¾ˆå¤šï¼Œä½†æ˜¯è¯éƒ½æ˜¯æ— ç©·\ntraining ç¬¬ä¸€ç§\néšæœºæŒ–ç©º15%mask ç„¶åé¢„æµ‹ã€‚ä¸¤ä¸ªè¯å¡«åœ¨è¿™é‡Œæ²¡æœ‰è¿å’Œæ„Ÿå°±è¡¨ç¤ºæœ‰ç±»ä¼¼çš„embedding\nç¬¬äºŒç§æ–¹æ³•ï¼š\nSEP: åˆ†ç•Œã€‚\nCLSï¼šclassificationã€‚åœ¨è¿™å¼€å¤´è¡¨ç¤ºè¦åšåˆ†ç±»ã€‚ä¸ºä»€ä¹ˆæ”¾å¼€å¤´ï¼Ÿ\nå¦‚æœæ˜¯RNNç»“æ„ï¼Œæ”¾åœ¨å°¾éƒ¨æ¯”è¾ƒåˆç†ï¼Œå› ä¸ºå°¾éƒ¨æ‰ä¼šè¾“å‡ºã€‚ä½†æ˜¯bertå†…éƒ¨æ˜¯transformerï¼Œä¸¤ä¸ªç›¸é‚»æˆ–è€…å¾ˆè¿œçš„æ²¡æœ‰å·®åˆ«ã€‚å¯¹äºæ”¾åœ¨å“ªé‡ŒåŒºåˆ«ä¸å¤§\nè¿™ä¸¤ä¸ªæ–¹æ³•éœ€è¦åŒæ—¶ä½¿ç”¨ï¼Œæ•ˆæœæœ€å¥½\nåœ¨CLSå‰é¢æ”¾ä¸€ä¸ªç±»å‹ï¼Œ24å±‚æˆ–è€…48å±‚ï¼Œæ–‡æœ¬åˆ†ç±»ï¼Œæƒ…æ„Ÿåˆ†ç±»\nSlot fillingï¼ŒæŒ–è¯å¡«ç©º\nNatural Language Inferenceï¼Œå›ç­”å¯¹é”™\nå…¶å®æ˜¯åˆ†ç±»ï¼Œåªæœ‰ä¸‰ç±»\nExtraction-based Question Answering é˜…è¯»ç†è§£\næ€ä¹ˆtrainå‘¢ï¼Ÿ\næ©™è‰²çš„sï¼Œè“è‰²çš„æ˜¯eï¼Œæ¯æ¬¡éƒ½åšç±»ä¼¼attentionçš„åŠ¨ä½œã€‚è¿™äº›è¯æ±‡æ¥è‡ªäºæ–‡ç« ã€‚å–æœ€é«˜çš„æ¦‚ç‡\nS=3ï¼Œe=2 å°±æ˜¯æ­¤é¢˜æ— è§£\nEnhanced Representation through Knowledge Integration (ERNIE) ä¸ºä¸­æ–‡è®¾è®¡çš„\nbert trained byå…¶ä»–è¯­è¨€æ–‡æœ¬åˆ†ç±»ï¼Œä½†æ˜¯å¯ä»¥å¿«é€Ÿå­¦ä¼šä¸­æ–‡çš„åˆ†ç±»\nGenerative Pre-Training (GPT) ","date":1586990905,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"dda22775532b33c5619df28e8a31ac26","permalink":"https://faithio.cn/post/wordembeddingelmobert/","publishdate":"2020-04-15T18:48:25-04:00","relpermalink":"/post/wordembeddingelmobert/","section":"post","summary":"Generating Word Vector is unsupervised. How about auto-encoder? Count based Prediction-based å°±ä¹Ÿæ˜¯one of encodingï¼Œoutput æ¥è¿‘ å˜å½¢ ä¸æ˜¯deep ï¼Œåªæ˜¯ä¸€ä¸ªlinear hidden layerã€‚ æœ‰å¾ˆå¤štipï¼Œå¾ˆå¤š","tags":[],"title":"Embedding","type":"post"},{"authors":[],"categories":[],"content":"","date":1586983342,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"6a6faa41c8fe066312ffcd4736cb727d","permalink":"https://faithio.cn/post/ml-2020/","publishdate":"2020-04-15T16:42:22-04:00","relpermalink":"/post/ml-2020/","section":"post","summary":"","tags":[],"title":"ML 2020","type":"post"},{"authors":[],"categories":[],"content":" Pre-training  unlabled dataæœ‰å¤§é‡ï¼Œå¯ä»¥å…ˆè®­ç»ƒå¥½ï¼Œæœ€åå†ç”¨labled data train ä¸€ä¸‹å°±å¥½\n CNN ","date":1586485145,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"947f4a41a0400747495afbd92f3bb7e7","permalink":"https://faithio.cn/post/auto-encoder/","publishdate":"2020-04-09T22:19:05-04:00","relpermalink":"/post/auto-encoder/","section":"post","summary":"Pre-training unlabled dataæœ‰å¤§é‡ï¼Œå¯ä»¥å…ˆè®­ç»ƒå¥½ï¼Œæœ€åå†ç”¨labled data train ä¸€ä¸‹å°±å¥½ CNN","tags":[],"title":"Auto Encoder","type":"post"},{"authors":[],"categories":[],"content":" HMM Step1 Step2 ","date":1586466969,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"dfad30ea5c8945132281581b39194905","permalink":"https://faithio.cn/post/structured-learning/","publishdate":"2020-04-09T17:16:09-04:00","relpermalink":"/post/structured-learning/","section":"post","summary":" HMM Step1 Step2 ","tags":[],"title":"Structured Learning","type":"post"},{"authors":[],"categories":[],"content":" http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/\nGate function uses sigmoid, but not ReLu\nRNN çš„big problems  RNNä¸å¥½è®­ç»ƒä¸æ˜¯å› ä¸ºactivation functionï¼Œè€Œæ˜¯æ¥è‡ªtime sequenceï¼ŒåŒæ ·çš„weightï¼Œåœ¨ä¸åŒçš„æ—¶é—´ç‚¹åå¤ä½¿ç”¨\n LSTM å¯ä»¥è®©RNNçš„error surface ä¸é‚£ä¹ˆå´å²–ï¼Œå¯ä»¥æŠŠå¹³å¦çš„åœ°æ–¹æ‹¿æ‰ï¼Œgradient vanishing but not gradient explodeã€‚\nlearning rate å°çš„æ—¶å€™è®­ç»ƒï¼Œæ²¡æœ‰å¹³å°è®­ç»ƒã€‚\nä¸ºä»€ä¹ˆhandling gradient vanishingï¼Ÿ\nRNNï¼šmemoryçš„å€¼æ¯æ¬¡éƒ½ä¼šè¢«æ´—æ‰\nLSTMï¼šmemory ä¹˜ä»¥forget gateå†åŠ èµ·inputçš„å€¼ï¼Œ memoryå’Œinputç›¸åŠ çš„ã€‚åªè¦forget gate openå°±ä¸ä¼šæ¸…é™¤memoryï¼Œæ‰€ä»¥ä¸ä¼šæœ‰gradient vanishingã€‚\n å»ºè®®ä¸è¦ç»™forget gateå¾ˆå¤§çš„biasï¼Œç¡®ä¿å®ƒå¤šæ•°æƒ…å†µå¼€å¯ã€‚\n  å‚æ•°æ¯”è¾ƒå°‘ï¼ŒLSTMå¦‚æœoverfitingï¼Œå¯ä»¥å°è¯•GRUã€‚\nGRUï¼š input gate/ forget gateè”åŠ¨ï¼Œinput æ‰“å¼€çš„æ—¶å€™ï¼Œforgetå…³é—­ï¼Œæ´—æ‰memoryã€‚è¦æ¸…æ‰memoryæ‰èƒ½æ”¾æ–°å€¼ã€‚\n  å¦‚æœç”¨identity matrix åˆå§‹åŒ–ï¼Œå°±æ˜¯ReLu ä½œä¸ºactivation functionï¼Œæ•ˆæœå¾ˆå¥½ã€‚åŠæ‰“LSTMï¼\nå¦‚æœæ˜¯randomï¼Œå°±ç”¨sigmoid ä½œä¸ºactivation functionã€‚\n Attention-based model(Memory) RNN output \u0026ndash;\u0026gt; HMM/CRF(input)\n","date":1586403161,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586466803,"objectID":"726ed725854b5f265031c5e90bcb7807","permalink":"https://faithio.cn/post/rnn/","publishdate":"2020-04-08T23:32:41-04:00","relpermalink":"/post/rnn/","section":"post","summary":"http://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/DNN%20backprop.ecm.mp4/ Gate function uses sigmoid, but not ReLu RNN çš„big problems RNNä¸å¥½è®­ç»ƒä¸æ˜¯å› ä¸ºactivation functionï¼Œè€Œæ˜¯æ¥è‡ªtime sequenceï¼ŒåŒæ ·çš„weight","tags":[],"title":"RNN","type":"post"},{"authors":[],"categories":[],"content":" dropout linear å¥½ \u0026ndash;\u0026gt;ReLU/maxout å¥½\n ##ResNet\n","date":1586399414,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"ef8aeccdbe56db07f0af0a93a9e02c54","permalink":"https://faithio.cn/post/cnn/","publishdate":"2020-04-08T22:30:14-04:00","relpermalink":"/post/cnn/","section":"post","summary":"dropout linear å¥½ \u0026ndash;\u0026gt;ReLU/maxout å¥½ ##ResNet","tags":[],"title":"CNN","type":"post"},{"authors":[],"categories":[],"content":" $$ \\begin{array}{l}P(Y | X)=\\frac{P(X | Y) P(Y)}{P(X)} \\propto(P(X | Y) \\cdot P(Y) \\ M A P \\ P(Y=0 | X) \\Rightarrow P(Y=1 | X)\\end{array} $$\nClassification æ”¹è¿›  ä¸åŒçš„classå¯ä»¥shareå‚æ•°ï¼Œå¦‚æœå‚æ•°è¶Šå¤šï¼Œvarianceä¼šè¶Šå¤§ï¼Œå°±ä¼šå¯¼è‡´overfitingã€‚Featureå’Œcovarianceçš„å¹³æ–¹æˆæ­£æ¯”\n  å½“Gaussian å…±ç”¨covarianceçš„æ—¶å€™ï¼Œboundaryå°±æ˜¯linearçš„ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥æˆä¸ºlinear modelã€‚ä½†æ˜¯å¦‚æœä¸å…±ç”¨covarianceå°±ä¸æ˜¯linearçš„\n ç®€å•çš„æ¨¡å‹ï¼Œå‚æ•°å°‘ï¼Œbiaså¤§ï¼Œvarianceå°\nå¤æ‚çš„æ¨¡å‹ï¼Œå‚æ•°å¤šï¼Œbiaså°ï¼Œvarianceå¤§\n covarianceé™¤äº†å¯¹è§’çº¿éƒ½æ˜¯é›¶ï¼Œå±æ€§ä¸å±æ€§ä¹‹é—´æ˜¯independent\n Logistic Regression  Cross entropy\n  ä¸ºä»€ä¹ˆé€»è¾‘å›å½’ä¸ç”¨square erroræ¥å®šä¹‰loss functionå‘¢ï¼Ÿ\n  å¯ä»¥é€šè¿‡è§£least square errorçš„æ–¹å¼ï¼Œæ‰¾æœ€ä½³è§£ï¼Œç„¶ååˆå§‹åŒ–\n Why Logistic Regression cannot use square error Discriminative vs Generative Gaussian å±äºGenerativeï¼Œä½†æ˜¯covarianceshareçš„è¯ï¼Œmodelæ˜¯ä¸€æ ·çš„\næ‰¾å‡ºçš„parameter w bæ˜¯ä¸ä¸€æ ·çš„\nå¦‚æœå½“å‰labelæœ‰é—®é¢˜ï¼Œdataæ˜¯æœ‰noiseçš„ï¼Œgenerative modelåšäº†ä¸€äº›å¼ºçš„å‡è®¾å°±å¯ä»¥æ’é™¤å¹²æ‰°ã€‚\nprior å’Œ class-dependent probabilityæ¥è‡ªä¸åŒçš„åˆ†å¸ƒï¼Œè¯­éŸ³è¾¨è¯†ï¼Œprioræ˜¯ä»ç½‘ç»œä¸Šæ”¶é›†çš„æ–‡æœ¬ï¼ˆæŸä¸€å¥è¯è¯´å‡ºçš„å‡ ç‡ï¼‰ï¼Œclass-dependentæ‰æ˜¯å£°éŸ³å’Œæ–‡æœ¬çš„ç»“åˆã€‚\næ‰€ä»¥æ•´ä¸ªç³»ç»Ÿæ˜¯generativeçš„ç³»ç»Ÿ\nMultilass å› ä¸ºæœ‰exponential å¤§çš„å€¼å’Œå°çš„å€¼ä¼šè¢«æ‹‰çš„æ›´å¼€ï¼Œä¸€å®šæ˜¯æ­£çš„ã€‚total sum æ˜¯ï¼Œå› ä¸ºåšäº†normalizationã€‚ï¼ˆsoftmaxæ˜¯å¼ºåŒ–ï¼‰\nSoftmax outputç”¨æ¥ç»Ÿè®¡posterior probabilityã€‚æœ‰ä¸‰ä¸ªclassï¼Œ gaussianï¼Œå…±ç”¨covariance matrixï¼Œå°±ä¼šå¾—åˆ°softmaxã€‚ï¼ˆMaximum entropyå’ŒLogistic regressionä¸€æ ·çš„ï¼‰\nXORé—®é¢˜ ","date":1586273008,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"852281a8c886216194a5c29b9c39b138","permalink":"https://faithio.cn/post/classification/","publishdate":"2020-04-07T11:23:28-04:00","relpermalink":"/post/classification/","section":"post","summary":"$$ \\begin{array}{l}P(Y | X)=\\frac{P(X | Y) P(Y)}{P(X)} \\propto(P(X | Y) \\cdot P(Y) \\ M A P \\ P(Y=0 | X) \\Rightarrow P(Y=1 | X)\\end{array} $$ Classification æ”¹è¿› ä¸åŒçš„classå¯ä»¥shareå‚æ•°ï¼Œå¦‚æœå‚æ•°è¶Šå¤šï¼Œvarianceä¼šè¶Šå¤§ï¼Œå°±ä¼šå¯¼è‡´o","tags":[],"title":"Classification","type":"post"},{"authors":[],"categories":[],"content":" kernel method è¯æ˜ linear SVM vs Logistics Regression åŒºåˆ«åœ¨äºloss function.\nå¦‚æœæ˜¯hinge loss å°±æ˜¯linear SVM\nCross Entropy å°±æ˜¯logistics regression\nSVMä¹Ÿæœ‰deep ç‰ˆæœ¬ï¼Œfunctionä¹Ÿä¸ä¸€å®šæ˜¯linearã€‚Deeplearningç”¨HingeLoss ä½œä¸ºloss functionå°±æ˜¯Deep SVM\nKernel method Kernel trick Radial basic function kernel - RBF å¾ˆå®¹æ˜“å‡ºç°overfiting\nSigmoid kernel å¯ä»¥ç›´æ¥è®¾è®¡kernel function\nxæ˜¯structured data like sequenceï¼Œæ¯ä¸ªsequenceçš„é•¿åº¦ä¸ä¸€æ ·ã€‚\nkernel ç±»ä¼¼äºå®šä¹‰similarityã€‚\nMercerâ€˜s theory å¯ä»¥æ£€æŸ¥ã€‚\næ€»ç»“  Support vector regressionï¼ˆSVRï¼‰  è¿›å…¥åˆ°æŸä¸€ä¸ªè·ç¦»çš„æ—¶å€™losså°±æ˜¯0\n Ranking SVM è€ƒè™‘outputæ˜¯éœ€è¦æœ‰order listçš„ã€‚åƒrecommendç³»ç»Ÿ\n One-class SVMï¼špositiveçš„è‡ªæˆä¸€ç±»ï¼Œå…¶ä»–çš„æ•£å¼€\n  ","date":1586272919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"039a5aded1ea3595932b885cc9d1a1b6","permalink":"https://faithio.cn/post/svm/","publishdate":"2020-04-07T11:21:59-04:00","relpermalink":"/post/svm/","section":"post","summary":"kernel method è¯æ˜ linear SVM vs Logistics Regression åŒºåˆ«åœ¨äºloss function. å¦‚æœæ˜¯hinge loss å°±æ˜¯linear SVM Cross Entropy å°±æ˜¯logistics regression SVMä¹Ÿæœ‰deep ç‰ˆæœ¬ï¼Œfunction","tags":[],"title":"SVM","type":"post"},{"authors":[],"categories":[],"content":" click here for link\nGAN $$ \\mathcal{KL}(p|q) = E_p[\\log \\frac{p}{q}] \\ \u0026mdash;-\nP_g \\rightarrow \\theta_g \\text{ MLE: } \\thetag = \\arg \\max{\\thetag} \\sum{i=1}^N \\log P_g(xi) = \\arg \\min \\mathcal{KL}(P{data}|P_g) $$\n","date":1586184049,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"1d122806ed4491e33c03463a7e4f4592","permalink":"https://faithio.cn/post/generative-adversarial-network/","publishdate":"2020-04-06T10:40:49-04:00","relpermalink":"/post/generative-adversarial-network/","section":"post","summary":"click here for link\nGAN $$ \\mathcal{KL}(p|q) = E_p[\\log \\frac{p}{q}] \\ \u0026mdash;-\nP_g \\rightarrow \\theta_g \\text{ MLE: } \\thetag = \\arg \\max{\\thetag} \\sum{i=1}^N \\log P_g(xi) = \\arg \\min \\mathcal{KL}(P{data}|P_g) $$","tags":[],"title":"Generative Adversarial Network","type":"post"},{"authors":[],"categories":[],"content":" Neural Networks Basics Logistic Regression as a Neural Network $$ \\hat{y}=\\sigma\\left(w^{T} x+b\\right), \\text { where } \\sigma(z)=\\frac{1}{1+e^{-z}} \\\n\\text { Given }\\left{\\left(x^{(1)}, y^{(1)}\\right), \\ldots,\\left(x^{(m)}, y^{(m)}\\right)\\right}, \\text { want } \\hat{y}^{(i)} \\approx y^{(i)} $$\nLoss(error) function:\nDon\u0026rsquo;t use this, non-convex $$ \\ell(\\hat{y}, y)=\\frac{1}{2}(\\hat{y}-y)^{2} $$ The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. $$ J(w, b)=\\frac{1}{m} \\sum{i=1}^{m} \\mathcal{L}\\left(\\hat{y}^{(i)}, y^{(i)}\\right)=-\\frac{1}{m} \\sum{i=1}^{m} y^{(i)} \\log \\widehat{y}^{(i)}+\\left(1-y^{(i)}\\right) \\log \\left(1-\\hat{y}^{(i)}\\right) $$\n$$ \\text { Want to find } w, b \\text { that minimize } J(w, b) $$\nGradient Desent $$ \\begin{array}{l}\\text { Step } 1: \\frac{d L}{d a} \\ L=-(y \\times \\log (a)+(1-y) \\times \\log (1-a)) \\ \\frac{d L}{d a}=-y \\times \\frac{1}{a}-(1-y) \\times \\frac{1}{1-a} \\times-1\\end{array} $$\n$$ \\begin{align} \\dfrac{d}{dx} \\sigma(x) \u0026amp;= \\dfrac{d}{dx} \\left[ \\dfrac{1}{1 + e^{-x}} \\right] \u0026amp;= \\dfrac{d}{dx} \\left( 1 + \\mathrm{e}^{-x} \\right)^{-1} \u0026amp;= -(1 + e^{-x})^{-2}(-e^{-x}) \u0026amp;= \\dfrac{e^{-x}}{\\left(1 + e^{-x}\\right)^2} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{e^{-x}}{1 + e^{-x}} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\dfrac{(1 + e^{-x}) - 1}{1 + e^{-x}} \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( \\dfrac{1 + e^{-x}}{1 + e^{-x}} - \\dfrac{1}{1 + e^{-x}} \\right) \u0026amp;= \\dfrac{1}{1 + e^{-x}\\ } \\cdot \\left( 1 - \\dfrac{1}{1 + e^{-x}} \\right) \u0026amp;= \\sigma(x) \\cdot (1 - \\sigma(x)) \\end{align} $$\n$$ \\begin{array}{l}\\text { In the previous video, Andrew refers to } d z=a(1-a) \\ \\text { Note that Andrew is using \u0026ldquo;dz\u0026rdquo; as a shorthand to refer to } \\frac{d a}{d z}=a(1-a) \\text { . } \\ \\text { To clarify, earlier in this week\u0026rsquo;s videos, Andrew used the name \u0026ldquo;dz\u0026rdquo; to refer to a different derivative: } \\frac{d L}{d z}=a-y . \\ \\text { Recall that the relationship between } \\frac{d L}{d z} \\text { and } \\frac{d a}{d z} \\text { is: } \\ \\frac{d L}{d z}=\\frac{d L}{d a} \\times \\frac{d a}{d z} \\ \\frac{d L}{d z}=\\frac{a-y}{a(1-a)} \\times a(1-a)=a-y\\end{array} $$\nVectorization Code For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $$ num_px $$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.\nExercise: Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num_px $$ num_px $$ 3, 1).\nA trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$$c$$d, a) is to use:\nX_flatten = X.reshape(X.shape[0], -1).T # X.T is the transpose of X  To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\nOne common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).\nLet\u0026rsquo;s standardize our dataset.\nNeural Network Shallow neural networks Representation Xï¼šç«–æ–¹å‘ features\næ¨ªæ–¹å‘ï¼štraining example\nActivation functionï¼š\n Sigmoid: å¦‚æœoutputæ˜¯binary classificationï¼Œå¯ä»¥è€ƒè™‘sigmoid functionï¼Œä¸€èˆ¬nerver used tanh functionï¼š ReLU Rectified Linear Unit $a = \\max(0, z)$ : by default, å¾ˆå¤šäººç”¨ï¼Œfasterï¼Œslope 1ï¼Œor 0 Leaky ReLU  Why need non-linear activation functions Derivatives of activation functions Gradient descent for Neural Networks np.sum(keepdims=True): prevent rank one arrays\nBackpropagation intuition https://medium.com/@pdquant/all-the-backpropagation-derivatives-d5275f727f60\nhttps://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/3/threads/a38VuhyMEei5zw6yFhWyOg\nRandom Initialization LR can be initialized as 0, but not neural network\nSupplement åŸºç¡€ graph LR; MachineLearning--\u0026gt;é¢‘ç‡/ç»Ÿè®¡æœºå™¨å­¦ä¹ ; é¢‘ç‡/ç»Ÿè®¡æœºå™¨å­¦ä¹ --\u0026gt;æ­£åˆ™åŒ–/L1/L2 é¢‘ç‡/ç»Ÿè®¡æœºå™¨å­¦ä¹ --\u0026gt;æ ¸åŒ– é¢‘ç‡/ç»Ÿè®¡æœºå™¨å­¦ä¹ --\u0026gt;é›†æˆåŒ– é¢‘ç‡/ç»Ÿè®¡æœºå™¨å­¦ä¹ --\u0026gt;å±‚æ¬¡åŒ– å±‚æ¬¡åŒ–--\u0026gt;MultiayerPercepton/MLP å±‚æ¬¡åŒ–--\u0026gt;Autoencoder å±‚æ¬¡åŒ–--\u0026gt;CNN å±‚æ¬¡åŒ–--\u0026gt;RNN MachineLearning--\u0026gt;è´å¶æ–¯æ´¾/PGM è´å¶æ–¯æ´¾/PGM--\u0026gt;BayesianNetwork/æœ‰å‘å›¾ è´å¶æ–¯æ´¾/PGM--\u0026gt;MarkovNetwork/æ— å‘å›¾ è´å¶æ–¯æ´¾/PGM--\u0026gt;MixedNetwork/æœ‰å‘å›¾æ— å‘å›¾ BayesianNetwork/æœ‰å‘å›¾--\u0026gt;DeepDirectedNetwork DeepDirectedNetwork--\u0026gt;SigmoidBeliefNetwork DeepDirectedNetwork--\u0026gt;VAE DeepDirectedNetwork--\u0026gt;GAN MarkovNetwork/æ— å‘å›¾--\u0026gt;DeepBoltzmannNetwork MixedNetwork/æœ‰å‘å›¾æ— å‘å›¾--\u0026gt;DeepBeliefNetwork  ç»Ÿè®¡æœºå™¨å­¦ä¹   æ­£åˆ™åŒ–ï¼šLoss Function + regularizer(L1/L2)\n æ ¸åŒ–: Kernel SVM\n é›†æˆåŒ–: AdaBoost, RandomForest\n å±‚æ¬¡åŒ–: Neural Network/Deep Neural Network\n MLP(Mutilayer Perceptron)\n Autoencoder\n CNN\n RNN\n   è´å¶æ–¯æ´¾  BayesianNetwork $\\Rightarrow$ Deep Directed Network  Sigmoid Belief Network Variational Autoencoder(VAE) GAN  Markov Network $\\Rightarrow$ Deep Boltzmann Network Mixed Netowork $\\Rightarrow$ Deep Belief Network   ä¸Šè¿°éƒ½æ˜¯ï¼šDeep Generative Model\n ç‹­ä¹‰çš„DeepLearningï¼šDeep Neural Network\nå…¶å®åº”è¯¥åŒ…æ‹¬ï¼š\n Deep Neural Network Deep Generative Modelï¼ˆå½“å±‚æ¬¡éå¸¸å¤šï¼Œæ¨æ–­éå¸¸å›°éš¾ï¼‰  æ—¶é—´çº¿  æ·±åº¦å­¦ä¹ çš„ç†è®ºåœ¨2006å¹´å·²ç»æˆå‹ï¼Œç›´åˆ°ç°åœ¨ï¼Œç†è®ºå¹¶æ²¡æœ‰æ ¹æœ¬æ€§çªç ´ã€‚ ä¸ºä»€ä¹ˆtake off  data åˆ†å¸ƒå¼ ç¡¬ä»¶ GPU æ•ˆæœ   Non-Linear Problem Neural Network ç¬¦åˆè¿ç®—-ã€‹å¤åˆè¡¨è¾¾å¼-ã€‰å¤åˆå‡½æ•°\näººå·¥æ™ºèƒ½ ä¸¤å¤§é˜µè¥ ä¸‰å¤§ä¸»ä¹‰ Deep learning HMM-GMM æ¯ä¸ªmodelå°±æ˜¯ä¸€ä¸ªstateï¼Œä½†æ˜¯DNNå°±æ˜¯ä¸€ä¸ªå¤§çš„modelã€‚æ‰€æœ‰çš„stateå…±ç”¨ä¸€ä¸ªDNNã€‚\næ›´åŠ å¤šå±‚çš„DNNï¼Œå…¶å®ä¼šæ›´å°‘neuronsï¼Œæœ€ç»ˆæ˜¯æ›´å°‘çš„å‚æ•°ï¼Œä¸å®¹æ˜“overfiting\nå¤šå±‚å…¶å®å°±æ˜¯å°†ç©ºé—´å¯¹æŠ˜äº†ã€‚\n","date":1585099595,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587936776,"objectID":"80470b31effc764701791a977ec585e6","permalink":"https://faithio.cn/post/deep-learning/","publishdate":"2020-03-24T21:26:35-04:00","relpermalink":"/post/deep-learning/","section":"post","summary":"Neural Networks Basics Logistic Regression as a Neural Network $$ \\hat{y}=\\sigma\\left(w^{T} x+b\\right), \\text { where } \\sigma(z)=\\frac{1}{1+e^{-z}} \\ \\text { Given }\\left{\\left(x^{(1)}, y^{(1)}\\right), \\ldots,\\left(x^{(m)}, y^{(m)}\\right)\\right}, \\text { want } \\hat{y}^{(i)} \\approx y^{(i)} $$ Loss(error) function: Don\u0026rsquo;t use this, non-convex $$ \\ell(\\hat{y}, y)=\\frac{1}{2}(\\hat{y}-y)^{2} $$ The loss function computes the error for a single training example; the cost function is the average of the loss functions of the entire training set. $$","tags":[],"title":"Deep Learning","type":"post"},{"authors":[],"categories":[],"content":" [pdf]\nclick here for link\næ¦‚ç‡å›¾æ¨¡å‹  inference-\u0026gt; $P(Z|X)$-\u0026gt;ç§¯åˆ†é—®é¢˜ï¼ˆMCMCï¼‰\n GMMï¼šæ ·æœ¬ä¹‹é—´æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒ\nHMM: Dynamic Model y: System state éšå˜é‡\n state ç¦»æ•£ï¼šHMM state çº¿æ€§: Kalman Filter state éçº¿æ€§: Particle Filter  $$ \\begin{aligned} \\lambda \u0026amp;= (\\underbrace{\\pi}{åˆå§‹prob dist}, \\underbrace{A}{çŠ¶æ€è½¬ç§»çŸ©é˜µ}, \\underbrace{B}{å‘å°„çŸ©é˜µemission}) \\pi\u0026amp;=\\left(\\pi, \\pi{2}, \\cdots, \\pi{N}\\right), \\sum{i=1}^{K} \\pi_{i}= 1 \\pi_i\u0026amp;= P\\left(i_1=q_i\\right) çŠ¶æ€å˜é‡i:\u0026amp; i_1, i_2, \\cdots i_t \\cdots \\rightarrow Q={q_1, q_2, \\cdots, q_m} è§‚æµ‹å˜é‡o:\u0026amp; o_1, o_2, \\cdots o_t \\cdots \\rightarrow V={v_1, v_2, \\cdots, vm} A\u0026amp;=\\left[a{i j}\\right], a{i j}=P\\left(i{t+1}=q_{i} | it=q{i}\\right) B\u0026amp;=\\left[b{j k} \\right], b{j k}=P\\left(Q{t}=v{k} | it=q{j}\\right) \\\n\\end{aligned} $$\n transition å’Œ emission probability æ˜¯independent\n ä¸¤ä¸ªå‡è®¾ï¼š\n é½æ¬¡Markov å‡è®¾\n $$ \\begin{aligned} \u0026amp;P(i_{t+1}|it, t{t-1}, \\cdots, t_1, ot, o{t-1}, \\dots, o1) = p(i{t+1}|i_t) \\end{aligned} $$\n è§‚å¯Ÿç‹¬ç«‹å‡è®¾ $$ \\begin{aligned} \u0026amp;P(o_{t}|it, t{t-1}, \\cdots, t_1, ot, o{t-1}, \\dots, o1) = p(o{t}|i_t) \\end{aligned} $$\n  ä¸‰ä¸ªé—®é¢˜ï¼š\n Evaluation: $P(O| \\lambda) \\Rightarrow$ å‰å‘åå‘ Forward-backward learning $\\lambda=\\arg \\max P(O|\\lambda)$ EM algorithm\\baum welch Decoding $\\lambda=\\arg \\max_{i} P(I|O)$  é¢„æµ‹ï¼š$P(i_{t+1}|o_1, o_2, \\cdots, o_t)$ æ»¤æ³¢ï¼š$P(i_{t}|o_1, o_2, \\cdots, o_t)$   HMM-Evaluation $$ \\begin{aligned} Give \u0026amp;\\lambda, æ±‚ P(O|\\lambda) P(O | \\lambda) \u0026amp;=\\sum{1} P(I, O | \\lambda)=\\sum{1} P(O | I, \\lambda) \\cdot P(I | \\lambda) \\\nP(I | \\lambda)\u0026amp;=P\\left(i{1}, i{2}, \\cdots, i{T} | \\lambda\\right)=\\underbrace{P\\left(i{T} | i, i{2},\\cdots,i{T-1}, \\lambda\\right)}_{P(iT|i{T-1})=a{i{T-1}, i_T}} P(i_1, i2, \\cdots, i{T-1}|\\lambda) = a{i{T-1}, iT} \\cdot a{i{T-2}, i{T-1}} \\cdots a{i{1}, i_{2}} \\cdot \\pi(i_1) \\\n\u0026amp;\\pi\\text{ æ˜¯åˆå§‹åˆ†å¸ƒ} \u0026amp;= \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{t-1}, it} \u0026mdash;-\np(O | I, \\lambda) \u0026amp; =\\prod{t=1}^{T} b_{it}\\left(O{t}\\right) \\end{aligned} $$\nPPT $$ \\begin{array}{l}P(O | \\lambda)=\\sum{I} P(I, O | \\lambda)=\\sum{I} P(O | I, \\lambda) \\cdot P(I | \\lambda) \\ \\because P(I | \\lambda)=P\\left(i{1}, i{2} \\cdots i{T} | \\lambda\\right)=P\\left(i{i} | i{i}, i{i}, \\ldots{i-1}, \\lambda\\right) \\cdot P\\left(i{i}, i{2}, \\cdots i{t-1}, \\lambda\\right)=\\pi\\left(a{i1}\\right) \\cdot \\prod{t=2}^{T} a_{i-1, i}\n\\ P(0 | I, \\lambda)=\\prod{t=1}^{T} b{t}\\left(O_{t}\\right)\n\\ \\therefore P(O | \\lambda)=\\sum{1} \\pi\\left(a{i{1}}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i{i}}\\left(0{t}\\right)= \\underbrace{ \\sum{i{1}} \\sum{i{2}} \\cdots \\sum{i{T}} }{O(N^T)} \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i}\\left(O{t}\\right)\\end{array} $$\nå‰å‘ç®—æ³• $$ \\begin{array}{l} \\\n\\alpha{t+1}(j) =P\\left(o{0}, \\cdots, o{t}, o{t+1}, i{t+1}=q{j} | \\lambda\\right) \\ =\\sum{i=1}^{N} P\\left(o{1}, \\cdots, o{t}, o{t+1}, i{t+1}=q{j}, i{t}=q{i} | \\lambda\\right) \\ =\\sum{i=1}^{N} P\\left(o{t+1} | o{1}, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{j}, \\lambda\\right) \\cdot P\\left(o1, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{j} | \\lambda\\right)\n\\ =\\sum{i=1}^{N} P\\left(o{t+1} | i{t+1}=q{j} \\right) \\cdot P\\left(o{1}, \\cdots, o{t}, i{t}=q{i}, i{t+1}=q{i} | x\\right)\n\\ =\\sum{i=1}^{N} P\\left(o{t+1} | i{t+1}=q{j}\\right) \\cdot P\\left(i{t+1}=q{j} | o{1}, \\cdots, o{t}, i{i}=q{i}, \\lambda\\right) \\cdot P\\left( o{1}, \\cdots, o{t}, i{i}=q{i} | \\lambda\\right)\n\\ =\\sum{i=1}^{N} \\underbrace{ P\\left(o{t+1} | i{t+1}=q{j}\\right)}_{bj(o{t+1})} \\cdot \\underbrace{P\\left(i{t+1}=q{j} | i{i}=q{i}, \\lambda\\right)}{a{ij}} \\alpha_t(i)\n\\end{array} $$\nåå‘ç®—æ³• $$ \\begin{array}{l} \\\n\\text{çŠ¶æ€ï¼š} \\ \\pi=\\left(\\pi, \\pi{2}, \\cdots, \\pi{N}\\right), \\sum{i=1}^{K} \\pi{i}= 1 \\\n\\begin{aligned}\n\u0026amp; P(o | x)=P(o, \\cdots , o_r| \\lambda)\n\\=\u0026amp; \\sum_{i=1}^{N} p\\left(o1, \\cdots, o{r}, i{1}=q{i} | \\lambda\\right)\n\\=\u0026amp; \\sum{i=1}^{N} p\\left(o{1}, \\cdots, o{r} | i{1}=q_{i}, \\lambda \\right) \\cdot \\underbrace{P(i_1=qi | \\lambda)}{\\pi_i}\n\\=\u0026amp; \\sum_{i=1}^{N} P\\left(o_1| o_2, \\cdots, o_r, i1=q{i}\\right) \\cdot P\\left( o_2, \\cdots, o_r | i1=q{i} \\right)\\cdot \\pi_i\n\\=\u0026amp; \\sum_{i=1}^{N} P\\left(o_1| i1=q{i}\\right) \\beta{1}(i) \\cdot \\pi{i}\n\\=\u0026amp; \\sum{i=1}^{N} b{i}(o1) \\pi{i} \\beta_{1}(i) \u0026mdash; \\\n\u0026amp; \\beta{t}(i)=P\\left(o{t+1}, \\cdots, o{T} | i{t}=q_{i}\\right)\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\cdots, o{T}, i{t+1}=q_{j} | it=q{i}\\right)\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\cdots, o{T} | i{t+1}=q{j}, t{t}=q{i}\\right) \\cdot \\underbrace{ P\\left(i{t-1}=q{j} | i{t}=q{i}\\right) }{a_{ij}}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1}, \\ldots, o{T} | i{t+1}=q{j}\\right) \\cdot a{ij}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1} | o{t+2}, \\cdots, o{T}, i{t+1}=q{j}\\right) \\cdot P\\left(o{t+1}, \\ldots, o{T} | i{t+1}=q{j}\\right) \\cdot a_{i j}\n\\=\u0026amp; \\sum{j=1}^{N} P\\left(o{t+1} | t{t+1}=q{j}\\right) \\quad \\cdot \\quad \\beta{t+1}(j) \\quad \\cdot \\quad a{ij}\n\\ =\u0026amp; \\sum{j=1}^{N} b{j}\\left(o{t+1}\\right) \\cdot a{i j} \\cdot \\beta_{t+1}(j) \\end{aligned}\n\\end{array} $$\nEvaluationæ€»ç»“ $$ \\begin{array}{l}\n\\text{æ¡ä»¶æ¦‚ç‡å¤æ‚åº¦å¾ˆé«˜ï¼š} P(O | \\lambda)=\\sum{I} P(I, O | \\lambda) =\\underbrace{ \\sum{i{1}} \\sum{i{2}} \\cdots \\sum{i{T}} }{O(N^T)} \\pi\\left(a{i}\\right) \\cdot \\prod{t=2}^{T} a{i{i-1}, it} \\prod{t=1}^{T} b{i}\\left(O{t}\\right) \\\n\\alpha_{t}(i)=P(o_1, \\cdots, o_t, i_t=q_i | \\lambda) \\\n\\alpha{T}(i)=P\\left(O, i{T}=q_{i} | \\lambda\\right) \\\nP(O | \\lambda)=\\sum{i=1}^{N} \\alpha{T}(i) \u0026mdash;\n\\beta{t}(i)=P(o{t+1}, \\cdots, o_T |i_t=qi, \\lambda) \\beta{1}(i)=P(o_{2}, \\cdots, o_T |i_1=qi, \\lambda) P(O | \\lambda)=\\sum{i=1}^{N} \\pi{i} b{i}(o1) \\beta{1}(i)\n\\end{array} $$\nå¼•å…¥EMçš„æ€æƒ³ $$ \\begin{aligned}\n\\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \\\n\u0026amp; \\text{x: è§‚æµ‹å€¼O zï¼šéšå˜é‡I(discrete) } \\theta \\text{:å‚æ•° }\\lambda \\\n\\ \\lambda^{(t)}\u0026amp;=\\left(\\pi^{t}, A^{t}, B^{t}\\right) \\lambda^{(t+1)}\u0026amp; =\\arg \\max {\\lambda} \\sum{1} \\log P(O,I |\\lambda) \\cdot\n\\underbrace{P\\left(I|O, \\lambda^{(t)}\\right)}_{ P\\left(I|O, \\lambda^{(t)}\\right) = \\frac{P\\left(I,O| \\lambda^{(t)}\\right)}{P\\left(O, \\lambda ^{(t)}\\right)} }\n= \\arg \\max {\\lambda} \\sum{1} \\log P(O,I |\\lambda) \\cdot P\\left(O,I| \\lambda^{(t)}\\right) \\\nQ\\left(\\lambda, \\lambda^{(t))}\\right) \u0026amp;=\\sum_{T} \\log P(O,I | \\lambda) \\cdot P\\left(O, I | \\lambda^{(t)}\\right) \u0026amp;= \\sumI \\left[ \\left(\\log \\pi{i1} + \\sum{t=2}^{T} \\log a{i{t-1}, it} + \\sum{t=2}^{T} \\log b_{i_t} \\left(o_t \\right) \\right) P\\left(O,I|\\lambda^{(t) }\\right) \\right] \u0026amp; \\text{Now we only consider }\\pi \\\n\\pi^{(t+1)} \u0026amp;=\\arg \\max _{\\pi} Q\\left(\\lambda, \\lambda^{(t)}\\right)\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{I}\\left[\\log \\pi_{i_1}, P\\left(O,I | \\lambda^{(t)}\\right)\\right]\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{i1} \\cdots \\sum{i{T}}\\left[\\log \\pi{i1} \\cdot P\\left(O, i{1} \\cdots i_T | \\lambda^{(t)}\\right)\\right]\n\\ \u0026amp;=\\arg \\max {\\pi} \\sum{i{1}}\\left[\\log \\pi{i{1}} P\\left(O, i{1} | \\lambda^{(t)}\\right)\\right] \\\n\u0026amp;=\\arg \\max {\\pi} \\sum{i=1}^{N}\\left[\\log \\pi_{i} \\cdot P\\left(O, i_1=q_i |\\lambda^{(t)}\\right) \\right] \\\u0026amp; \\pi \\text{å¸¦çº¦æŸï¼Œå’Œä¸º1} \\end{aligned} $$\nç”¨lagrange multiplier $$ \\begin{array}{l}\n\\mathcal{L}(\\pi, \\eta)=\\sum{i=1}^{N} \\log \\pi{i} P\\left(O, i{1}=q{i} | \\lambda^{(t)}\\right)+\\eta\\left(\\sum{i=1}^{i} \\pi{i}-1\\right)\n\\ \\frac{\\partial f}{\\partial \\pii}=\\frac{1}{\\pi{i}} P\\left(O, i{1}=q{i} | \\lambda^{(t)}\\right)+\\eta=0 \\\n\\sum_{i=1}^{N} \\left[P\\left(O, i1=q{i} | \\lambda^{(t)}\\right)+\\pi_{i} \\eta \\right] =0 \\\nP\\left(O | \\lambda^{(t)}\\right)+\\eta=0 \\\n\\therefore \\eta = - P\\left(O, \\lambda^{(t)}\\right) \\\n\\pii = - \\frac{P\\left(O, i{1}=q_{i} | \\lambda^{(t)}\\right)}{\\eta} \\pii^{(t+1)} = \\frac{P\\left(O, i{1}=q_{i} | \\lambda^{(t)}\\right)}{P\\left(O, \\lambda^{(t)}\\right)} \\\n\\pi_i^{(t+1)} = \\left(\\pi_1^{(t+1)}, \\pi_2^{(t+1)}, \\cdots, \\pi_N^{(t+1)} \\right) \\end{array} $$\nDecoding $$ \\begin{aligned} \\delta_{t}(i) \u0026amp;=\\max _{i_1, i2, \\cdots, i{t+1} } P\\left(o_1,O_2, \\cdots, O_t, i_1, i2, \\cdots, i{t-1}, it=q{i}\\right) \\ \\delta{t+1}(j) \u0026amp;=\\max{i_1, i2, \\cdots, i{t+1} } P\\left(o_1,O_2, \\cdots, O_t, i_1, i2, \\cdots, i{t}, i{t+1}=q{i}\\right) \u0026amp;=\\max {1 \\leqslant i \\leq N} \\delta{t}(i) a{i j} b{j}\\left(O_{t+1}\\right) \\\n\u0026amp;\\text{ä¸Šè¿°å¼å­åªæ±‚å‡ºæœ€å¤§æ¦‚ç‡å€¼ï¼Œéœ€è¦è®°å½•çŠ¶æ€è·¯å¾„ï¼š} \\\n\\psi{t+1}(j) \u0026amp;=\\underset{1 \\leqslant i \\leqslant N}{\\arg \\max } \\delta{t}(i) \\cdot a_{ij}\n\\end{aligned} $$\nfiltering(Forward Algorithm) $$ P\\left(i{t} | o{1: t}\\right)=\\frac{P\\left(i{t}, o{1:t}\\right)}{P\\left(o{1:t}\\right)}=\\frac{P\\left(o{1:t}, it\\right)}{\\sum{it} P\\left(o{1:t}, it\\right)} \\propto P\\left(o{1:t}, i_t\\right) = \\alpha_i(t) $$\nsmoothing(Forward-backward Algorithm) $$ \\begin{aligned} P\\left(i{t} | o{1: T}\\right) \u0026amp;=\\frac{P\\left(i{t}, o{1:T}\\right)}{P\\left(o{1:T}\\right)}=\\frac{P\\left(o{1:T}, it\\right)}{\\sum{it} P\\left(o{1:T}, i_t\\right)} \\\nP\\left(o_{1:T}, it\\right) \u0026amp; = P\\left(o{1:t}, o_{t+1:T}, i_t\\right) \\\n\u0026amp; = \\underbrace{ P\\left(o{t+1:T}| o{1:t}, it\\right) }{ P\\left( o_{t+1:T}| i_t \\right)}\n\\underbrace{ P\\left( o_{1:t}, it\\right)}{\\alpha_t} \\\n\u0026amp;= \\beta_t \\cdot \\alpha_t \\\n\u0026amp; \\therefore P\\left(o_{1:T}, it\\right) \\propto P\\left( o{t+1:T}| i_t \\right) = \\alpha_t \\cdot \\beta_t \\end{aligned} $$\nprediction $$ \\begin{aligned} P\\left( i{t+1}|o{1:t} \\right) \u0026amp;= \\sum{i{t}} P\\left( i_{t+1}, it|o{1:t} \\right)\n\\\u0026amp;= \\sum{i{t}} \\underbrace{ P\\left( i_{t+1}| it,o{1:t} \\right)}{ P\\left( i{t+1}| i_t\\right) } \\underbrace{ P\\left( it|o{1:t} \\right) }_{filtering}\n\\end{aligned} $$\n$$ \\begin{aligned} P\\left( o{t+1}|o{1:t} \\right) \u0026amp;= \\sum{i{t+1}} P\\left( o{t+1}, i{t+ 1}|o_{1:t} \\right)\n\\\u0026amp;= \\sum{i{t+1}} \\underbrace{ P\\left( o{t+1}| i{t+1},o{1:t} \\right)}{ P\\left( o{t+1}| i{t+1}\\right) } \\underbrace{ P\\left( i{t+1}|o{1:t} \\right) }_{ä¸Šä¸€ä¸ªprediction}\n\\end{aligned} $$\n","date":1585082750,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589829036,"objectID":"a26198dec54033211ebab263a5e00927","permalink":"https://faithio.cn/post/hmm/","publishdate":"2020-03-24T16:45:50-04:00","relpermalink":"/post/hmm/","section":"post","summary":"[pdf] click here for link æ¦‚ç‡å›¾æ¨¡å‹ inference-\u0026gt; $P(Z|X)$-\u0026gt;ç§¯åˆ†é—®é¢˜ï¼ˆMCMCï¼‰ GMMï¼šæ ·æœ¬ä¹‹é—´æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒ HMM: Dynamic Model y: System state éšå˜é‡ state ç¦»æ•£ï¼šHMM state çº¿æ€§: Kalman Filter","tags":[],"title":"HMM","type":"post"},{"authors":[],"categories":[],"content":" è¯­éŸ³è¯†åˆ« HMM Method 1:Tandem Method 2: DNN-HMM Hybrid ","date":1585068369,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585155865,"objectID":"4f4a6c327fba1cf1c0a126544a3a4547","permalink":"https://faithio.cn/post/nlp/","publishdate":"2020-03-24T12:46:09-04:00","relpermalink":"/post/nlp/","section":"post","summary":"è¯­éŸ³è¯†åˆ« HMM Method 1:Tandem Method 2: DNN-HMM Hybrid","tags":[],"title":"NLP","type":"post"},{"authors":[],"categories":[],"content":" $$ \\begin{aligned} E{z|x}\\left[f(z)\\right] \u0026amp;= \\int P(z|x) f(z) dz \\ \u0026amp; \\approx \\frac{1}{N} \\sum{i=1}^N f(z_i) \\\u0026amp; z^{(1)}, z^{(2)}, \\cdots, z^{(N)} \\sim P(z|x) \\end{aligned} $$\n$$ \\frac{1}{N} \\sum_{i=1}^{N} f\\left(x^{(i)}\\right) \\stackrel{a . s}{\\rightarrow} \\int f(x) p(x) d x $$\næ¦‚ç‡åˆ†å¸ƒé‡‡æ · Standard distributions PDFå¦‚æœå¾ˆå¤æ‚ï¼ŒCDFæ±‚ä¸å‡ºæ¥ã€‚\nRejection Sampling adaptive rejection sampling log P(x)æ˜¯concave æ‰èƒ½ä½¿ç”¨ã€‚\nImportance Sampling å› ä¸ºå¤§éƒ¨åˆ†é‡‡æ ·å¾—åˆ°çš„æ ·æœ¬é‡è¦æ€§å¾ˆä½ï¼Œåä¹‹ä»…æœ‰å°‘é‡çš„æ ·æœ¬é‡è¦æ€§éå¸¸å¤§ã€‚\nSampling Importance Resampling\n$$ \\begin{array}{l}\\text { Our goal is to compute: } I(f)=\\int f(x) p(x) d x \\\n\\text { If we have a density } q(x) \\text { which is easy to sample from, we can sample } x^{(i)} \\stackrel{\\text { id }}{\\sim} q(x) \\text { Define the importance weight as: } w\\left(x^{(i)}\\right)=\\frac{p\\left(x^{(i)}\\right)}{q\\left(x^{(i)}\\right)} \\\n\\text { Consider the weighted Monte Carlo sum: } \\\n\\begin{array}{ll}\n\\frac{1}{N} \\sum{i=1}^{N} f\\left(x^{(i)}\\right) w\\left(x^{(i)}\\right) \u0026amp;= \\frac{1}{N} \\sum{i=1}^{N} f\\left(x^{(i)}\\right) \\frac{p\\left(x^{(i)}\\right)}{q\\left(x^{(i)}\\right)} \\\n\u0026amp; \\stackrel{a . s .}{\\rightarrow} \\int\\left(f(x) \\frac{p(x)}{q(x)}\\right) q(x) d x \\quad \\text{(Law of Large Numbers)} \\\n\u0026amp;= \\int f(x) p(x) d x\\end{array}\\end{array} $$\nMCMC åŸºäºéšæœºé‡‡æ ·çš„è¿‘ä¼¼æ–¹æ³•\nMarkov Chain: æ—¶é—´çŠ¶æ€éƒ½æ˜¯ç¦»æ•£çš„ã€‚ç‰¹æ®Šçš„éšæœºè¿‡ç¨‹\né½æ¬¡ï¼ˆä¸€é˜¶ï¼‰Markov Chainï¼šæœªæ¥åªä¾èµ–äºå½“å‰ï¼Œå’Œè¿‡å»æ²¡æœ‰å…³ç³» ${xt}$ Pä¸ºè½¬ç§»çŸ©é˜µ$[P{ij}]$ $$ P(X_{t+1} = x| x_1, x_2, \\cdots, xt) = P(X{t+1}|x_t) $$\n$$ P{i j} \\quad P{i j}=P\\left(X{i+1}=j | X{t=i}\\right) $$\ngraph LR; x1--\u0026gt;x2; x2--\u0026gt;x3; x3--\u0026gt;xt; xt--\u0026gt;xt+1;  å¹³ç¨³åˆ†å¸ƒ\n","date":1585028300,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589841215,"objectID":"2e809b9eacbd8c09c0c32ead5e993a3d","permalink":"https://faithio.cn/post/markov-chain-monte-carlo/","publishdate":"2020-03-24T01:38:20-04:00","relpermalink":"/post/markov-chain-monte-carlo/","section":"post","summary":"$$ \\begin{aligned} E{z|x}\\left[f(z)\\right] \u0026amp;= \\int P(z|x) f(z) dz \\ \u0026amp; \\approx \\frac{1}{N} \\sum{i=1}^N f(z_i) \\\u0026amp; z^{(1)}, z^{(2)}, \\cdots, z^{(N)} \\sim P(z|x) \\end{aligned} $$ $$ \\frac{1}{N} \\sum_{i=1}^{N} f\\left(x^{(i)}\\right) \\stackrel{a . s}{\\rightarrow} \\int f(x) p(x) d x $$ æ¦‚ç‡åˆ†å¸ƒé‡‡æ · Standard distributions PDFå¦‚æœå¾ˆå¤æ‚ï¼ŒCDFæ±‚ä¸å‡ºæ¥ã€‚ Rejection Sampling adaptive rejection sampling log P(x","tags":[],"title":"Markov Chain Monte Carlo","type":"post"},{"authors":[],"categories":[],"content":" æ··åˆæ¨¡å‹éƒ½æ˜¯ç”Ÿæˆæ¨¡å‹ï¼ŒNä¸ªæ ·æœ¬ï¼Œå…ˆç”Ÿæˆx1ï¼Œx2\n$$ \\begin{aligned} p(x) \u0026amp;= \\sumz P(x,z) \u0026amp;= \\sum{k=1}^z P(x, z=Ck) \u0026amp;= \\sum{k=1}^z p(z=C_k) \\cdot p(x|z=Ck) \u0026amp;= \\sum{k=1}^z p_k \\mathcal{N}(x| \\mu_k, \\Sigma_k) \\end{aligned} $$ $$ \\log (\\Delta + \\Delta + \\Delta ) \\rightarrow \\text{è¿åŠ ç¬¦å·å¾ˆéš¾æ±‚å¯¼ï¼Œä»¤å¯¼æ•°ä¸º0ï¼Œè¿ä¹˜æ¯”è¾ƒæ–¹ä¾¿} \\text{å•å˜é‡çš„é«˜æ–¯åˆ†å¸ƒå¯ä»¥ç›´æ¥ç”¨MLEæ±‚å‡ºæ¥} $$\nç”¨EMæ±‚è§£ $$ \\text{ E-Step: } P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\\n\\text{ M-Step: } \\theta^{(t+1)}=\\arg \\max {\\theta} \\underbrace{ E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]}_{Q(\\theta, \\theta^{(t)})} \\\n\\text{E-step:} \\\nQ(\\theta, \\theta^{(t)}) = \\int_z \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \\text{ç‹¬ç«‹åŒåˆ†å¸ƒ} = \\sumz \\log \\prod{i=1}^N P(x_i, z_i|\\theta) \\cdot \\sumz \\log \\prod{i=1}^N P(z_i|xi, \\theta^{(t)})\n=\\sum{z_{1} z2 \\cdots z{N}} \\sum{i=1}^{N} \\log P\\left(x{i} z{i} | \\theta\\right) \\cdot \\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) \\\n=\\sum{z{1} z2 \\cdots z{N}} \\left[\\log P\\left(x{1}, z{1} | \\theta\\right)+\\log P\\left(x{2}, z{2} | \\theta\\right)+\\cdots+\\log P\\left(x{N}, z{N} | \\theta\\right)\\right] \\cdot \\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) + \\cdots + \\sum{z{N}} \\log p\\left(x{N}, z{N} | \\theta\\right) \\cdot p\\left(z{N} | x{N}, \\theta\\right) =\\sum{i=1}^{N} \\sum_{zi} \\log p\\left(x{i}, z{i} | \\theta\\right) \\cdot p\\left(z{i} | x_{i}, \\theta^{(i)}\\right) \\\n=\\sum{i=1}^{N} \\sum{z{i}} \\log p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z{i}}\\right) \\cdot \\frac{p{z{i}} \\cdot \\mathcal{N}\\left(x{i} | \\mu{i}, \\Sigma{i}\\right)}{\\sum{k=1}^{K} p{x} \\mathcal{N}\\left(x{i} | \\mu_{k}, \\Sigmak\\right)} \u0026mdash; \\begin{aligned} P(x, z) \u0026amp;=P(z) \\cdot p(x | z) \\ \u0026amp;=p{z} \\cdot N\\left(x | \\mu{z}, z{z}\\right) \\ p(z | x) \u0026amp;=\\frac{p(x, z)}{p(x)}=\\frac{p{z} \\cdot \\mathcal{N}\\left(x | \\mu{z} \\Sigma{z}\\right)}{\\sum{k=1}^{K} p{k} \\cdot \\mathcal{N}\\left(x | \\mu{k}, \\Sigma_{k}\\right)} \\end{aligned} $$\n$$ \\text{å–ç¬¬ä¸€é¡¹} \\sum{z{1} z2 \\cdots z{N}} \\log p\\left(x{1}, z{1} |\\theta\\right) \\cdot \\underbrace{\\prod{i=1}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right)}{ p\\left(z_1,\\left|x1, \\theta^{(t)}\\right) \\cdot \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right)\\right. } \\\n=\\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) \\sum_{z_2 \\cdots zN} \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\sum{z{1}} \\log p\\left(x{1}, z{1} | \\theta\\right) \\cdot p\\left(z{1} | x{1}, \\theta\\right) \u0026mdash;- \\prod{i=2}^{N} p\\left(z{i} | x{i}, \\theta^{(t)}\\right) = \\prod{i=2}^{N} P(z_2|x_2)P(z_3|x_3)\\cdots P(z_N|xN) = \\sum{z_2}P(z_2|x2)\\cdot \\sum{z_3}P(z_3|x3)\\cdot \\cdots \\sum{z_N}P(z_N|x_N) = 1 $$\nE-Step: $$ \\text{ M-Step: } \\theta^{(t+1)}=\\arg \\max {\\theta} \\underbrace{ E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]}_{Q(\\theta, \\theta^{(t)})} \\begin{aligned} Q(\\theta, \\theta^{(t)}) \u0026amp;= \\intz \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \u0026amp;=\\sum{i=1}^{N} \\sum{z{i}} \\log p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z{i}}\\right) \\cdot \\underbrace{ \\frac{p{z{i}} \\cdot \\mathcal{N}\\left(x{i} | \\mu{i}, \\Sigma{i}\\right)}{\\sum{k=1}^{K} p{x} \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigmak\\right)} }{P(z_i|x_i, \\theta^{(t)}) \\rightarrow \\theta^{(t)} \\text{ is a constant.}} \\\n\u0026amp;= \\intz \\log P(X, Z|\\theta) P(Z|X, \\theta^{(t)}) dz \u0026amp;=\\sum{i=1}^{N} \\sum{z{i}} \\log [p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z_{i}}\\right)] \\cdot P(z_i|xi, \\theta^{(t)}) \u0026amp;= \\sum{z{i}} \\sum{i=1}^{N} \\log [p{z{i}} \\mathcal{N}\\left(x{i} | \\mu{z{i}} \\Sigma{z_{i}}\\right)] \\cdot P(z_i|xi, \\theta^{(t)}) \u0026amp;= \\sum{k=1}^{k} \\sum{i=1}^{N} \\log [p{k} \\cdot \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigma{k}\\right)] \\cdot p\\left(z{i}=C{k} | x{i}, \\theta^{(t)}\\right) \\\n\u0026amp;= \\sum{k=1}^{k} \\sum{i=1}^{N} [\\log p{k} + \\log \\mathcal{N}\\left(x{i} | \\mu{k}, \\Sigma{k}\\right)] \\cdot p\\left(z{i}=C{k} | x_{i}, \\theta^{(t)}\\right) \\end{aligned} $$ æ±‚ $p_k^{t+1} = (p_1^{t+1}, p_2^{t+1}, \\cdots, pk^{t+1})$ $$ \\left{ \\begin{array}{l} p{k}^{(k+1)}=\\operatorname{argmax}{p{k}} \\sum{k=1}^{k} \\sum{i=1}^{N} \\log p{k} \\cdot p\\left(z{i} = Ck | x{i}, \\theta^{(t)}\\right) s.t. \\sum{k=1}^{k} p{k}=1 \\end{array} \\right. $$ ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜å­æ³•ï¼š $$ \\mathcal{L}(p, \\lambda)=\\sum{k=1}^{K} \\sum{i=1}^{N} \\log p{k} \\cdot p\\left(z{i}=C{k} | x{i}, \\theta^{(t)}\\right)+\\lambda(\\sum_{k=1}^k - 1) $$\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p{k}}= \\sum{i=1}^{N} \\frac{1}{p{k}} \\cdot p\\left(z{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)+\\lambda \\triangleq 0 \\rightarrow \\sum{i=1}^{N} \\cdot p\\left(z{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)+p_k \\lambda = 0 \\\n\\Rightarrow^{(k=1,\\cdots , K)} \\sum{i=1}^{N} \\underbrace{\\sum{i=1}^K \\cdot p\\left(z_{i}=Ck | x{i} \\cdot \\theta^{(k)}\\right)}1 + \\underbrace{\\sum{i=1}^K p_k}_1 \\lambda \\Rightarrow N+ \\lambda = 0 \\Rightarrow \\lambda = -N $$\n$$ p{k}^{(t+1)}=\\frac{1}{N} \\sum{i=1}^{N} p\\left(z{i}=C{k} | x_{i}, \\theta^{(t)}\\right) $$\n","date":1585021364,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585028218,"objectID":"1ae0708a82dfe0be1cc5160b25eca272","permalink":"https://faithio.cn/post/gaussian-mixture-model/","publishdate":"2020-03-23T23:42:44-04:00","relpermalink":"/post/gaussian-mixture-model/","section":"post","summary":"æ··åˆæ¨¡å‹éƒ½æ˜¯ç”Ÿæˆæ¨¡å‹ï¼ŒNä¸ªæ ·æœ¬ï¼Œå…ˆç”Ÿæˆx1ï¼Œx2 $$ \\begin{aligned} p(x) \u0026amp;= \\sumz P(x,z) \u0026amp;= \\sum{k=1}^z P(x, z=Ck) \u0026amp;= \\sum{k=1}^z p(z=C_k) \\cdot p(x|z=Ck) \u0026amp;= \\sum{k=1}^z p_k \\mathcal{N}(x| \\mu_k, \\Sigma_k) \\end{aligned} $$ $$ \\log (\\Delta + \\Delta + \\Delta ) \\rightarrow \\text{è¿åŠ ç¬¦å·å¾ˆéš¾æ±‚å¯¼","tags":[],"title":"Gaussian Mixture Model","type":"post"},{"authors":[],"categories":[],"content":" click here for link\n$MLE: P(X|\\theta)$\n$$ \\begin{aligned} \\theta_{MLE} \u0026amp;=\\arg \\max _{\\theta} \\log P(X | \\theta) \\\n\\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \u0026amp;= \\arg \\max {\\theta} E{\\mathbf{Z} | x \\theta^{t}}[\\log P(x, z | \\theta)] \\\n\\text{ E-Step: } \u0026amp; P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\\n\\text{ M-Step: } \u0026amp;\\theta^{(t+1)}=\\arg \\max {\\theta} E{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)]\n\\end{aligned} $$\néœ€è¦è¯æ˜ä¸€å®šä¼šæ”¶æ•›Convergence $$ \\theta^{(t)} \\rightarrow \\theta^{(t+1)} \\log p\\left(x | \\theta^{(t)}\\right) \\leqslant \\log p\\left(x | \\theta^{(t+1)}\\right) $$\n$$ \\frac{P(x, z | \\theta)}{P(z | x)} \\\n\\log P(x | \\theta)=\\log P(x, z | \\theta)-\\log P(z | x, \\theta) \\\n\\begin{aligned} left \u0026amp;=\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(x | \\theta) d z \\ \u0026amp;=\\log P(x | \\theta) \\underbrace{ \\int{z} P\\left(z | x, \\theta^{(t)}\\right) d z }_1 \\ \u0026amp;= \\log P(x | \\theta) \\end{aligned} \\\nright =\\underbrace{\\int{\\mathbb{Z}} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log P(x, z | \\theta) d z}{Q\\left(\\theta, \\theta^{(t)}\\right)} -\\underbrace{\\int{\\mathbb{Z}} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(z | x, \\theta) d z}{H\\left(\\theta, \\theta^{(t)}\\right)}\\\nQ\\left(\\theta^{(t+1)}, \\theta^{(t)}\\right) \\geqslant Q\\left(\\theta^{(t)}, \\theta^{(t)}\\right) \\\n\\begin{aligned} \u0026amp; H\\left(\\theta^{(t+1)} \\cdot \\theta^{(t)}\\right)-H\\left(\\theta^{(t)} \\cdot \\theta^{(t)}\\right) \\ \u0026amp;=\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p\\left(z | x \\theta^{(t+1)}\\right) d z \\ \u0026amp;-\\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p\\left(z | x, \\theta^{(t)}\\right) d z \\\u0026amp; = \\int_{z} P\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log \\frac{p\\left(z | x, \\theta^{(t+1)}\\right)}{p\\left(z | x, \\theta^{(t)}\\right)} d z \\ \u0026amp; = -\\mathcal{KL}\\left(P(z | x, \\theta^{(t)}) | p\\left(z | x, \\theta^{(t+1)}\\right) \\right) \\ \u0026amp; \\leqslant 0\n\\end{aligned} \\\n\\begin{aligned} \u0026amp; E[\\ln x] \\leqslant \\log E[x] \\ \\leqslant \\log \\underbrace{\\int_{z} p\\left(z|x, \\theta^{(t+ 1)}\\right) d z}_1=\\log 1=0\n\\end{aligned} $$\n$$ p(x, z)=p(z | x) \\cdot p(x) \\log p(x) = \\log \\frac{p(x, z)}{p(z | x) } = \\log p(x, z) - \\log p(z | x)\nadd \\quad \\theta \u0026mdash;\n\\log P(x | \\theta)=\\log P(x, z | \\theta)-\\log P(z | x, \\theta) =\\log \\frac{P(x, z | \\theta)}{q(z)}-\\log \\frac{P(z | x, \\theta)}{q(z)} \\quad q(z) \\neq 0 \\text{å·¦å³ä¸¤è¾¹å¯¹äº} q(z) \\text{æ±‚æœŸæœ›} left = \\int{z} q(z) \\cdot \\log p(x | \\theta) d z=\\log p(x | \\theta) \\cdot \\underbrace{\\int{z} q(z) d z}{1}=\\log p(x | \\theta) rigth = \\underbrace{ \\int{z} q(z) \\log \\frac{p(x, z | \\theta)}{q(z)} d z}{ELBO: evidence lower bound} \\underbrace{ - \\int{z} q(z) \\log \\frac{p(z | x, \\theta)}{q(z)} d z}_{\\mathcal{KL}(q(z) | p(z | x, \\theta)} \\log p(x | \\theta)=ELBO+ KL(q|p) \\log p(x | \\theta) \\geqslant ELBO \\text{maximize ELBO, then posterior maximize, æœ€å¤§åŒ–ELBO(æœŸæœ›)ï¼Œ ç„¶åæ›´æ–°åéªŒæ¦‚ç‡çš„å‚æ•°} \\theta $$\n$$ \\hat{\\theta}=\\arg \\max _{\\theta} E L B O = \\arg \\max _{\\theta} \\int q(z) \\log \\frac{p (x, z|\\theta)}{q(z)} d z\nå½“\\log p(x | \\theta) \\geqslant ELBO å–ç­‰äºå·(KL=0)ï¼Œq(z) = p(z|x, \\theta^{(t)}) =\\arg \\max _{\\theta} \\int p\\left(z | x, \\theta^{(t)}\\right) \\log \\frac{p(x, z | \\theta)}{p\\left(z | x,\\theta^{(t)}\\right)} d z =\\arg \\max {\\theta} \\int p\\left(z | x, \\theta^{(t)}\\right) \\left[ \\log p(x, z | \\theta) - \\underbrace{ \\log p\\left(z | x,\\theta^{(t)}\\right)}{ä¸\\thetaæ— å…³ï¼Œå·²ç»å˜æˆå¸¸æ•°} \\right]dz = \\arg \\max {\\theta} \\int{z} p\\left(z | x, \\theta^{(t)}\\right) \\cdot \\log p(x, z | \\theta) d z\n$$\næ–°çš„è§’åº¦æ¨å¯¼EM $$ \\begin{aligned} \\log P(x|\\theta) \u0026amp; = \\log \\intz P(x, z| \\theta) \u0026amp; = \\log \\int{z} \\frac{P(x, z | \\theta)}{q(z)} \\cdot q(z) d z \u0026amp; = \\log E{q(z)}\\left[\\frac{p(x, z | \\theta)}{q(z)}\\right] \u0026amp; \\text{use jensen inequalty} \u0026amp; \\geqslant E{q(z)}\\left[\\log \\frac{p(x, z | \\theta)}{q(z)}\\right] \\rightarrow ELBO \u0026amp; \\Leftrightarrow \\frac{P(x, z | \\theta)}{q(z)}=C q(z) \u0026amp; =\\frac{1}{c} p(x, z | \\theta) 1 =\\intz q(z) d z \u0026amp;=\\int{z} \\frac{1}{c} p(x, z | \\theta) d z \u0026amp; =\\frac{1}{c} \\int_{x} p(x, z | \\theta) d z 1 \u0026amp; =\\frac{1}{c} P(x | \\theta) c \u0026amp; =P(x | \\theta) \\end{aligned} $$\n$$ q(z)=\\frac{1}{p(x | \\theta)} \\cdot p(x, z | \\theta)=p(z | x, \\theta) $$\n$$ t \\in[0.1] c= ta+ (1-t)b f\u0026copy; =f(ta+ (1-t)b) \\geqslant tf(a) + (1-t)f(b) $$\n$$ \\begin{array}{l}x(t)=x{1}+t\\left(x{2}-x{1}\\right) \\ y(t)=f\\left(x{1}\\right)+t\\left(f\\left(x{2}\\right)-f\\left(x{1}\\right)\\right) \\ t \\in \\mathbb{R}\\end{array} \\begin{array}{l}\\text { Combining like terms and replacing } t \\text { with }(1-t) \\text { (which is fine since } t \\text { is an arbitrary parameter; } \\ \\text { furthermore } 0 \\leq 1-t \\leq 1 \\Longleftrightarrow 0 \\leq t \\leq 1 \\text { ), we can write the secant line as the set of } \\ \\text { points } \\ \\qquad \\begin{array}{l}x(t)=t x{1}+(1-t) x{2} \\ y(t)=t f\\left(x{1}\\right)+(1-t) f\\left(x{2}\\right) \\ t \\in \\mathbb{R}\\end{array}\\end{array}\n$$ http://www.gtmath.com/2016/03/convexity-and-jensens-inequality.html\nå¹¿ä¹‰EM æ¦‚ç‡ç”Ÿæˆæ¨¡å‹é—®é¢˜ï¼Œé€šè¿‡zç”Ÿæˆxï¼Œç„¶åå†é€šè¿‡ç§¯åˆ†æŠŠzæ¶ˆæ‰ã€‚å‚æ•°learningé—®é¢˜\ngraph LR; z--\u0026gt;x;  $$ \\hat{\\theta} = \\arg \\max _{\\theta} \\log P(X|\\theta)\n= \\arg \\max {\\theta} \\log \\prod{i=1}^N P(x_i|\\theta) $$\n$$ \\log P(x | \\theta)=E L B O+K L(q | p) \\left{\\begin{array}{l}E L B O=E_{q(z)}\\left[\\log \\frac{p(x, z | \\theta)}{q(z)}\\right] \\ KL(q | p)=\\int q(z) \\cdot \\log \\frac{q(z)}{p(z | x, \\theta)} d z\\end{array}\\right. \\\n\\text{E-step: å›ºå®š }\\theta \\rightarrow \\hat{q}=\\arg \\min _{q} K L(q | p)=\\arg \\max_q \\mathcal{L}(q, \\theta) \\text{M-step: å›ºå®š }\\hat{q} \\rightarrow \\theta=\\arg \\max _{\\theta} \\mathcal{L}(\\hat{q}, \\theta) $$\n$$ \\left{\\begin{array}{l} \\text { E-stes: } q^{(t+1)}=\\arg \\max _{q} \\mathcal{L}\\left(q, \\theta^{(t)}\\right) \\ \\text { M-step: } \\theta^{(t+1)}=\\arg \\max _{\\theta} \\mathcal{L}(q^{t+1}, \\theta) \\end{array}\\right. $$\næ‰€ä»¥EMä¹Ÿå«MMç®—æ³•ï¼Œè½®æµè¿­ä»£q and $\\theta$\nSMOï¼šåæ ‡ä¸Šå‡æ³•/æ¢¯åº¦ä¸Šå‡æ³•\nMæ­¥å’ŒEæ­¥å…¶å®å¯ä»¥äº¤æ¢\nE-Step å…¶å®æ˜¯æ±‚åéªŒæ¦‚ç‡ï¼Œå‡å¦‚intractable ç„¶åç”¨VIæ±‚å‡ºåéªŒ å°±å«VBEM/VEMï¼Œå¦‚æœç”¨MCæ±‚åéªŒé‚£å°±æ˜¯MCEM\nVI \u0026lt;=\u0026gt; VB\næ—¢ç„¶æ˜¯ä¼˜åŒ–é—®é¢˜ï¼Œèƒ½å¦ç”¨æ¢¯åº¦çš„æ–¹æ³•æ±‚è§£å‘¢ï¼Ÿ\n","date":1584676534,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589823101,"objectID":"9ea6f7a01fddd5d96157297ddf58bdd4","permalink":"https://faithio.cn/post/expectation-maximization/","publishdate":"2020-03-19T23:55:34-04:00","relpermalink":"/post/expectation-maximization/","section":"post","summary":"click here for link $MLE: P(X|\\theta)$ $$ \\begin{aligned} \\theta_{MLE} \u0026amp;=\\arg \\max _{\\theta} \\log P(X | \\theta) \\ \\theta^{(t+1)} \u0026amp;=\\arg \\max {\\theta} \\int{z} \\log p(x, z | \\theta) \\cdot p\\left(z | x, \\theta^{(t)}\\right) d z \u0026amp;= \\arg \\max {\\theta} E{\\mathbf{Z} | x \\theta^{t}}[\\log P(x, z | \\theta)] \\ \\text{ E-Step: } \u0026amp; P\\left(z | x, \\theta^{(t)}\\right) \\rightarrow E_{z|x, \\theta^{(t)}}[\\log P(x, z | \\theta)] \\ \\text{ M-Step: } \u0026amp;\\theta^{(t+1)}=\\arg \\max {\\theta} E{z|x,","tags":[],"title":"Expectation Maximization","type":"post"},{"authors":[],"categories":[],"content":" click here for link\nCommon X: data\n$X=\\left(x_1, x_2 \\cdots xN\\right){N \\times p}^{T}$ $$ \\theta = \\left(\\begin{array}{cccc}x{0} \u0026amp; x{a} \u0026amp; \\ldots \u0026amp; x{1 x} \\ x{1} \u0026amp; x{12} \u0026amp; \\ldots \u0026amp; x{21} \\ \\vdots \u0026amp; \u0026amp; \u0026amp; x{n y} \\ x{m} \u0026amp; x_{n x} \u0026amp; \\ldots \u0026amp; \\end{array}\\right) $$\né¢‘ç‡ï¼ˆç»Ÿè®¡æœºå™¨å­¦ä¹ ï¼‰ ä¼˜åŒ–é—®é¢˜ $$ x \\sim p(x | \\theta) $$ $\\theta$ æœªçŸ¥å¸¸é‡ï¼Œ Xï¼šr v $$ MLEï¼š\\theta_{M L E}=\\arg \\max _\\theta \\log P(X | \\theta) $$\nè´å¶æ–¯(æ¦‚ç‡å›¾æ¨¡å‹) æ±‚ç§¯åˆ†ï¼ˆMCMCï¼‰\n$\\theta$ r vï¼Œ $$ \\theta \\sim p(\\theta) $$\n$$ P(\\theta | x)=\\frac{P(x | \\theta) \\cdot P(\\theta)}{P(x)} \\propto P(x | \\theta) \\cdot P(\\theta) P(x) = \\int_{\\theta} P(x | \\theta) \\cdot P(\\theta) d \\theta $$\n$$ MAP: \\theta_{MAP}=\\arg \\max _{\\theta} P(\\theta | x)=\\arg \\max _{\\theta} P(x | \\theta) \\cdot P(\\theta) $$\nBias and Variance Avoid overfiting book  æèˆª ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼ˆé¢‘ç‡æ´¾ï¼‰æ„ŸKæœ´å†³é€»ï¼Œ æ”¯æEéšæ¡ å‘¨å¿—å â€œè¥¿ç“œä¹¦â€ PRML å›åˆ†ç¥æ ¸ç¨€ å›¾æ··è¿‘é‡‡è¿ é¡ºç»„ - è´å¶æ–¯ MLAPP è´å¶æ–¯ ESL é¢‘ç‡æ´¾ Deep Learning åœ£ç»/å¼ å¿—åç¿»è¯‘  é«˜æ–¯åˆ†å¸ƒ é©¬æ°è·ç¦»/æ¬§æ°è·ç¦»\n$X^TAX$ : æ¬§æ°è·ç¦»ï¼Œä¸­é—´æ˜¯å•ä½çŸ©é˜µï¼Œé©¬æ°è·ç¦»ï¼Œä¸­é—´æ˜¯åæ–¹å·®çŸ©é˜µï¼ˆå…¶å®æ˜¯äºŒæ¬¡å‹ï¼‰\n","date":1584659753,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589760399,"objectID":"bc2fa12456182893105148befb3b4799","permalink":"https://faithio.cn/post/foundation-of-machine-learning/","publishdate":"2020-03-19T19:15:53-04:00","relpermalink":"/post/foundation-of-machine-learning/","section":"post","summary":"click here for link Common X: data $X=\\left(x_1, x_2 \\cdots xN\\right){N \\times p}^{T}$ $$ \\theta = \\left(\\begin{array}{cccc}x{0} \u0026amp; x{a} \u0026amp; \\ldots \u0026amp; x{1 x} \\ x{1} \u0026amp; x{12} \u0026amp; \\ldots \u0026amp; x{21} \\ \\vdots \u0026amp; \u0026amp; \u0026amp; x{n y} \\ x{m} \u0026amp; x_{n x} \u0026amp; \\ldots \u0026amp; \\end{array}\\right) $$ é¢‘ç‡ï¼ˆç»Ÿè®¡æœºå™¨å­¦ä¹ ï¼‰ ä¼˜åŒ–é—®é¢˜ $$ x \\sim p(x | \\theta) $$","tags":[],"title":"Foundation of Machine Learning","type":"post"},{"authors":[],"categories":[],"content":"Approximate Inference.pdf\nApproximate Inference.html\n","date":1584656517,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586648375,"objectID":"42e77f450ce9f46625dae22d128fa311","permalink":"https://faithio.cn/post/approximate-inference/","publishdate":"2020-03-19T18:21:57-04:00","relpermalink":"/post/approximate-inference/","section":"post","summary":"Approximate Inference.pdf\nApproximate Inference.html","tags":[],"title":"Approximate Inference","type":"post"},{"authors":[],"categories":[],"content":"Exponential.pdf\nExponential.html\n","date":1584656503,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584657777,"objectID":"b00c82fc12ffaf3b2f6fd5dba8d770b8","permalink":"https://faithio.cn/post/the-exponential-family/","publishdate":"2020-03-19T18:21:43-04:00","relpermalink":"/post/the-exponential-family/","section":"post","summary":"Exponential.pdf\nExponential.html","tags":[],"title":"The Exponential Family","type":"post"},{"authors":[],"categories":[],"content":" pdf\ngraph TD; æ¦‚ç‡å›¾--\u0026gt;Representation-è¡¨ç¤º; æ¦‚ç‡å›¾--\u0026gt;Inference-æ¨æ–­; æ¦‚ç‡å›¾--\u0026gt;Learning-å­¦ä¹ ; Representation-è¡¨ç¤º--\u0026gt;æœ‰å‘å›¾BayesianNetwork; Representation-è¡¨ç¤º--\u0026gt;é«˜æ–¯å›¾-è¿ç»­; Representation-è¡¨ç¤º--\u0026gt;æ— å‘å›¾MarkovNetwork; é«˜æ–¯å›¾-è¿ç»­--\u0026gt;GaussianBN; é«˜æ–¯å›¾-è¿ç»­--\u0026gt;GaussianMN; Inference-æ¨æ–­--\u0026gt;ç²¾ç¡®æ¨æ–­; Inference-æ¨æ–­--\u0026gt;ApproximateInference; ApproximateInference--\u0026gt;DeterministicApproximation(Variantional Inference); ApproximateInference--\u0026gt;StochasticcApproximation(MCMC); Learning-å­¦ä¹ --\u0026gt;å‚æ•°å­¦ä¹ ; Learning-å­¦ä¹ --\u0026gt;ç»“æ„å­¦ä¹ ; å‚æ•°å­¦ä¹ --\u0026gt;å®Œå¤‡æ•°æ®; å‚æ•°å­¦ä¹ --\u0026gt;éšå˜é‡; éšå˜é‡--\u0026gt;EM;  $$ \\begin{array}{l} \\text{Sum Rule: } P(x_1)=\\int P\\left(x_1, x2\\right) d x{2} \\ \\text{Product Rule: } P\\left(x1, x{2}\\right)=P\\left(x_{1}\\right) \\cdot P\\left(x_2 | x1\\right)=P\\left(x{2}\\right) \\cdot P\\left(x{1} | x{2}\\right)\n\\end{array} $$\nChain Rule:\nBayesian Network  æ‹“æ‰‘æ’åºæ„å»ºå›¾\n graph TD; a--\u0026gt;b; a--\u0026gt;c;   $$ Chain Rule: P\\left(x{1}, x{2}, \\cdots, x{p}\\right)=P\\left(x{1}\\right) \\cdot \\prod{i=2}^{p} p\\left(x{i} | x_{1:i-1}\\right) P(a, b, c) = P(a)P(b|a)(c|a) \\rightarrow å› å­åˆ†è§£\nP(a, b, c) = P(a)P(b|a)(c|a,b) \\rightarrow Chain rule\nP(c | a)=P(c | a, b) \\Rightarrow c \\perp b | a p(c | a) \\cdot p(b | a)=p(c|a,b) \\cdot p(b | a)=p( b, c | a) p(c | a) \\cdot p(b | a)=p(b, c | a) $$\nTail to tail, è‹¥aè¢«è§‚æµ‹ï¼Œåˆ™è·¯å¾„è¢«å µå¡$tail \\rightarrow head$\ngraph LR; a--\u0026gt;b; b--\u0026gt;c;  head to tail $$ P(a,b, c) = P(a)P(b|a)P(c|b) P(a, b, c) = P(a) P(b|a) P(c|a,b) P(c|b) = P(c|a,b) $$\n$$ a \\perp c | b $$ è‹¥bè¢«è§‚æµ‹ï¼Œåˆ™è·¯å¾„è¢«é˜»å¡ï¼ˆindependentï¼‰\ngraph TD; a--\u0026gt;c; b--\u0026gt;c;  head to head\né»˜è®¤æƒ…å†µä¸‹ï¼Œ$a \\perp b$ï¼Œè·¯å¾„é˜»å¡çš„\nè‹¥cè¢«è§‚æµ‹ï¼Œåˆ™è·¯å¾„æ˜¯é€šçš„ $$ P(a, b, c)=P(a) \\cdot P(b) \\cdot P(c | a, b) P(a, b, c) = P(a)\\cdot P(b|a) \\cdot (c|a,b) P(b) = P(b|a) $$\nInference $$ \\begin{aligned} \\text { sum rule } \u0026amp; p(X)=\\sum_{Y} p(X, Y) \\ \\text { product rule } \u0026amp; p(X, Y)=p(Y | X) p(X) \\end{aligned} $$ æ±‚æ¦‚ç‡ï¼š $ P(x)=P\\left(x_0, x_1, \\cdots, x_p\\right) $\nè¾¹ç¼˜æ¦‚ç‡marginal probabilityï¼š $$ P\\left(x{i}\\right)=\\sum{x1} \\cdot \\sum{x{i-1}} \\sum{x{i+1}} \\ldots \\sum{x_{p}} p(x) $$ æ¡ä»¶æ¦‚ç‡conditional probabilityï¼š $$ P\\left(x_A | x_B\\right) \\quad x=x_A \\cup x_B $$ MAP Inference: $$ \\hat{z}=\\arg \\max _{z} P(z | x) \\propto \\arg \\max P(z, x) $$\ngraph LR; Inference--\u0026gt;ç²¾ç¡®æ¨è®º; Inference--\u0026gt;è¿‘ä¼¼æ¨æ–­; ç²¾ç¡®æ¨è®º--\u0026gt;variableElimination/VE; ç²¾ç¡®æ¨è®º--\u0026gt;BeliefPropagation/SumProductAlgorithmæ ‘ç»“æ„; ç²¾ç¡®æ¨è®º--\u0026gt;JunctionTreeAlgorithmæ™®é€šå›¾ç»“æ„BasedBP; è¿‘ä¼¼æ¨æ–­--\u0026gt;LoopBeliefPropagationæœ‰ç¯å›¾BasedBP; è¿‘ä¼¼æ¨æ–­--\u0026gt;MenteCarloInference:ImportanceSampling,MCMC; è¿‘ä¼¼æ¨æ–­--\u0026gt;VariationalInference  Variable Elimination-ä¹˜æ³•åˆ†é…å¾‹ $$ M A P \\quad \\tilde{X}_{A}=\\arg \\max {X} P\\left(x{A} | x{B}\\right)=\\arg \\max P\\left(x{A}, x_{B}\\right) $$\ngraph LR; a--\u0026gt;b; b--\u0026gt;c; c--\u0026gt;d;  å‡è®¾a,b,c,då‡æ˜¯ç¦»æ•£çš„äºŒå€¼r,v {0,1}\n$$ p(d) = \\sum_{a, b, c} p(a, b, c, d) \\\n= \\sum_{a, b, c} p(a) \\cdot p(b | a) \\cdot p(c | b) \\cdot p(d | c) \\\n= p(a=0) \\cdot p(b=0 | a=0) \\cdot p(c=0 | b=0) \\cdot p(d=0|c=0) + p(a=1) \\cdot p(b=0 | a=1) \\cdot p(c=0 | b=0) \\cdot p(d=0|c=0) \\\n \\cdots  p(a=1) \\cdot p(b=1 | a=1) \\cdot p(c=1 | b=1) \\cdot p(d=1|c=1) = \\sum{b, c} p(c | b) \\cdot p(d | c) \\cdot \\underbrace{\\sum{a} p(a) \\cdot p(b | a)}_{\\phi_a(b)}   = \\sumc p(d | c) \\cdot \\underbrace{\\sum{b} p(c | b)\\cdot \\phia(b) }{\\phi_b\u0026copy;} = \\phi_c(d) $$ ä¹˜æ³•å¯¹åŠ æ³•çš„åˆ†é…å¾‹$ab+cb = b(a+c)$\nCons:\n Memoryless.é‡å¤è®¡ç®— Ordering NP-hard  Belief Propagation graph LR; a--\u0026gt;b; b--\u0026gt;c; c--\u0026gt;d; d--\u0026gt;e;  $$ \\text{ Forward Algorithm} P(a, b, c, d, e)=P(a) P(b | a) \\cdot P(c | b) \\cdot P(d | c) \\cdot P(e|d) P(e)=\\sum{a, b,c, d} P(a, b, c, d, e) =\\sum{d} p(e | d) \\sum{c} p(d | c) \\underbrace{ \\sum{b} p(c | b) \\underbrace{ \\sum{a} p(b | a) p(a) }{m{a\\rightarrow b }(b)}}{m_{b \\rightarrow c}\u0026copy;} $$\n$$ p\u0026copy;=\\sum{a, b, d, e} p(a, b, c, d, e) = \\left(\\sum{b} p(c | b) \\cdot \\sum{a} p(b | a) \\cdot p(a) \\right) \\left(\\sum{d} p(d | c) \\sum_{e} p(e | d)\\right)\n\n\\text{ Forward-Backward Algorithm} $$\ngraph TD; a---b; b---d; b---c;  $$ \\begin{aligned} \u0026amp; p(a, b, c, d) \\=\u0026amp; \\frac{1}{z} \\psi{a}(a) \\psi{b}(b) \\cdot \\psi{c}\u0026copy; \\cdot \\varphi(d) \\ \u0026amp; \\cdot \\psi{a, b}(a, b) \\cdot \\psi{b, c}(b, c) \\cdot \\psi{b, d}(b, d) \\end{aligned} $$\n","date":1584654998,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1584678125,"objectID":"97dc121d7ddd7c67d1b89d3e4f7cf1a1","permalink":"https://faithio.cn/post/probabilistic-graphical-model/","publishdate":"2020-03-19T17:56:38-04:00","relpermalink":"/post/probabilistic-graphical-model/","section":"post","summary":"pdf graph TD; æ¦‚ç‡å›¾--\u0026gt;Representation-è¡¨ç¤º; æ¦‚ç‡å›¾--\u0026gt;Inference-æ¨æ–­; æ¦‚ç‡å›¾--\u0026gt;Learning-","tags":[],"title":"Probabilistic Graphical Model","type":"post"},{"authors":[],"categories":[],"content":"When I run some python code from github, it occur the following problem as screenshot.\n RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of \u0026lsquo;python\u0026rsquo; with \u0026lsquo;pythonw\u0026rsquo;. See \u0026lsquo;Working with Matplotlib on OSX\u0026rsquo; in the Matplotlib FAQ for more information.\n Solution:(https://stackoverflow.com/questions/21784641/installation-issue-with-matplotlib-python)\nProblem Cause In mac os image rendering back end of matplotlib (what-is-a-backend to render using the API of Cocoa by default). There is Qt4Agg and GTKAgg and as a back-end is not the default. Set the back end of macosx that is differ compare with other windows or linux os.\nI resolve this issue following ways:\n I assume you have installed the pip matplotlib, there is a directory in you root called ~/.matplotlib. Create a file ~/.matplotlib/matplotlibrc there and add the following code: backend: TkAgg  From this link you can try different diagram.\n","date":1583775429,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583802329,"objectID":"f401314725b6ff0b004bf2f679a80813","permalink":"https://faithio.cn/post/run-issue-with-matplotlib-in-mac-os-x/","publishdate":"2020-03-09T13:37:09-04:00","relpermalink":"/post/run-issue-with-matplotlib-in-mac-os-x/","section":"post","summary":"When I run some python code from github, it occur the following problem as screenshot.\n RuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends.","tags":[],"title":"Run Issue With Matplotlib in Mac OS X","type":"post"},{"authors":[],"categories":[],"content":" Math Formula Factor graphs Shows how a function of several variables can be factored into a product of simpler functions.\n $$ f(x,y,z) = (x+y) \\cdot (y + z) \\cdot (x +z) $$\n Very useful for representing posteriors.\n$ $$ P(x1, ..., x_n) = P(x_1) \\Pi P( x_i | x_{i-1} ) $$ $\n$$ P(m|x1, \u0026hellip;, x_n) = P(m) \\cdot \\Pi P(x_i|m)$$\nmodeling  What graph should I use for this data?  Inference  Given the graph and data, what is the mean of x algorithm  Sampling Variable elimination Message-passing(Expectation Propagation, Variational Bayes)   Cutter problem  Want to estimate x given multiple y\u0026rsquo;s $$ p(x) = \\mathcal{N}(x; 0, 100) $$ $$ p(y_i|x) = (0.5)\\mathcal{N}(y_i; x, 1) + (0.5)\\mathcal{N} (y_i;0,10)$$  -\u0026gt; $ P(x|y1, \u0026hellip;, y_n) = P(x) \\cdot \\Pi P(y_i|x)$\nif we only have 2 points:\n$$ P(x) \\cdot P(y_1|x) \\cdot P(y_2|x) \\rightarrow p(y_i|x) = (0.5)\\mathcal{N}(y_i; x, 1) + (0.5)\\mathcal{N} (y_i;0,10)$$\n2 points have 4 Gaussians -\u0026gt; N points $$2^N$$ Gaussians\n https://zhuanlan.zhihu.com/p/75617364 $$ p(z | w)=\\frac{p(w | z) p(z)}{p(w)}=\\frac{p(w | z) p(z)}{\\int_{z} p(w | z) p(z) d z} $$ Because it extends belief propagation. Belief propagation passes the entire distribution is the message. While EP will only pass onto the distribution certain expectation distribution allows you to you get a very compact message.\n Expectation Propagation  Fits an exponential-family approximation to the posterior. Belief propagation is a special case Kalman filtering is a special case Does not always converge.  May get stuck due to improper distributions May oscillate due to loopy graph   AGM $$ p(\\mathbf{X} | \\Theta)=\\sum{j=1}^{M} p{j} p\\left(\\mathbf{X} | \\xi_{j}\\right) $$\n $\\xi_j$ is the set of the parameters of component j. $ p_j$ are the mixing proptions which must be positive and sum to one. $\\Theta = {p_1, \\ldots, p_M, \\xi_1, \\ldots, \\xi_M}$ is the complete set of parameters fully characterizing the mixture. $ M \\geq 1$ is number of components in the mixture.  $$ p\\left(X | \\theta\\right)=\\prod{d=1}^{D} \\sqrt{\\frac{2}{\\pi}} \\frac{1}{\\left(\\sigma{l{d}}+\\sigma{r{d}}\\right)} \\times\\left{\\begin{array}{ll}\\exp \\left[-\\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 \\sigma{l{d} }^{2}}\\right] \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\ \\exp \\left[-\\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 \\sigma{r{d}}^{2}}\\right] \u0026amp; \\text { if } X{d} \\geq \\mu{d}\\end{array}\\right. $$ - $\\vec{\\mu}=\\left(\\mu{1}, \\ldots, \\mu{D}\\right)$ is the mean - $\\vec{\\sigma}{l}=\\left(\\vec{\\sigma}{l{1}}, \\ldots, \\vec{\\sigma}{l{D}}\\right)$ is the left standard deviation - $\\vec{\\sigma}{r}=\\left(\\vec{\\sigma}{r{1}}, \\ldots, \\vec{\\sigma}{r_{D}}\\right)$ is the right standard deviation\n$$ \\log P = \\sum{d=1}^{D} \\log \\sqrt{\\frac{2}{\\pi}} - \\frac{1}{2}\\log (\\sqrt{v{l{d}}} + \\sqrt{v{r{d}}}) - \\left{\\begin{array}{ll} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{l{d} }} \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{r{d} }} \u0026amp; \\text { if } X{d} \\geq \\mu{d} \\end{array}\\right. \\frac{\\partial \\log P}{\\partial v{l{d}}} = -\\frac{1}{4}\\frac{1}{v{l{d}} + \\sqrt{v{l{d}} v{r{d}} }} + \\left{\\begin{array}{ll} \\frac{\\left(X{d}-\\mu{d}\\right)^{2}}{2 v{l{d}}^2} \u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} 0 \u0026amp; \\text { if } X{d} \\geq \\mu_{d} \\end{array}\\right. $$\n$$ p(X, \\boldsymbol{\\theta})=\\prod{i} f{i}(\\boldsymbol{\\theta}) = \\prod_{i} p(xi|\\boldsymbol{\\theta})\n%p\\left(\\theta | X \\right) = \\frac{1}{p(X)} \\prod{i} f_{i}(\\boldsymbol{\\theta}) $$\n$$ %p(X)= \\int \\prod{i} f{i}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} $$\nHere, $p(\\vec{X})$ is very intractable to calculate and we don\u0026rsquo;t know $ f_{i}(\\boldsymbol{\\theta}) $.\nNow we consider using EP. The approximation, $q\\left(\\theta_j \\right)$ , of the posterior, $p\\left( \\theta_j | \\vec{X} \\right)$ , is assumed to have same functional form. $$ q(\\theta_j)=\\frac{1}{Z} \\prod_i \\widetilde{f}_i(\\theta_j) $$\nWe hope that: $$ \\mathrm{KL}(p | q)=\\mathrm{KL}\\left(\\frac{1}{p(X)} \\prod{i} f{i}(\\boldsymbol{\\theta}) | \\frac{1}{Z} \\prod{i} \\widetilde{f}{i}(\\boldsymbol{\\theta})\\right) $$\nIn general, this minimization will be intractable because the KL divergence involves averaging with respect to the true distribution.\nBut We can use EP:\n first choose a factor $\\widetilde{f}_{j}$ to approximate.  Begin Loop, until the following steps are convergence.\n second compute the cavity distribution $q^{\\backslash j}(\\boldsymbol{\\theta})$:  $$ q^{\\backslash j}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}_{j}(\\boldsymbol{\\theta})} \\\n\\hat{p} = \\frac{1}{Z{j}} f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta}) $$\nHere $q^{\\backslash j}(\\boldsymbol{\\theta})$ is called the cavity distribution. $\\hat{p}$ is defined as a product of the exact factor $f_i$ with the rest of the factors approximated, normalised to 1, and the cavity distribution needs to be computed in order to express $\\hat{p}$.\n $$ q^{\\text {new }}(\\boldsymbol{\\theta}) \\propto \\widetilde{f}{j}(\\boldsymbol{\\theta}) \\prod{i \\neq j} \\tilde{f}{i}(\\boldsymbol{\\theta}) p \\propto \\hat{p} = f{j}(\\boldsymbol{\\theta}) \\prod{i \\neq j} \\tilde{f}{i}(\\boldsymbol{\\theta}) $$\n  Then compute the approximative distribution $q^{new}$  $$ \\arg \\min \\mathrm{KL}(\\hat{p} | q^{new}(\\theta)) = \\arg \\min \\mathrm{KL}\\left(\\frac{f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta})}{Z{j}} | q^{\\mathrm{new}}(\\boldsymbol{\\theta})\\right) $$\n More generally, it is straightforward to obtain the required expectations for any member of the exponential family, provided it can be normalized, because the expected statistics can be related to the derivatives of the normalization coefficient. $$ \\text{bishop:} p(\\mathbf{x} | \\boldsymbol{\\eta})=h(\\mathbf{x}) g(\\boldsymbol{\\eta}) \\exp \\left{\\boldsymbol{\\eta}^{\\mathrm{T}} \\mathbf{u}(\\mathbf{x})\\right} -\\nabla \\ln g(\\boldsymbol{\\eta})=\\mathbb{E}[\\mathbf{u}(\\mathbf{x})] $$\n  Update the factor  $$ q^{\\text {new }}(\\boldsymbol{\\theta}) \\propto \\hat{p} = \\frac{1}{Z{j}} f{j}(\\boldsymbol{\\theta}) q^{\\backslash j}(\\boldsymbol{\\theta}) $$\nThen we easily obtain the formula for the approximation of $fi$: $$ f{i} \\approx \\tilde{f}{i}=Z{i} \\frac{q^{\\text {new }}(\\boldsymbol{\\theta})}{q^{\\backslash j}(\\boldsymbol{\\theta})} $$ This division of distributions is from exponetial family, so does the result $\\tilde{f}_{i}$. Now repeat it until parameter covergence.\nEnd Loop.\n Evaluate the approximation to the model evidence  After the algorithm has converged to a set of factors $\\left{\\tilde{f}{i}\\right}$, the approximate posterior as well as the model evidence can be computed as following: $$ p(X, \\boldsymbol{\\theta}) \\simeq \\prod{i} \\tilde{f}{i}(\\boldsymbol{\\theta}) p(X) \\simeq \\int \\prod{i} \\tilde{f}_{i}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} $$\n$$ p(\\mathbf{X} | \\boldsymbol{\\theta})=(1-w) \\mathcal{A}(\\mathbf{X} | \\boldsymbol{\\theta}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}) $$\nwhere w is the proportion of background clutter. And the prior over $\\mathbf{\\theta}$(mean) is taken to be Asymmetric Gaussian.\nAnd $$ p(\\boldsymbol{\\theta})= \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{Ir}) $$ $$ p(X, \\boldsymbol{\\theta})=p(\\boldsymbol{\\theta}) \\prod{n=1}^{N} p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) $$\n1. initialize the approximating factors we select an approximating distribution from the exponential family to approximate the stochastic variables $\\theta$ $$ q_0(\\boldsymbol{\\theta})\n= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{I_r}) $$\n$$ \\widetilde{f}_{n}(\\boldsymbol{\\theta})=s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{\\sigma{rn}^2}, \\mathbf{\\sigma{l_n}^2} \\right) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) $$\n$$ sn = \\prod{d=1}^{D} \\sqrt{\\frac{2}{\\pi}} \\frac{1}{\\left(\\sigma{l{d}}+\\sigma{r{d}}\\right)} $$ While $\\sigma_{ln} \\rightarrow \\infty, \\sigma{r_n} \\rightarrow \\infty $ and $ \\mu_n = 0 $.\n###2. initialize the posterior approximation $q(\\boldsymbol{\\theta})$\nWe chooses the parameter values a = 10, b = 100 and w = 0.5 and use $v$ denote $ \\sigma^2$ as following, then $\\mathbf{v_r} = \\mathbf{v_l} = b = 100$\n3. Until all $(\\mun, v{ln}, v{r_n}, s_n)$ converge: $$ q^{\\backslash n}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}_n(\\boldsymbol{\\theta})} = \\frac{\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu}, \\mathbf{v_r I}, \\mathbf{v_l I})}{s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right)} \\propto \\left{\\begin{array}{ll}\n{\\frac{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_l \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu})\\right}}{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{l_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right}}} \u0026amp;\u0026amp; \\text { if } X\u0026lt;\\mu \\\n{\\frac{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_r \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu})\\right}}{\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{r_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right}}} \u0026amp;\u0026amp; \\text { if } X\u0026gt;\\mu\n\\end{array}\\right. \\\n= \\left{\\begin{array}{ll}\n\\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_l \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu}) + \\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{l_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n})\\right} \u0026amp; \\text { if } X\u0026lt;\\mu \\exp \\left{-\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mu})^{T}(v_r \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu}) +\n\\frac{1}{2}(\\boldsymbol{X}-\\mathbf{\\mun})^{T}(v{r_n} \\mathbf{I})^{-1}(\\boldsymbol{X}-\\mathbf{\\mu_n}) \\right} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$ - Remove the current estimate $\\widetilde{f}_j(\\boldsymbol{\\theta})$ from $q(\\theta)$, then we has mean and inverse variance given by: $$ \\left{\\begin{array}{ll} \\left({v_l}^{\\backslash n}\\right)^{-1}={v_l}^{-1}-{vl}{n}^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\left({v_r}^{\\backslash n}\\right)^{-1}={v_r}^{-1}-{vr}{n}^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$\n$$ \\mathbf{\\mu}^{\\backslash n}= \\mathbf{\\mu}+\n\\left{\\begin{array}{ll} {v_l}^{\\backslash n} {vl}{n}^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_{n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n{v_r}^{\\backslash n} {vr}{n}^{-1}\\left(\\mathbf{\\mu}-\\mathbf{\\mu}_{n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. \u0026mdash;-\n\\begin{aligned} {v^{\\backslash{n}}}^{-1} \u0026amp;= v^{-1} - v_n^{-1} {\\mu}^{\\backslash n} \u0026amp;= v^{\\backslash{n}}(\\mu v^{-1} - \\mu_n v_n^{-1}) \u0026amp;= v^{\\backslash{n}}[\\mu ({v^{\\backslash{n}}}^{-1} + v_n^{-1}) - \\mu_n v_n^{-1}] \u0026amp;= \\mu + v^{\\backslash{n}} v_n^{-1} \\mu - v^{\\backslash{n}} v_n^{-1} \\mu_n \u0026amp;= \\mu + v^{\\backslash{n}} v_n^{-1} (\\mu -\\mun) \\end{aligned} $$ \u0026gt; Cavity Distribution: \u0026gt; $$ \u0026gt; q^{\\backslash n}(\\boldsymbol{\\theta})=\\frac{q(\\boldsymbol{\\theta})}{\\widetilde{f}{n}(\\boldsymbol{\\theta})} \u0026gt; $$\n Recompute $(\\mu, v, Z)$ from $(\\mathbf{\\mu}^{\\backslash n}, {v_l}^{\\backslash n}, {vr}^{\\backslash n})$ $$ Z{n}=(1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir}\\right) $$ \u0026gt;$$ \u0026gt;\\begin{aligned} \u0026gt;Z{n} \u0026amp;=\\int q^{\\backslash n}(\\boldsymbol{\\theta}) f_{n}(\\boldsymbol{\\theta}) \\mathrm{d} \\boldsymbol{\\theta} \\ \u0026gt;\u0026amp;=\\int q^{\\backslash n}(\\boldsymbol{\\theta}) P(X|\\mu) \\mathrm{d} \\boldsymbol{\\theta} \u0026gt; \u0026gt;\u0026amp;=\\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \\cdot { (1-w) \\mathcal{A}(\\mathbf{x_n} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{x_n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r})} \\mathrm{d} \\boldsymbol{\\theta} \u0026gt; \u0026gt;\u0026amp;= (1-w)\\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \\mathcal{A}(\\mathbf{x_n} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r}) \\mathrm{d} \\boldsymbol{\\theta} \u0026gt;\u0026amp;+ w \\int \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, v_r^{\\backslash n} \\mathbf{I}) \u0026gt;\\mathcal{A}(\\mathbf{x_n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir})} \\mathrm{d} \\boldsymbol{\\theta} \u0026gt;\u0026amp;=(1-w) \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \u0026gt;\\end{aligned} \u0026gt;$$  we assumed that $f{0}(\\boldsymbol{\\theta})=p(\\boldsymbol{\\theta})$ and $ f{n}(\\boldsymbol{\\theta})=p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) = (1-w) \\mathcal{A}(\\mathbf{X} | \\boldsymbol{\\mu}, \\mathbf{I_l}, \\mathbf{I_r})+w \\mathcal{A}(\\mathbf{X} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}) $, also $q(\\boldsymbol{\\theta})=\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{m}, v_l \\mathbf{I}, vr \\mathbf{I}) $ $$ \\begin{aligned} \\rho{n} \u0026amp;=\\frac{1}{Z{n}}(1-w) \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right) \u0026amp;= \\frac{1}{Z{n}}(1-w)\\cdot \\frac{Zn - w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right)}{1-w} \u0026amp;= 1 - \\frac{w}{Zn} \\cdot \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{Ir}\\right) \\end{aligned} $$ \u0026gt;Then our goal is to minimize: \u0026gt;$$ \u0026gt;\\mathrm{KL}\\left(\\frac{f{n}(\\boldsymbol{\\theta}) q^{\\backslash n}(\\boldsymbol{\\theta})}{Z_{n}} | q^{\\mathrm{new}}(\\boldsymbol{\\theta})\\right) \u0026gt;$$\nBasic rule for Asymmetric Gaussian:\nhttps://stats.stackexchange.com/questions/27436/how-to-take-derivative-of-multivariate-normal-density $$ \\nabla_{\\boldsymbol{\\mu}} \\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r})=\n\\left{\\begin{array}{ll}\n\\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r}) \\cdot(\\mathbf{x}-\\boldsymbol{\\mu}) \\mathbf{v_l}^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\mathcal{A}(\\mathbf{x} | \\boldsymbol{\\mu}, \\mathbf{v_l}, \\mathbf{v_r}) \\cdot(\\mathbf{x}-\\boldsymbol{\\mu}) \\mathbf{v_r}^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$ So we compute the mean and variance: $$ \\begin{aligned} \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\ln Z{n} \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} Z_{n} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta})f_{n}(\\boldsymbol{\\theta}) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta}) p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int\\left{\\nabla{\\mathbf{\\mu}^{\\backslash n}} q^{\\backslash n}(\\boldsymbol{\\theta})\\right} \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int \\frac{1}{v^{\\backslash n}}\\left(\\boldsymbol{\\theta}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\theta\\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\frac{1}{v^{\\backslash n}} \\cdot\\left{\\int \\boldsymbol{\\theta} \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta}-\\int \\mathbf{\\mu}^{\\backslash n} \\cdot q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta}\\right} \\\n\u0026amp;=\\frac{1}{v^{\\backslash n}} \\cdot\\left{\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right} \\\n\u0026amp;= \\left{\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right} \\cdot \\left{\\begin{array}{ll} \\frac{1}{vl^{\\backslash n}} \u0026amp; \\text { if } X{d}\u0026lt;\\mu_{d} \\frac{1}{vr^{\\backslash n}} \u0026amp; \\text { if } X{d} \\geqslant \\mu_{d} \\end{array}\\right. \\end{aligned} $$\n$$ \\text{According to the following}: q^{\\backslash n}(\\boldsymbol{\\theta})=\\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu^{\\backslash n}}, v_l^{\\backslash n} \\mathbf{I}, vr^{\\backslash n} \\mathbf{I}) q^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right)=Z_{n} \\cdot q^{new}(\\theta) $$\n$$ \\begin{aligned} \\mathbb{E}[\\boldsymbol{\\theta}] \u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\ln Z{n} \\ \u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}} \\nabla{\\mathbf{\\mu}^{\\backslash n}} Z_n \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}} \\nabla{\\mathbf{\\mu}^{\\backslash n}} (1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\frac{1}{Z{n}}(1-w) \\nabla{\\mathbf{\\mu}^{\\backslash n}} \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(v_r^{\\backslash n}+1\\right) \\mathbf{I}\\right)\n%\\cdot \\frac{1}{v^{\\backslash n}+1}\\left(\\mathbf{x}_{n}-\\mathbf{\\mu}^{\\backslash n}\\right)\n\\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+v^{\\backslash n} \\cdot \\rho{n} \\cdot \\frac{1}{v^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\\n\u0026amp;=\\mathbf{\\mu}^{\\backslash n}+ \\rho_{n} \\cdot\n\\left{\\begin{array}{ll} \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n}\n\u0026amp; \\text { if } X{d}\u0026lt;\\mu{d} \\frac{1}{vr^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot vl^{\\backslash n} \u0026amp; \\text { if } X{d} \\geqslant \\mu_{d} \\end{array}\\right.\n\\\n\\text{According to: }\u0026amp; \\rho{n} = 1 - \\frac{w}{Zn} \\cdot \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) \\\n\u0026amp;\\text{Here we match first moment}: \\mathbb{E}[\\boldsymbol{\\theta}] = \\mathbf{\\mu^{new}} \\end{aligned} $$\nNow we consider when: $$ \\text { if } X{d}\u0026lt;\\mu{d} $$\n$$ \\begin{aligned} \\nabla_{vl^{\\backslash n}} \\ln Z{n} \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{vl^{\\backslash n}} Z{n} \\ \u0026amp;=\\frac{1}{Z{n}} \\cdot \\nabla{vl^{\\backslash n}} \\int q^{\\backslash n}(\\boldsymbol{\\theta}) p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z{n}} \\cdot \\int\\left{\\nabla{vl^{\\backslash n}} q^{\\backslash n}(\\boldsymbol{\\theta})\\right} p\\left(\\mathbf{x}{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{Z_{n}} \\cdot \\int\\left{\n\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left| \\boldsymbol{\\theta} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right}\nq^{\\backslash n}(\\boldsymbol{\\theta}) \\cdot p\\left(\\mathbf{x}_{n} | \\boldsymbol{\\theta}\\right) d \\boldsymbol{\\theta} \\\n\u0026amp;=\\int q^{\\mathrm{new}}(\\boldsymbol{\\theta}) \\cdot\\left{\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left(\\mathbf{\\mu}^{\\backslash n}-\\boldsymbol{\\theta}\\right)^{T}\\left(\\mathbf{\\mu}^{\\backslash n}-\\boldsymbol{\\theta}\\right)-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\\right} d \\boldsymbol{\\theta} \\\n\u0026amp;=\\frac{1}{2\\left(v_l^{\\backslash n}\\right)^{2}}\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]-2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{\\mu}^{\\backslash n}+\\left|\\mathbf{\\mu}^{\\backslash n}\\right|^{2}\\right}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\end{aligned} $$\nSo we rearrange the above equation: $$ \\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]=2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n}+2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{m}^{\\backslash n}-\\left|\\mathbf{m}^{\\backslash n}\\right|^{2}+ \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } $$ Also according to: $$ Z{n}=(1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(vr^{\\backslash n}+1\\right) \\mathbf{I}\\right)+w \\mathcal{A}\\left(\\mathbf{x}{n} | \\mathbf{0}, a \\mathbf{I_l}, a \\mathbf{I_r}\\right) $$\n$$ \\nabla_{vl^{\\backslash n}} \\ln Z{n} = (1-w) \\mathcal{A}\\left(\\mathbf{x}_{n} | \\mathbf{\\mu}^{\\backslash n},\\left(v_l^{\\backslash n}+1\\right) \\mathbf{I}, \\left(v_r^{\\backslash n}+1\\right) \\mathbf{I}\\right) \\cdot \\\n\\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right) \\\n= \\rho_n \\cdot \\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right) $$\nAccording to the bellow formula: $$ v \\mathbf{I}=\\mathbb{E}\\left[\\boldsymbol{\\theta} \\boldsymbol{\\theta}^{T}\\right]-\\mathbb{E}[\\boldsymbol{\\theta}] \\mathbb{E}\\left[\\boldsymbol{\\theta}^{T}\\right] $$\n$$ \\begin{aligned} v_l^{new} \u0026amp;=\\frac{1}{D} \\cdot\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T} \\boldsymbol{\\theta}\\right]-\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T}\\right] \\mathbb{E}[\\boldsymbol{\\theta}]\\right}=\\frac{1}{D} \\cdot\\left{\\mathbb{E}\\left[\\boldsymbol{\\theta}^{T} \\boldsymbol{\\theta}\\right]-|\\mathbb{E}[\\boldsymbol{\\theta}]|^{2}\\right} \u0026amp;=\\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n}+2 \\mathbb{E}[\\boldsymbol{\\theta}] \\mathbf{\\mu}^{\\backslash n}-\\left|\\mathbf{\\mu}^{\\backslash n}\\right|^{2}\n \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } - |\\mathbb{E}[\\boldsymbol{\\theta}]|^{2} \\right}\n  \u0026amp;=\\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left|\\mathbb{E}[\\boldsymbol{\\theta}]-\\mathbf{\\mu}^{\\backslash n}\\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \\\n\u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right}\n\\end{aligned} $$ substitute $\\nabla_{vl^{\\backslash n}} \\ln Z{n}$: $$ \\begin{aligned} v_l^{new} \u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(vl^{\\backslash n}\\right)^{2} \\cdot \\nabla{vl^{\\backslash n}} \\ln Z{n} - \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \\\n\u0026amp;= \\frac{1}{D} \\cdot\\left{ 2\\left(v_l^{\\backslash n}\\right)^{2} \\cdot\n\\rho_n \\cdot \\left( \\frac{1}{2\\left(v_l^{\\backslash n} + 1\\right)^{2}}\\left| \\mathbf{x_n} - \\mathbf{\\mu}^{\\backslash n}\\right|^{2}-\\frac{D}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n\\right)\n \\left| \\rho_n \\cdot \\frac{1}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \\cdot v_l^{\\backslash n} \\right|^{2} + \\frac{D \\cdot \\left(v_l^{\\backslash n}\\right)^{2}}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } } \\right} \u0026amp;=\\frac{\\left(v_l^{\\backslash n}\\right)^{2} - 2 \\left(v_l^{\\backslash n}\\right)^{2} \\rho_n}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } + \\rho{n}\\left(1-\\rho_{n}\\right) \\frac{\\left(vl^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_l^{\\backslash n}+1\\right)^{2}}  \\end{aligned} $$ So in conclusions: we have:\n$$ \\mathbf{\\mu^{new}}=\\mathbf{\\mu}^{\\backslash n}+\n\\left{\\begin{array}{ll}\n\\rho_{n} \\frac{v_l^{\\backslash n}}{vl^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\rho_{n} \\frac{v_r^{\\backslash n}}{vr^{\\backslash n}+1}\\left(\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$\n$$ \\left{\\begin{array}{ll} v_l^{new}= \\frac{\\left(v_l^{\\backslash n}\\right)^{2} - 2 \\left(v_l^{\\backslash n}\\right)^{2} \\rho_n}{4 v_l^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot vr^{\\backslash n} } } + \\rho{n}\\left(1-\\rho_{n}\\right) \\frac{\\left(vl^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_l^{\\backslash n}+1\\right)^{2}}\n\u0026amp; \\text { if } X\u0026lt;\\mu \\\nv_r^{new}= \\frac{\\left(v_r^{\\backslash n}\\right)^{2} - 2 \\left(v_r^{\\backslash n}\\right)^{2} \\rho_n}{4 v_r^{\\backslash n} + \\sqrt{ v_l^{\\backslash n} \\cdot v_r^{\\backslash n} } }\n+\\rho{n}\\left(1-\\rho{n}\\right) \\frac{\\left(vr^{\\backslash n}\\right)^{2}\\left|\\mathbf{x}{n}-\\mathbf{\\mu}^{\\backslash n}\\right|^{2}}{D\\left(v_r^{\\backslash n}+1\\right)^{2}} \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$ - Evaluate and store the new factor\n Update formula for $\\hat{f}i$ $$ \\left{\\begin{array}{ll} \\left({v{l_n}}\\right)^{-1}={(v_l^{new})}^{-1}-({vl}^{\\backslash n})^{-1} \u0026amp; \\text { if } X\u0026lt;\\mu \\left({v{r_n}}\\right)^{-1}={(v_r^{new})}^{-1}-({v_r}^{ \\backslash n})^{-1} \u0026amp; \\text { if } X\u0026gt;\\mu \\end{array}\\right. $$\n $$ \\mathbf{\\mu}_{n}=\\mathbf{\\mu}^{\\backslash n}+ \\left{\\begin{array}{ll}\n\\left(v_{n}+v^{\\backslash n}\\right)\\left(v^{\\backslash n}\\right)^{-1}\\left(\\mathbf{\\mu}^{\\mathrm{new}}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026lt;\\mu \\\n\\left(v_{n}+v^{\\backslash n}\\right)\\left(v^{\\backslash n}\\right)^{-1}\\left(\\mathbf{\\mu}^{\\mathrm{new}}-\\mathbf{\\mu}^{\\backslash n}\\right) \u0026amp; \\text { if } X\u0026gt;\\mu \\\n\\end{array}\\right. $$\n$$ \\begin{aligned} \u0026amp; \\widetilde{f}{n}(\\boldsymbol{\\theta})=Z{n} \\frac{q^{\\mathrm{new}}(\\boldsymbol{\\theta})}{q^{\\backslash n}(\\boldsymbol{\\theta})} \\\n\\Rightarrow \u0026amp; Z_n q^{\\mathrm{new}}(\\boldsymbol{\\theta}) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) q^{\\backslash n}(\\boldsymbol{\\theta}) = s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) \\\n\\Rightarrow \u0026amp; \\int Z_n q^{\\mathrm{new}}(\\boldsymbol{\\theta}) d\\theta = \\int s_n \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}n, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) d \\theta \\\n\\Rightarrow \u0026amp; Z_n = s_n \\int q^{\\mathrm{new}}(\\boldsymbol{\\theta}) d\\theta =\n\\int s_n \\mathcal{A}\\left( \\mathbf{\\mu}n - \\boldsymbol{\\theta} | 0, \\mathbf{v{rn} I}, \\mathbf{v{l_n} I} \\right) \\mathcal{A}\\left(\\boldsymbol{\\theta} | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{v_r^{\\backslash n} I}, \\mathbf{v_l^{\\backslash n} I} \\right) d \\theta \\\n\\Rightarrow \u0026amp; Z_n = s_n \\mathcal{A}\\left(\\mathbf{\\mu}_n | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{(vr^{\\backslash n}+ v{r_n}) I}, \\mathbf{(vl^{\\backslash n}+v{r_n}) I} \\right) \\end{aligned} $$\n$$ s_n = \\frac{Z_n} {\\mathcal{A}\\left(\\mathbf{\\mu}_n | \\mathbf{\\mu}^{\\backslash n}, \\mathbf{(vr^{\\backslash n}+ v{r_n}) I}, \\mathbf{(vl^{\\backslash n}+v{r_n}) I} \\right)} $$\n Evaluate the approximation to the model evidence - Posterior probability. (When $(\\mathbf{\\mu}_n, {vl} n, {v_r}_n, S_n)$ unchanged )  $$ p(X) \\simeq q(\\boldsymbol{\\theta})= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{\\mu}, \\mathbf{v_l}, \\mathbf{vr}) = \\prod{n=0}^{N} \\widetilde{f}{n}(\\boldsymbol{\\theta})=f{0}(\\boldsymbol{\\theta}) \\prod{n=1}^{N} \\widetilde{f}{n}(\\boldsymbol{\\theta})\n= \\mathcal{A}(\\boldsymbol{\\theta} | \\mathbf{0}, b \\mathbf{I_l}, b \\mathbf{Ir})\\cdot \\prod{i=1}^{N} \\mathcal{A}\\left(\\boldsymbol{\\mu}_{i}, \\mathbf{vl}{i}, \\mathbf{vr}{i}\\right) $$\n$$ \\begin{aligned} p(X, \\boldsymbol{\\Theta}) \u0026amp; =\\prod{i} f{i}(\\boldsymbol{\\Theta}) = \\prod_{i} p(xi|\\boldsymbol{\\Theta})\n\\text{choose a factor:} q^{*}(\\Theta)\u0026amp;=\\frac{\\prod{i} \\widetilde{f}{i}(\\Theta)}{\\int \\prod{i} \\tilde{f}{i}(\\Theta) d \\Theta} \\propto \\prod{i} \\widetilde{f}_{i}(\\Theta) \\\nq^{\\backslash j}(\\Theta)\u0026amp; =\\frac{q^{*}(\\Theta)}{\\widetilde{f}_{j}(\\Theta)} \\\n\\arg \\min \\mathrm{KL}(\\hat{p} | q^{new}(\\Theta)) \u0026amp; = \\arg \\min \\mathrm{KL}\\left(\\frac{f{j}(\\boldsymbol{\\Theta}) q^{\\backslash j}(\\boldsymbol{\\Theta})} { \\underbrace{ Z{j} }{ Z{j}=\\int q^{\\backslash j}(\\boldsymbol{\\Theta}) f_{j}(\\boldsymbol{\\Theta}) \\mathrm{d} \\boldsymbol{\\Theta}} }\n| q^{\\mathrm{new}}(\\boldsymbol{\\Theta})\\right) \\\n\\tilde{f}{j}(\\boldsymbol{\\Theta}) \u0026amp;=Z{j} \\frac{q^{\\text {new }}(\\boldsymbol{\\Theta})}{q^{\\backslash j}(\\boldsymbol{\\Theta})}\n\\end{aligned} $$\n","date":1582994068,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589841215,"objectID":"985b28a7398b99c38e892b86d015b478","permalink":"https://faithio.cn/post/stochastic-expectation-propagation/","publishdate":"2020-02-29T11:34:28-05:00","relpermalink":"/post/stochastic-expectation-propagation/","section":"post","summary":"Math Formula Factor graphs Shows how a function of several variables can be factored into a product of simpler functions.\n $$ f(x,y,z) = (x+y) \\cdot (y + z) \\cdot (x +z) $$\n Very useful for representing posteriors.\n$ $$ P(x1, ..., x_n) = P(x_1) \\Pi P( x_i | x_{i-1} ) $$ $\n$$ P(m|x1, \u0026hellip;, x_n) = P(m) \\cdot \\Pi P(x_i|m)$$\nmodeling  What graph should I use for this data?","tags":[],"title":"Stochastic Expectation Propagation","type":"post"},{"authors":[],"categories":[],"content":" Introduction A hypothesis h(x), takes an input and gives us the estimated output value.\nThis hypothesis can be a as simple as a one variable linear equation, .. up to a very complicated and long multivariate equation with respect to the type of the algorithm weâ€™re using (i.e. linear regression, logistic regression..etc).\nOur task is to find the best Parameters (a.k.a Thetas or Weights) that give us the least error in predicting the output. We call this error a Cost or Loss Function and apparently our goal is to minimize it in order to get the best predicted output!\nOne more thing to recall, that the relation between the parameter value and its effect on the cost function (i.e. the error) looks like a bell curve (i.e. Quadratic; recall this because itâ€™s very important) .\nSo if we start at any point in that curve and if we keep taking the derivative (i.e. tangent line) of each point we stop at, we will end up at what so called the Global Optima as shown in this image: If we take the partial derivative at minimum cost point (i.e. global optima) we find the slope of the tangent line = 0 (then we know that we reached our target).\nThatâ€™s valid only if we have Convex Cost Function, but if we donâ€™t, we may end up stuck at what so called Local Optima; consider this non-convex function:\nNow you should have the intuition about the hack relationship between what we are doing and the terms: Deravative, Tangent Line, Cost Function, Hypothesis ..etc.\nSide Note: The above mentioned intuition also related to the Gradient Descent Algorithm (see later).\nBackground Linear Approximation:\nGiven a function, f(x), we can find its tangent at x=a. The equation of the tangent line L(x) is: L(x)=f(a)+fâ€²(a)(xâˆ’a).\nTake a look at the following graph of a function and its tangent line:\nFrom this graph we can see that near x=a, the tangent line and the function have nearly the same graph. On occasion we will use the tangent line, L(x), as an approximation to the function, f(x), near x=a. In these cases we call the tangent line the linear approximation to the function at x=a.\nQuadratic Approximation:\nSame like linear approximation but this time we are dealing with a curve but we cannot find the point near to 0 by using the tangent line.\nInstead, we use a parabola (which is a curve where any point is at an equal distance from a fixed point or a fixed straight line), like this:\nAnd in order to fit a good parabola, both parabola and quadratic function should have same value, same first derivative, AND second derivative, \u0026hellip; the formula will be (just out of curiosity): Qa(x) = f(a) + f'(a)(x-a) + f''(a)(x-a)2/2\nNow we should be ready to do the comparison in details.\nComparison between the methods 1. Newtonâ€™s Method(newton-cg): Recall the motivation for gradient descent step at x: we minimize the quadratic function (i.e. Cost Function).\nNewtonâ€™s method uses in a sense a better quadratic function minimisation. A better because it uses the quadratic approximation (i.e. first AND second partial derivatives).\nYou can imagine it as a twisted Gradient Descent with The Hessian (The Hessian is a square matrix of second-order partial derivatives of order nxn).\nMoreover, the geometric interpretation of Newton\u0026rsquo;s method is that at each iteration one approximates f(x) by a quadratic function around xn, and then takes a step towards the maximum/minimum of that quadratic function (in higher dimensions, this may also be a saddle point). Note that if f(x) happens to be a quadratic function, then the exact extremum is found in one step.\nDrawbacks:\n Itâ€™s computationally expensive because of The Hessian Matrix (i.e. second partial derivatives calculations). It attracts to Saddle Points which are common in multivariable optimization (i.e. a point its partial derivatives disagree over whether this input should be a maximum or a minimum point!).  2. Limited-memory Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno Algorithm(lbfgs): In a nutshell, it is analogue of the Newtonâ€™s Method but here the Hessian matrix is approximated using updates specified by gradient evaluations (or approximate gradient evaluations). In other words, using an estimation to the inverse Hessian matrix.\nThe term Limited-memory simply means it stores only a few vectors that represent the approximation implicitly.\nIf I dare say that when dataset is small, L-BFGS relatively performs the best compared to other methods especially it saves a lot of memory, however there are some â€œ*serious*â€ drawbacks such that if it is unsafeguarded, it may not converge to anything.\n3. A Library for Large Linear Classification(liblinear): Itâ€™s a linear classification that supports logistic regression and linear support vector machines (A linear classifier achieves this by making a classification decision based on the value of a linear combination of the characteristics i.e feature value).\nThe solver uses a coordinate descent (CD) algorithm that solves optimization problems by successively performing approximate minimization along coordinate directions or coordinate hyperplanes.\nLIBLINEAR is the winner of ICML 2008 large-scale learning challenge. It applies Automatic parameter selection (a.k.a L1 Regularization) and itâ€™s recommended when you have high dimension dataset (recommended for solving large-scale classification problems)\nDrawbacks:\n It may get stuck at a non-stationary point (i.e. non-optima) if the level curves of a function are not smooth. Also cannot run in parallel. It cannot learn a true multinomial (multiclass) model; instead, the optimization problem is decomposed in a â€œone-vs-restâ€ fashion so separate binary classifiers are trained for all classes.  Side note: According to Scikit Documentation: The â€œliblinearâ€ solver is used by default for historical reasons.\n4. Stochastic Average Gradient(sag): SAG method optimizes the sum of a finite number of smooth convex functions. Like stochastic gradient (SG) methods, the SAG method\u0026rsquo;s iteration cost is independent of the number of terms in the sum. However, by incorporating a memory of previous gradient values the SAG method achieves a faster convergence rate than black-box SG methods.\nIt is faster than other solvers for large datasets, when both the number of samples and the number of features are large.\nDrawbacks:\n It only supports L2 penalization. Its memory cost of O(N), which can make it impractical for large N (because it remembers the most recently computed values for approx. all gradients).  5. SAGA(saga): The SAGA solver is a variant of SAG that also supports the non-smooth penalty=l1 option (i.e. L1 Regularization). This is therefore the solver of choice for sparse multinomial logistic regression and itâ€™s also suitable very Large dataset.\nSide note: According to Scikit Documentation: The SAGA solver is often the best choice.\nSummary The following table is taken from Scikit Documentation\n","date":1582962364,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587265422,"objectID":"25e50f2219880ef0b8c0c1f286c67275","permalink":"https://faithio.cn/post/logistic-regression-solvers-defintions-in-sklearn/","publishdate":"2020-02-29T02:46:04-05:00","relpermalink":"/post/logistic-regression-solvers-defintions-in-sklearn/","section":"post","summary":"Introduction A hypothesis h(x), takes an input and gives us the estimated output value.\nThis hypothesis can be a as simple as a one variable linear equation, .. up to a very complicated and long multivariate equation with respect to the type of the algorithm weâ€™re using (i.e. linear regression, logistic regression..etc).\nOur task is to find the best Parameters (a.k.a Thetas or Weights) that give us the least error in predicting the output.","tags":[],"title":"Logistic Regression","type":"post"},{"authors":null,"categories":null,"content":" K-Means åŠå…¶è¡ç”Ÿç®—æ³•\nç”Ÿæˆæ¨¡å‹ä¸åˆ¤åˆ«æ¨¡å‹ åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œé€šå¸¸æœ‰ä¸¤ç§æ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ (generative model) å’Œåˆ¤åˆ«æ¨¡å‹ (discriminative model)ã€‚å¯¹äºæ— ç›‘ç£å­¦ä¹ ï¼Œèšç±»é—®é¢˜ä¸­ï¼ŒåŒæ ·æ˜¯ä¹Ÿæ˜¯ä»¥ K-Means å’Œ é«˜æ–¯æ··åˆæ¨¡å‹ (Gaussian Mixture Model) ä¸ºç»å…¸çš„ä»£è¡¨ã€‚\n è¿˜è®°å¾—ä»Šå¹´å¹´åˆåˆšå¼€å§‹ç³»ç»Ÿæ€§å­¦ä¹ æœºå™¨å­¦ä¹ çš„æ—¶å€™ï¼Œè¿™ä¸¤ä¸ªæ¦‚å¿µä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œç°åœ¨å¼„æ‡‚äº†ï¼Œä»¥åæœ‰æ—¶é—´å¯ä»¥ä¸“é—¨è®²ä¸‹ã€‚\n å¯¹äºåˆ¤åˆ«æ¨¡å‹ï¼Œé€šå¸¸å°±æ˜¯è®¡ç®—è¾¹ç•Œ (boudary)ï¼Œå¦‚æœä»¥æ•°å­¦å…¬å¼æ¥è¡¨è¾¾é€šå¸¸å°±æ˜¯ç›´æ¥ä» training data è®¡ç®—$P(\\mathcal{predict} | \\mathcal{data})$ã€‚ç›¸åçš„ï¼Œç”Ÿæˆæ¨¡å‹åˆ™ä¼šå‡è®¾æˆ‘ä»¬çš„å…ˆéªŒæ¦‚ç‡ (prior) å’Œ è¿‘ä¼¼æ¦‚ç‡ (likelihood) çš„æ¨¡å‹ï¼Œä» training dataæ±‚å‡ºä»–ä»¬çš„å‚æ•°ï¼Œæœ€åé€šè¿‡ç»å…¸çš„è´å¶æ–¯å…¬å¼æ±‚å‡ºï¼š $$ P(\\mathcal{predict} | \\mathcal{data}) = \\frac{P(\\mathcal{data} | \\mathcal{predict}) \\times P(predict)}{P(data)} $$\nK-Means åŠè¡ç”Ÿç®—æ³• K-Means K-Means æ˜¯ EM ç®—æ³•çš„ç‰¹æ®Šä¾‹å­ï¼Œå› ä¸ºå®ƒç”¨çš„æ˜¯æ¬§å‡ é‡Œå¾· (Euclidean Distance) è·ç¦»ï¼Œå®ƒçš„ç›®æ ‡functonå¦‚ä¸‹ï¼š $$ J=\\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}\\left|x^{i}-\\mu{k}\\right|^{2} $$ m ä»£è¡¨data instancesï¼ŒKä»£è¡¨ç›®å‰clusterçš„æ•°é‡ã€‚å½“$w{ik}=1$è¡¨ç¤ºè¿™ä¸ªæ•°æ®ç‚¹å±äºcluster kï¼Œè‹¥$w{ik}= 0$åˆ™è¡¨ç¤ºè¿™ä¸ªç‚¹ä¸å±äºè¿™ä¸ªclusterã€‚\né‚£ä¹ˆç®—æ³•æœ¬èº«å¯ä»¥åˆ†ä¸º E-Step å’Œ M-Stepã€‚E-Step ä¸»è¦è®¡ç®—æ¬§å‡ é‡Œå¾·è·ç¦»ï¼ŒM-Stepåˆ™æ˜¯ç®—objective function Jå¯¹äº$\\mu$çš„æ¢¯åº¦ã€‚ $$ \\begin{aligned} \u0026amp; \\text{E-Stepï¼š} \\frac{\\partial J}{\\partial w{i k}}=\\sum{i=1}^{m} \\sum{k=1}^{K} \u0026amp;\\left|x^{i}-\\mu{k}\\right|^{2} \\\n\\Rightarrow w{i k} \u0026amp;=\\left{\\begin{array}{ll}1 \u0026amp; \\text { if } k=\\operatorname{argmin}{j}\\left|x^{i}-\\mu_{j}\\right|^{2} \\ 0 \u0026amp; \\text { otherwise. }\\end{array}\\right. \u0026amp; \\text{M-Stepï¼š} \\\n\\frac{\\partial J}{\\partial \\mu{k}}=2 \\sum{i=1}^{m} w{i k}\\left(x^{i}-\\mu{k}\\right)=\u0026amp; 0 \\\n\\Rightarrow \\mu{k} \u0026amp;=\\frac{\\sum{i=1}^{m} w{i k} x^{i}}{\\sum{t-1}^{m} w_{i k}}\n\\end{aligned} \\\n$$\n éœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š\n å¦‚æœæ•°æ®é›†çš„varianceè¿‡å¤§ï¼Œæœ€å¥½å¯¹æ•°æ®åšå½’ä¸€åŒ– (Standardize)ï¼Œä½¿å¾—ä»–ä»¬çš„meanç­‰äº0ï¼Œæ ‡å‡†å·®ç­‰äº1ï¼Œä»¥é¿å…æŸäº›featureå¯¹äºå…¶ä»–featureçš„å½±å“ã€‚ K-Means ä¾èµ–äºåˆå§‹åŒ–çŠ¶æ€ï¼Œå¾ˆæœ‰å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œæ‰€ä»¥å»ºè®®å¤šåˆå§‹åŒ–å‡ æ¬¡ï¼Œç„¶åå–æœ€å°çš„J   Fuzzy C-Means (FCM) ç”±äºK-Meansæ˜¯ç¡¬åˆ†ç±»ï¼ŒFuzzy C-Meanså°±æ˜¯ç›¸å½“äºSoft K-Meansã€‚è¿™é‡Œçš„Softæ˜¯æŒ‡ç»™æ•°æ®ç‚¹å¯¹äºæ¯ä¸ªclusterä¸å†æ˜¯ç¡¬åˆ†é…ï¼Œè€Œä¸”ç»™æ¯ä¸ªclusteråˆ†é…å“åº”çš„æ¦‚ç‡ã€‚\n åŒç†ç±»ä¼¼äºSVMä¹Ÿæœ‰ç¡¬é—´éš”å’Œè½¯é—´éš”ã€‚\n è¿™é‡Œæˆ‘ä»¬åŒæ ·å¯ä»¥å†™å‡ºå®ƒçš„objective function Jï¼š $$ \\begin{array}{l} \\underset{C}{\\arg \\min } \\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}^{m}\\left|\\mathbf{x}{i}-\\mathbf{\\mu}_{k}\\right|^{2}\n\\ \\text { where: } \\ w{i j}=\\frac{1}{\\sum{k=1}^{K}\\left(\\frac{\\left|\\mathbf{x}{i}-\\mathbf{\\mu}{j}\\right|}{\\left|\\mathbf{x}{i}-\\mathbf{\\mu}{k}\\right|}\\right)^{\\frac{2}{m-1}}}\\end{array} $$\n FCMä¹Ÿæ˜¯ç¨å¾®å°†K-Means å˜å½¢ï¼Œå°†wæ”¹ä¸ºä¸€ä¸ªç›¸å¯¹å€¼ï¼Œç›¸å¯¹äºå…¶ä»–æ‰€æœ‰ç‚¹å¯¹åº”clustersçš„è·ç¦»ã€‚åˆ†æ¯å…¶å®å°±æ˜¯Normalization constantï¼Œä¸ºäº†ä¿è¯wå¤„äº0å’Œ1ä¹‹é—´ã€‚\n Hierarchical clustering å¦‚æœä½ ç•™æ„ä¸Šè¿°çš„ç®—æ³•ï¼Œä»–ä»¬éƒ½æ˜¯è¦å®ç°çŸ¥é“æˆ–è€…æ¨æ–­clustersçš„æ•°é‡ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹è¿°æ–¹æ³•æ¨æ–­ï¼š\n model selection criteria (MML/LEC/AIC/BICç­‰ç­‰) Elbow method (which uses the within cluster sums of squares) Average silhouette method Gap statistic method  ä½†æ˜¯ä¸K-Means Clusteringä¸åŒçš„æ˜¯ï¼ŒHierarchical Clustering å¯ä»¥å¸®æˆ‘ä»¬æ‰¾åˆ°æœ€ä¼˜çš„clustersæ•°é‡ã€‚\nå…¶ç®—æ³•å¾ˆç®€å•è¿‡ç¨‹å¦‚ä¸‹ï¼š\n é¦–å…ˆå‡è®¾æ¯ä¸€ä¸ªç‚¹éƒ½æ˜¯ä¸€ä¸ªclusterï¼Œå› æ­¤Nä¸ªæ•°æ®ç‚¹å°±æœ‰Nä¸ªclusters é€šè¿‡è®¡ç®—clusterä¸clusterçš„è·ç¦»å¹¶å­˜åœ¨distance matrixé‡Œï¼Œå°†æ•°æ®é›†ä¸­è·ç¦»æœ€è¿‘çš„ä¸¤ä¸ªç‚¹åˆå¹¶æˆä¸€ä¸ªclusterï¼Œæ­¤æ—¶æœ‰N-1ä¸ªclusters é‡æ–°è®¡ç®—è·ç¦»distanc matrix ä¸æ–­é‡å¤çŸ¥é“åªå‰©ä¸‹ä¸€ä¸ªcluster  æ³¨æ„æœ‰äº”ç§æ–¹å¼è®¡ç®—è·ç¦»ï¼š\n Single linkage: computes the minimum distance between clusters before merging them. Complete linkage: computes the maximum distance between clusters before merging them. Average linkage: computes the average distance between clusters before merging them. Centroid linkage: calculates centroids for both clusters, then computes the distance between the two before merging them. Wardâ€™s (minimum variance) criterion: minimizes the total within-cluster variance and find the pair of clusters that leads to minimum increase in total within-cluster variance after merging.  ä¸¾ä¾‹ï¼š\næ ¹æ®ç¬¬ä¸€ç§è·ç¦»å…¬å¼ï¼š $$ \\sqrt{\\left(x{a}-x{b}\\right)^{2}+\\left(y{a}-y{b}\\right)^{2}} $$ æˆ‘ä»¬å¯ä»¥ç®—å‡ºdistance matrixï¼š\nå¯ä»¥çœ‹å‡º0.328æ˜¯æœ€å°çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†2å’Œ4åˆå¹¶ï¼Œæ­¤æ—¶åˆå¹¶é«˜åº¦ä¸º0.328ï¼š\nç„¶åå†å°†2\u0026amp;4å’Œ3åˆå¹¶ï¼Œåˆå¹¶é«˜åº¦ä¸º0.483ï¼š\nåˆå¹¶1å’Œ5ï¼Œåˆå¹¶é«˜åº¦ä¸º0.942ï¼š\nç„¶åæ ¹æ®æˆ‘ä»¬æ¯æ¬¡åˆå¹¶çš„æ•°æ®ç»˜åˆ¶æˆæ ‘çŠ¶å›¾ï¼Œæœ€åçš„é«˜åº¦ä¸º1.530ï¼š\næ­¤æ—¶æœ€ä¼˜çš„cluster æ•°ç›®åº”è¯¥å°±æ˜¯æœ€å¤§çš„åˆå¹¶é«˜åº¦ä¸‹çš„ç«–çº¿æ¡æ•°ä¹Ÿå°±æ˜¯2.\n æ³¨æ„ï¼šå…¶å®è¿™é‡Œè•´æ¶µäº†ä¸¤ç§ç­–ç•¥ï¼ŒTop-Down ï¼ˆä»ä¸€ä¸ªclusterå¼€å§‹ï¼Œä¸æ–­åˆ†è§£åˆ°Nä¸ªclustersï¼‰æˆ–è€… Bottom-Up ï¼ˆä»Nä¸ªcluserså¼€å§‹åˆå¹¶ä¸ºä¸€ä¸ªcluserï¼‰\n Hierarchical K-Means (HKMeans) å…¶å®æ˜¯Top-Down approachï¼Œå°±æ˜¯é€’å½’è°ƒç”¨K-Meansä¸æ–­å°†å…¶åˆ’ä¸ºclustersä¸­ã€‚è¿™ç§æ–¹å¼ç›¸å¯¹è¾ƒå¿«ï¼Œæ—¶é—´å¤æ‚åº¦ä¸º$O(K \\log_kn)$ã€‚ä½†æ˜¯è¿™ç§åˆ’åˆ†æ–¹æ³•æ˜¯greedyçš„ä¹Ÿæ˜¯hardçš„ï¼Œç›¸é‚»çš„ä¸¤ä¸ªç‚¹å¦‚æœåˆ’ä¸ºä¸¤ä¸ªä¸åŒçš„clusterï¼Œä»–ä»¬å†ä¹Ÿä¸ä¼šåˆ’ä¸ºåŒä¸€ä¸ªclusters.\næ€»ç»“ æœ¬æ¬¡æˆ‘ä»¬ç»†è®²äº†æ— ç›‘ç£å­¦ä¹ èšç±»çš„åˆ¤åˆ«æ¨¡å‹ï¼Œå¯¹äºåˆ¤åˆ«æ¨¡å‹æœ€å¤§çš„é—®é¢˜æ˜¯æ— æ³•è§£å†³æ•°æ®é›†overlappingçš„é—®é¢˜ï¼Œæ›´æ— æ³•åšä¸€äº›æ¨æ–­å’Œé¢„æµ‹ã€‚è¿™æ—¶ç”Ÿæˆæ¨¡å‹çš„å¥½å¤„å°±ä½“ç°å‡ºæ¥ï¼Œä»–å¯ä»¥é¢„æµ‹å‡ºæ•°æ®é›†ä¸­æ²¡æœ‰çš„æ•°æ®çš„ã€‚åé¢æˆ‘ä¼šè®²ä¸€ä¸‹ç”Ÿæˆæ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹åœ¨æ·±åº¦å­¦ä¹ ä¸­çš„åº”ç”¨ï¼Œæ¬¢è¿ç»§ç»­å…³æ³¨ã€‚\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"d0f14e1d792c8e64ca3fca4e638fc92d","permalink":"https://faithio.cn/post/k-means-vs-fuzzy-c-means/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/k-means-vs-fuzzy-c-means/","section":"post","summary":"K-Means åŠå…¶è¡ç”Ÿç®—æ³•\nç”Ÿæˆæ¨¡å‹ä¸åˆ¤åˆ«æ¨¡å‹ åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œé€šå¸¸æœ‰ä¸¤ç§æ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ (generative model) å’Œåˆ¤åˆ«æ¨¡å‹ (discriminative model)ã€‚å¯¹äºæ— ç›‘ç£å­¦ä¹ ï¼Œèšç±»é—®é¢˜ä¸­ï¼ŒåŒæ ·æ˜¯ä¹Ÿæ˜¯ä»¥ K-Means å’Œ é«˜æ–¯æ··åˆæ¨¡å‹ (Gaussian Mixture Model) ä¸ºç»å…¸çš„ä»£è¡¨ã€‚\n è¿˜è®°å¾—ä»Šå¹´å¹´åˆåˆšå¼€å§‹ç³»ç»Ÿæ€§å­¦ä¹ æœºå™¨å­¦ä¹ çš„æ—¶å€™ï¼Œè¿™ä¸¤ä¸ªæ¦‚å¿µä¸æ˜¯å¾ˆæ¸…æ¥šï¼Œç°åœ¨å¼„æ‡‚äº†ï¼Œä»¥åæœ‰æ—¶é—´å¯ä»¥ä¸“é—¨è®²ä¸‹ã€‚\n å¯¹äºåˆ¤åˆ«æ¨¡å‹ï¼Œé€šå¸¸å°±æ˜¯è®¡ç®—è¾¹ç•Œ (boudary)ï¼Œå¦‚æœä»¥æ•°å­¦å…¬å¼æ¥è¡¨è¾¾é€šå¸¸å°±æ˜¯ç›´æ¥ä» training data è®¡ç®—$P(\\mathcal{predict} | \\mathcal{data})$ã€‚ç›¸åçš„ï¼Œç”Ÿæˆæ¨¡å‹åˆ™ä¼šå‡è®¾æˆ‘ä»¬çš„å…ˆéªŒæ¦‚ç‡ (prior) å’Œ è¿‘ä¼¼æ¦‚ç‡ (likelihood) çš„æ¨¡å‹ï¼Œä» training dataæ±‚å‡ºä»–ä»¬çš„å‚æ•°ï¼Œæœ€åé€šè¿‡ç»å…¸çš„è´å¶æ–¯å…¬å¼æ±‚å‡ºï¼š $$ P(\\mathcal{predict} | \\mathcal{data}) = \\frac{P(\\mathcal{data} | \\mathcal{predict}) \\times P(predict)}{P(data)} $$\nK-Means åŠè¡ç”Ÿç®—æ³• K-Means K-Means æ˜¯ EM ç®—æ³•çš„ç‰¹æ®Šä¾‹å­ï¼Œå› ä¸ºå®ƒç”¨çš„æ˜¯æ¬§å‡ é‡Œå¾· (Euclidean Distance) è·ç¦»ï¼Œå®ƒçš„ç›®æ ‡functonå¦‚ä¸‹ï¼š $$ J=\\sum{i=1}^{m} \\sum{k=1}^{K} w{i k}\\left|x^{i}-\\mu{k}\\right|^{2} $$ m ä»£è¡¨data instancesï¼ŒKä»£è¡¨ç›®å‰clusterçš„æ•°é‡ã€‚å½“$w{ik}=1$è¡¨ç¤ºè¿™ä¸ªæ•°æ®ç‚¹å±äºcluster kï¼Œè‹¥$w{ik}= 0$åˆ™è¡¨ç¤ºè¿™ä¸ªç‚¹ä¸å±äºè¿™ä¸ªclusterã€‚\né‚£ä¹ˆç®—æ³•æœ¬èº«å¯ä»¥åˆ†ä¸º E-Step å’Œ M-Stepã€‚E-Step ä¸»è¦è®¡ç®—æ¬§å‡ é‡Œå¾·è·ç¦»ï¼ŒM-Stepåˆ™æ˜¯ç®—objective function Jå¯¹äº$\\mu$çš„æ¢¯åº¦ã€‚ $$ \\begin{aligned} \u0026amp; \\text{E-Stepï¼š} \\frac{\\partial J}{\\partial w{i k}}=\\sum{i=1}^{m} \\sum{k=1}^{K} \u0026amp;\\left|x^{i}-\\mu{k}\\right|^{2} \\","tags":null,"title":"","type":"post"}]